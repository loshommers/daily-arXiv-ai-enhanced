<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 30]
- [cs.CL](#cs.CL) [Total: 14]
- [cs.LG](#cs.LG) [Total: 22]
- [cs.CR](#cs.CR) [Total: 4]
- [stat.ML](#stat.ML) [Total: 8]
- [cs.AI](#cs.AI) [Total: 13]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [OTPrune: Distribution-Aligned Visual Token Pruning via Optimal Transport](https://arxiv.org/abs/2602.20205)
*Xiwen Chen,Wenhui Zhu,Gen Li,Xuanzhao Dong,Yujian Xiong,Hao Wang,Peijie Qiu,Qingquan Song,Zhipeng Wang,Shao Tang,Yalin Wang,Abolfazl Razi*

Main category: cs.CV

TL;DR: OTPrune：基于最优运输的视觉token剪枝，优化推理过程。


<details>
  <summary>Details</summary>
Motivation: 现有剪枝方法忽视了视觉表示的潜在分布结构。

Method: OTPrune通过最小化全和剪枝token分布之间的2-Wasserstein距离进行剪枝，以优化运输。

Result: OTPrune减少了推理成本，同时保留了局部多样性和全局代表性。

Conclusion: OTPrune在性能效率权衡方面优于现有方法。

Abstract: Multi-modal large language models (MLLMs) achieve strong visual-language reasoning but suffer from high inference cost due to redundant visual tokens. Recent work explores visual token pruning to accelerate inference, while existing pruning methods overlook the underlying distributional structure of visual representations. We propose OTPrune, a training-free framework that formulates pruning as distribution alignment via optimal transport (OT). By minimizing the 2-Wasserstein distance between the full and pruned token distributions, OTPrune preserves both local diversity and global representativeness while reducing inference cost. Moreover, we derive a tractable submodular objective that enables efficient optimization, and theoretically prove its monotonicity and submodularity, providing a principled foundation for stable and efficient pruning. We further provide a comprehensive analysis that explains how distributional alignment contributes to stable and semantically faithful pruning. Comprehensive experiments on wider benchmarks demonstrate that OTPrune achieves superior performance-efficiency tradeoffs compared to state-of-the-art methods. The code is available at https://github.com/xiwenc1/OTPrune.

</details>


### [2] [De-rendering, Reasoning, and Repairing Charts with Vision-Language Models](https://arxiv.org/abs/2602.20291)
*Valentin Bonas,Martin Sinnona,Viviana Siless,Emmanuel Iarussi*

Main category: cs.CV

TL;DR: 提出了一种基于LLM的数据可视化反馈框架，通过识别和提出设计建议，提高可视化质量和用户素养。


<details>
  <summary>Details</summary>
Motivation: 数据可视化在科学传播、新闻业和日常决策中起着核心作用，但它们经常存在错误，这些错误可能会扭曲解释或误导受众。基于规则的视觉化检查器可以标记违规行为，但它们忽略了上下文，并且不提出有意义的设计更改。直接查询通用LLMs关于可视化质量是不可靠的：缺乏遵循可视化设计原则的训练，它们通常会提供不一致或错误的反馈。

Method: 提出一个结合图表反渲染、自动分析和迭代改进的框架，以提供可操作、可解释的视觉设计反馈。系统从图像中重建图表结构，使用视觉语言推理识别设计缺陷，并提出基于可视化研究确立的原则的具体修改建议。

Result: 在Chart2Code基准测试的1000个图表上进行了评估，系统生成了10452个设计建议，这些建议聚类成10个有意义的类别（例如，轴格式化、颜色可访问性、图例一致性）。这些结果突出了LLM驱动的推荐系统在提供结构化、基于原则的视觉设计反馈方面的潜力，为更智能和易于访问的编写工具打开了大门。

Conclusion: 提出了一种新的数据可视化反馈框架，该框架通过LLM技术提供有意义的建议，有助于提高可视化质量和可视化素养。

Abstract: Data visualizations are central to scientific communication, journalism, and everyday decision-making, yet they are frequently prone to errors that can distort interpretation or mislead audiences. Rule-based visualization linters can flag violations, but they miss context and do not suggest meaningful design changes. Directly querying general-purpose LLMs about visualization quality is unreliable: lacking training to follow visualization design principles, they often produce inconsistent or incorrect feedback. In this work, we introduce a framework that combines chart de-rendering, automated analysis, and iterative improvement to deliver actionable, interpretable feedback on visualization design. Our system reconstructs the structure of a chart from an image, identifies design flaws using vision-language reasoning, and proposes concrete modifications supported by established principles in visualization research. Users can selectively apply these improvements and re-render updated figures, creating a feedback loop that promotes both higher-quality visualizations and the development of visualization literacy. In our evaluation on 1,000 charts from the Chart2Code benchmark, the system generated 10,452 design recommendations, which clustered into 10 coherent categories (e.g., axis formatting, color accessibility, legend consistency). These results highlight the promise of LLM-driven recommendation systems for delivering structured, principle-based feedback on visualization design, opening the door to more intelligent and accessible authoring tools.

</details>


### [3] [N4MC: Neural 4D Mesh Compression](https://arxiv.org/abs/2602.20312)
*Guodong Chen,Huanshuo Dong,Mallesham Dasari*

Main category: cs.CV

TL;DR: N4MC is a 4D neural compression framework that efficiently compresses time-varying mesh sequences and outperforms existing methods


<details>
  <summary>Details</summary>
Motivation: Compressing time-varying mesh sequences efficiently

Method: Learning motion compensation using a 4D tensor representation and a transformer-based interpolation model

Result: Outperforms state-of-the-art in rate-distortion performance, enabling real-time decoding of 4D mesh sequences

Conclusion: N4MC is a novel and effective 4D neural compression framework for time-varying mesh sequences

Abstract: We present N4MC, the first 4D neural compression framework to efficiently compress time-varying mesh sequences by exploiting their temporal redundancy. Unlike prior neural mesh compression methods that treat each mesh frame independently, N4MC takes inspiration from inter-frame compression in 2D video codecs, and learns motion compensation in long mesh sequences. Specifically, N4MC converts consecutive irregular mesh frames into regular 4D tensors to provide a uniform and compact representation. These tensors are then condensed using an auto-decoder, which captures both spatial and temporal correlations for redundancy removal. To enhance temporal coherence, we introduce a transformer-based interpolation model that predicts intermediate mesh frames conditioned on latent embeddings derived from tracked volume centers, eliminating motion ambiguities. Extensive evaluations show that N4MC outperforms state-of-the-art in rate-distortion performance, while enabling real-time decoding of 4D mesh sequences. The implementation of our method is available at: https://github.com/frozzzen3/N4MC.

</details>


### [4] [GSNR: Graph Smooth Null-Space Representation for Inverse Problems](https://arxiv.org/abs/2602.20328)
*Romario Gualdrón-Hurtado,Roman Jacome,Rafael S. Suarez,Henry Arguello*

Main category: cs.CV

TL;DR: 提出了GSNR，一种新的图像重建方法，在多个场景中显著提高了性能。


<details>
  <summary>Details</summary>
Motivation: 图像反演问题因感知矩阵的非平凡零空间而具有病态性，导致与测量一致的解有无限多个。常见的图像先验促进了图像流形上的解，如稀疏性、平滑性或得分函数。然而，由于这些先验没有约束零空间分量，它们可能会对重建造成偏差。因此，我们旨在将有意义的零空间信息纳入重建框架。受图上平滑图像表示的启发，我们提出了图平滑零空间表示（GSNR），这是一种仅对不可见分量施加结构的机制。特别是，给定一个图拉普拉斯算子，我们在零空间信号中构建了一个零限制拉普拉斯算子，该算子编码了相邻像素之间的相似性，并设计了一个从 $p$-平滑图谱模式（最低图频率）到低维投影矩阵。这种方法具有强大的理论和实践意义：i）通过零空间图正则化器提高收敛性，ii）更好的覆盖范围，即多少零空间方差被 $p$ 模式捕获，以及iii）高度的预测能力，即这些模式可以从测量中推断得多好。GSNR被纳入已知的逆问题求解器，例如PnP、DIP和扩散求解器，在四种场景中：图像去模糊、压缩感知、去马赛克和图像超分辨率，与基线公式相比，提供了一致的性能提升，高达4.3 dB，与端到端学习模型相比，在PSNR方面提高了高达1 dB。

Method: 提出了一种名为GSNR的图平滑零空间表示机制，该机制仅对不可见分量施加结构。具体来说，给定一个图拉普拉斯算子，我们构建了一个零限制拉普拉斯算子，该算子编码了相邻像素之间的相似性，并设计了一个从 $p$-平滑图谱模式到低维投影矩阵。

Result: 该方法在图像去模糊、压缩感知、去马赛克和图像超分辨率等场景中与基线公式相比，提供了一致的性能提升，高达4.3 dB，与端到端学习模型相比，在PSNR方面提高了高达1 dB。

Conclusion: GSNR是一种有效的图像重建方法，可以显著提高重建质量。

Abstract: Inverse problems in imaging are ill-posed, leading to infinitely many solutions consistent with the measurements due to the non-trivial null-space of the sensing matrix. Common image priors promote solutions on the general image manifold, such as sparsity, smoothness, or score function. However, as these priors do not constrain the null-space component, they can bias the reconstruction. Thus, we aim to incorporate meaningful null-space information in the reconstruction framework. Inspired by smooth image representation on graphs, we propose Graph-Smooth Null-Space Representation (GSNR), a mechanism that imposes structure only into the invisible component. Particularly, given a graph Laplacian, we construct a null-restricted Laplacian that encodes similarity between neighboring pixels in the null-space signal, and we design a low-dimensional projection matrix from the $p$-smoothest spectral graph modes (lowest graph frequencies). This approach has strong theoretical and practical implications: i) improved convergence via a null-only graph regularizer, ii) better coverage, how much null-space variance is captured by $p$ modes, and iii) high predictability, how well these modes can be inferred from the measurements. GSNR is incorporated into well-known inverse problem solvers, e.g., PnP, DIP, and diffusion solvers, in four scenarios: image deblurring, compressed sensing, demosaicing, and image super-resolution, providing consistent improvement of up to 4.3 dB over baseline formulations and up to 1 dB compared with end-to-end learned models in terms of PSNR.

</details>


### [5] [3DSPA: A 3D Semantic Point Autoencoder for Evaluating Video Realism](https://arxiv.org/abs/2602.20354)
*Bhavik Chandna,Kelsey R. Allen*

Main category: cs.CV

TL;DR: 开发了一种名为3DSPA的自动评估视频真实性的框架，该框架通过整合3D点轨迹、深度线索和DINO语义特征，提高了视频生成模型的真实性评估。


<details>
  <summary>Details</summary>
Motivation: AI视频生成正在快速发展，但评估生成视频的真实性仍然是一个手动过程，需要人类注释或定制评估数据集，这些数据集范围有限。

Method: 开发了一种自动评估视频真实性的框架，名为3DSPA，该框架整合了3D点轨迹、深度线索和DINO语义特征，以统一表示视频评估。

Result: 实验表明，3DSPA可以可靠地识别违反物理定律的视频，对运动伪影更敏感，并且与人类对视频质量和真实性的判断更一致。

Conclusion: 通过丰富基于轨迹的表示，结合3D语义，为生成视频模型的基准测试提供了更坚实的基础。

Abstract: AI video generation is evolving rapidly. For video generators to be useful for applications ranging from robotics to film-making, they must consistently produce realistic videos. However, evaluating the realism of generated videos remains a largely manual process -- requiring human annotation or bespoke evaluation datasets which have restricted scope. Here we develop an automated evaluation framework for video realism which captures both semantics and coherent 3D structure and which does not require access to a reference video. Our method, 3DSPA, is a 3D spatiotemporal point autoencoder which integrates 3D point trajectories, depth cues, and DINO semantic features into a unified representation for video evaluation. 3DSPA models how objects move and what is happening in the scene, enabling robust assessments of realism, temporal consistency, and physical plausibility. Experiments show that 3DSPA reliably identifies videos which violate physical laws, is more sensitive to motion artifacts, and aligns more closely with human judgments of video quality and realism across multiple datasets. Our results demonstrate that enriching trajectory-based representations with 3D semantics offers a stronger foundation for benchmarking generative video models, and implicitly captures physical rule violations. The code and pretrained model weights will be available at https://github.com/TheProParadox/3dspa_code.

</details>


### [6] [CLIPoint3D: Language-Grounded Few-Shot Unsupervised 3D Point Cloud Domain Adaptation](https://arxiv.org/abs/2602.20409)
*Mainak Singha,Sarthak Mehrotra,Paolo Casari,Subhasis Chaudhuri,Elisa Ricci,Biplab Banerjee*

Main category: cs.CV

TL;DR: CLIPoint3D is a new framework for 3D点云域适应，在基准测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: Recent vision-language models (VLMs) such as CLIP demonstrate impressive cross-modal reasoning, extending beyond images to 3D perception. Yet, these models remain fragile under domain shifts, especially when adapting from synthetic to real-world point clouds.

Method: CLIPoint3D, the first framework for few-shot unsupervised 3D point cloud domain adaptation built upon CLIP. Projects 3D samples into multiple depth maps, exploits the frozen CLIP backbone, refined through a knowledge-driven prompt tuning scheme. Applies parameter-efficient fine-tuning to CLIP's encoders and designs an entropy-guided view sampling strategy. Uses optimal transport-based alignment loss and uncertainty-aware prototype alignment loss.

Result: Achieves consistent 3-16% accuracy gains over both CLIP-based and conventional encoder-based baselines on PointDA-10 and GraspNetPC-10 benchmarks.

Conclusion: CLIPoint3D is an effective framework for few-shot unsupervised 3D point cloud domain adaptation.

Abstract: Recent vision-language models (VLMs) such as CLIP demonstrate impressive cross-modal reasoning, extending beyond images to 3D perception. Yet, these models remain fragile under domain shifts, especially when adapting from synthetic to real-world point clouds. Conventional 3D domain adaptation approaches rely on heavy trainable encoders, yielding strong accuracy but at the cost of efficiency. We introduce CLIPoint3D, the first framework for few-shot unsupervised 3D point cloud domain adaptation built upon CLIP. Our approach projects 3D samples into multiple depth maps and exploits the frozen CLIP backbone, refined through a knowledge-driven prompt tuning scheme that integrates high-level language priors with geometric cues from a lightweight 3D encoder. To adapt task-specific features effectively, we apply parameter-efficient fine-tuning to CLIP's encoders and design an entropy-guided view sampling strategy for selecting confident projections. Furthermore, an optimal transport-based alignment loss and an uncertainty-aware prototype alignment loss collaboratively bridge source-target distribution gaps while maintaining class separability. Extensive experiments on PointDA-10 and GraspNetPC-10 benchmarks show that CLIPoint3D achieves consistent 3-16% accuracy gains over both CLIP-based and conventional encoder-based baselines. Codes are available at https://github.com/SarthakM320/CLIPoint3D.

</details>


### [7] [Beyond Human Performance: A Vision-Language Multi-Agent Approach for Quality Control in Pharmaceutical Manufacturing](https://arxiv.org/abs/2602.20543)
*Subhra Jyoti Mandal,Lara Rachidi,Puneet Jain,Matthieu Duvinage,Sander W. Timmer*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Colony-forming unit (CFU) detection is critical in pharmaceutical manufacturing, serving as a key component of Environmental Monitoring programs and ensuring compliance with stringent quality standards. Manual counting is labor-intensive and error-prone, while deep learning (DL) approaches, though accurate, remain vulnerable to sample quality variations and artifacts. Building on our earlier CNN-based framework (Beznik et al., 2020), we evaluated YOLOv5, YOLOv7, and YOLOv8 for CFU detection; however, these achieved only 97.08 percent accuracy, insufficient for pharmaceutical-grade requirements. A custom Detectron2 model trained on GSK's dataset of over 50,000 Petri dish images achieved 99 percent detection rate with 2 percent false positives and 0.6 percent false negatives. Despite high validation accuracy, Detectron2 performance degrades on outlier cases including contaminated plates, plastic artifacts, or poor optical clarity. To address this, we developed a multi-agent framework combining DL with vision-language models (VLMs). The VLM agent first classifies plates as valid or invalid. For valid samples, both DL and VLM agents independently estimate colony counts. When predictions align within 5 percent, results are automatically recorded in Postgres and SAP; otherwise, samples are routed for expert review. Expert feedback enables continuous retraining and self-improvement. Initial DL-based automation reduced human verification by 50 percent across vaccine manufacturing sites. With VLM integration, this increased to 85 percent, delivering significant operational savings. The proposed system provides a scalable, auditable, and regulation-ready solution for microbiological quality control, advancing automation in biopharmaceutical production.

</details>


### [8] [Robust Spiking Neural Networks Against Adversarial Attacks](https://arxiv.org/abs/2602.20548)
*Shuai Wang,Malu Zhang,Yulin Jiang,Dehao Zhang,Ammar Belatreche,Yu Liang,Yimeng Shan,Zijian Zhou,Yang Yang,Haizhou Li*

Main category: cs.CV

TL;DR: 提出TGO方法提高SNNs鲁棒性


<details>
  <summary>Details</summary>
Motivation: Spiking Neural Networks (SNNs) 在能量效率神经形态计算中具有潜力，但其鲁棒性受限。

Method: 提出了一种Threshold Guarding Optimization (TGO) 方法，包括增加损失函数约束和引入噪声脉冲神经元。

Result: 实验表明，该方法显著提高了直接训练的SNNs的鲁棒性。

Conclusion: TGO方法为提高SNNs在复杂环境中的鲁棒性提供了有效途径。

Abstract: Spiking Neural Networks (SNNs) represent a promising paradigm for energy-efficient neuromorphic computing due to their bio-plausible and spike-driven characteristics. However, the robustness of SNNs in complex adversarial environments remains significantly constrained. In this study, we theoretically demonstrate that those threshold-neighboring spiking neurons are the key factors limiting the robustness of directly trained SNNs. We find that these neurons set the upper limits for the maximum potential strength of adversarial attacks and are prone to state-flipping under minor disturbances. To address this challenge, we propose a Threshold Guarding Optimization (TGO) method, which comprises two key aspects. First, we incorporate additional constraints into the loss function to move neurons' membrane potentials away from their thresholds. It increases SNNs' gradient sparsity, thereby reducing the theoretical upper bound of adversarial attacks. Second, we introduce noisy spiking neurons to transition the neuronal firing mechanism from deterministic to probabilistic, decreasing their state-flipping probability due to minor disturbances. Extensive experiments conducted in standard adversarial scenarios prove that our method significantly enhances the robustness of directly trained SNNs. These findings pave the way for advancing more reliable and secure neuromorphic computing in real-world applications.

</details>


### [9] [The Finite Primitive Basis Theorem for Computational Imaging: Formal Foundations of the OperatorGraph Representation](https://arxiv.org/abs/2602.20550)
*Chengshuai Yang*

Main category: cs.CV

TL;DR: 提出了一种新的成像正向模型表示方法，并证明了其普适性和有效性。


<details>
  <summary>Details</summary>
Motivation: 针对传统成像正向模型的局限性，提出了一种新的成像正向模型表示方法。

Method: 提出了一种基于类型化有向无环图（DAG）的成像正向模型表示方法，并证明了该方法的普适性和有效性。

Result: 证明了所有成像正向模型都可以用11个基本操作表示，并提供了算法实现和实证验证。

Conclusion: 该方法为PWM框架提供了数学基础，为成像正向模型的表示和优化提供了新的思路。

Abstract: Computational imaging forward models, from coded aperture spectral cameras to MRI scanners, are traditionally implemented as monolithic, modality-specific codes. We prove that every forward model in a broad, precisely defined operator class Cimg (encompassing clinical, scientific, and industrial imaging modalities, both linear and nonlinear) admits an epsilon-approximate representation as a typed directed acyclic graph (DAG) whose nodes are drawn from a library of exactly 11 canonical primitives: Propagate, Modulate, Project, Encode, Convolve, Accumulate, Detect, Sample, Disperse, Scatter, and Transform. We call this the Finite Primitive Basis Theorem. The proof is constructive: we provide an algorithm that, given any H in Cimg, produces a DAG G with relative operator error at most epsilon and graph complexity within prescribed bounds. We further prove that the library is minimal: removing any single primitive causes at least one modality to lose its epsilon-approximate representation. A systematic analysis of nonlinearities in imaging physics shows they fall into two structural categories: pointwise scalar functions (handled by Transform) and self-consistent iterations (unrolled into existing linear primitives). Empirical validation on 31 linear modalities confirms eimg below 0.01 with at most 5 nodes and depth 5, and we provide constructive DAG decompositions for 9 additional nonlinear modalities. These results establish mathematical foundations for the Physics World Model (PWM) framework.

</details>


### [10] [WildGHand: Learning Anti-Perturbation Gaussian Hand Avatars from Monocular In-the-Wild Videos](https://arxiv.org/abs/2602.20556)
*Hanhui Li,Xuan Huang,Wanquan Liu,Yuhao Cheng,Long Chen,Yiqiang Yan,Xiaodan Liang,Chenqiang Gao*

Main category: cs.CV

TL;DR: WildGHand在真实场景手部重建中表现卓越。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在真实场景下的退化问题。

Method: 优化框架，包括动态扰动解耦模块和扰动感知优化策略。

Result: 在多个指标上实现最先进性能，如PSNR提高了15.8%，LPIPS降低了23.1%。

Conclusion: WildGHand在真实场景的手部重建方面取得了突破性进展，显著优于现有模型。

Abstract: Despite recent progress in 3D hand reconstruction from monocular videos, most existing methods rely on data captured in well-controlled environments and therefore degrade in real-world settings with severe perturbations, such as hand-object interactions, extreme poses, illumination changes, and motion blur. To tackle these issues, we introduce WildGHand, an optimization-based framework that enables self-adaptive 3D Gaussian splatting on in-the-wild videos and produces high-fidelity hand avatars. WildGHand incorporates two key components: (i) a dynamic perturbation disentanglement module that explicitly represents perturbations as time-varying biases on 3D Gaussian attributes during optimization, and (ii) a perturbation-aware optimization strategy that generates per-frame anisotropic weighted masks to guide optimization. Together, these components allow the framework to identify and suppress perturbations across both spatial and temporal dimensions. We further curate a dataset of monocular hand videos captured under diverse perturbations to benchmark in-the-wild hand avatar reconstruction. Extensive experiments on this dataset and two public datasets demonstrate that WildGHand achieves state-of-the-art performance and substantially improves over its base model across multiple metrics (e.g., up to a $15.8\%$ relative gain in PSNR and a $23.1\%$ relative reduction in LPIPS). Our implementation and dataset are available at https://github.com/XuanHuang0/WildGHand.

</details>


### [11] [AIForge-Doc: A Benchmark for Detecting AI-Forged Tampering in Financial and Form Documents](https://arxiv.org/abs/2602.20569)
*Jiaqi Wu,Yuchen Zhou,Muduo Xu,Zisheng Liang,Simiao Ren,Jiayu Xue,Meige Yang,Siying Chen,Jingheng Huan*

Main category: cs.CV

TL;DR: AIForge-Doc 是首个针对基于扩散模型的金融和表格文档修复的基准，发现现有检测器对 AI 伪造的文档无法有效识别。


<details>
  <summary>Details</summary>
Motivation: 现有文件伪造数据集依赖于传统数字编辑工具，无法检测 AI 伪造的文件欺诈威胁。

Method: 使用 Gemini 2.5 Flash Image 和 Ideogram v2 Edit 两个 AI 修复 API 系统性地伪造实际收据和表单图像中的数字字段，并使用像素精确的篡改区域掩码进行标注。

Result: 三个代表性检测器（TruFor、DocTamper 和 GPT-4o）的检测结果均大幅下降，证实了 AI 伪造值对自动检测器和 VLMs 来说是无法区分的。

Conclusion: AIForge-Doc 代表了对文件法医学的一个全新且未解决的挑战。

Abstract: We present AIForge-Doc, the first dedicated benchmark targeting exclusively diffusion-model-based inpainting in financial and form documents with pixel-level annotation. Existing document forgery datasets rely on traditional digital editing tools (e.g., Adobe Photoshop, GIMP), creating a critical gap: state-of-the-art detectors are blind to the rapidly growing threat of AI-forged document fraud. AIForge-Doc addresses this gap by systematically forging numeric fields in real-world receipt and form images using two AI inpainting APIs -- Gemini 2.5 Flash Image and Ideogram v2 Edit -- yielding 4,061 forged images from four public document datasets (CORD, WildReceipt, SROIE, XFUND) across nine languages, annotated with pixel-precise tampered-region masks in DocTamper-compatible format. We benchmark three representative detectors -- TruFor, DocTamper, and a zero-shot GPT-4o judge -- and find that all existing methods degrade substantially: TruFor achieves AUC=0.751 (zero-shot, out-of-distribution) vs. AUC=0.96 on NIST16; DocTamper achieves AUC=0.563 vs. AUC=0.98 in-distribution, with pixel-level IoU=0.020; GPT-4o achieves only 0.509 -- essentially at chance -- confirming that AI-forged values are indistinguishable to automated detectors and VLMs. These results demonstrate that AIForge-Doc represents a qualitatively new and unsolved challenge for document forensics.

</details>


### [12] [An interactive enhanced driving dataset for autonomous driving](https://arxiv.org/abs/2602.20575)
*Haojie Feng,Peizhi Zhang,Mengjie Tian,Xinrui Zhang,Zhuoren Li,Junpeng Huang,Xiurong Wang,Junfan Zhu,Jianzhou Wang,Dongxiao Yin,Lu Xiong*

Main category: cs.CV

TL;DR: 本文提出了IEDD数据集，以解决自动驾驶中VLA模型的开发难题，并通过基准实验证明了其价值。


<details>
  <summary>Details</summary>
Motivation: 为了应对自动驾驶向完全自动化发展所需的鲁棒交互能力，以及现有数据中交互场景的稀疏性和多模态对齐不足的问题。

Method: 提出了Interactive Enhanced Driving Dataset (IEDD)，开发了可扩展的流程从自然驾驶数据中挖掘百万级别的交互片段，并设计了度量指标来量化交互过程。此外，通过生成与结构化语言严格对齐的合成鸟瞰视图（BEV）视频，构建了IEDD-VQA数据集。

Result: 提供了对十种主流视觉语言模型（VLM）的基准结果，以证明该数据集在评估和微调自动驾驶模型的推理能力方面的重用价值。

Conclusion: 该研究提出的方法和数据集为自动驾驶模型的发展提供了重要的技术支持。

Abstract: The evolution of autonomous driving towards full automation demands robust interactive capabilities; however, the development of Vision-Language-Action (VLA) models is constrained by the sparsity of interactive scenarios and inadequate multimodal alignment in existing data. To this end, this paper proposes the Interactive Enhanced Driving Dataset (IEDD). We develop a scalable pipeline to mine million-level interactive segments from naturalistic driving data based on interactive trajectories, and design metrics to quantify the interaction processes. Furthermore, the IEDD-VQA dataset is constructed by generating synthetic Bird's Eye View (BEV) videos where semantic actions are strictly aligned with structured language. Benchmark results evaluating ten mainstream Vision Language Models (VLMs) are provided to demonstrate the dataset's reuse value in assessing and fine-tuning the reasoning capabilities of autonomous driving models.

</details>


### [13] [Efficient and Explainable End-to-End Autonomous Driving via Masked Vision-Language-Action Diffusion](https://arxiv.org/abs/2602.20577)
*Jiaru Zhang,Manav Gagvani,Can Cui,Juntong Peng,Ruqi Zhang,Ziran Wang*

Main category: cs.CV

TL;DR: MVLAD-AD：结合掩码视觉语言动作扩散模型，实现自动驾驶中的高效规划和可解释性。


<details>
  <summary>Details</summary>
Motivation: LLMs和VLMs在自动驾驶中面临推理延迟、动作精度和可解释性挑战。

Method: 提出MVLAD-AD框架，结合掩码视觉语言动作扩散模型，实现高效规划和语义可解释性。

Result: 在nuScenes和衍生基准测试中，MVLAD-AD在规划精度、效率和可解释性方面优于现有方法。

Conclusion: MVLAD-AD为自动驾驶中的高效规划和可解释性提供了一种新的解决方案。

Abstract: Large Language Models (LLMs) and Vision-Language Models (VLMs) have emerged as promising candidates for end-to-end autonomous driving. However, these models typically face challenges in inference latency, action precision, and explainability. Existing autoregressive approaches struggle with slow token-by-token generation, while prior diffusion-based planners often rely on verbose, general-purpose language tokens that lack explicit geometric structure. In this work, we propose Masked Vision-Language-Action Diffusion for Autonomous Driving (MVLAD-AD), a novel framework designed to bridge the gap between efficient planning and semantic explainability via a masked vision-language-action diffusion model. Unlike methods that force actions into the language space, we introduce a discrete action tokenization strategy that constructs a compact codebook of kinematically feasible waypoints from real-world driving distributions. Moreover, we propose geometry-aware embedding learning to ensure that embeddings in the latent space approximate physical geometric metrics. Finally, an action-priority decoding strategy is introduced to prioritize trajectory generation. Extensive experiments on nuScenes and derived benchmarks demonstrate that MVLAD-AD achieves superior efficiency and outperforms state-of-the-art autoregressive and diffusion baselines in planning precision, while providing high-fidelity and explainable reasoning.

</details>


### [14] [SpatiaLQA: A Benchmark for Evaluating Spatial Logical Reasoning in Vision-Language Models](https://arxiv.org/abs/2602.20901)
*Yuechen Xie,Xiaoyan Zhang,Yicheng Shan,Hao Zhu,Rui Tang,Rong Wei,Mingli Song,Yuanyu Wan,Jie Song*

Main category: cs.CV

TL;DR: SpatiaLQA基准和递归场景图辅助推理方法提高了VLMs的空间逻辑推理能力。


<details>
  <summary>Details</summary>
Motivation: 尽管VLMs在常见的视觉问答和逻辑推理方面表现出色，但它们在复杂现实环境中的合理决策能力仍然不足。

Method: 提出了一种名为递归场景图辅助推理的方法，该方法利用视觉基础模型将复杂场景逐步分解为与任务相关的场景图，从而增强VLMs的空间逻辑推理能力。

Result: 实验结果表明，即使是最高级的模型在空间逻辑推理方面也面临困难，而提出的方法在所有之前的方法中表现最佳。

Conclusion: SpatiaLQA是一个用于评估VLMs空间逻辑推理能力的基准，提出的方法能够有效提升VLMs的推理能力。

Abstract: Vision-Language Models (VLMs) have been increasingly applied in real-world scenarios due to their outstanding understanding and reasoning capabilities. Although VLMs have already demonstrated impressive capabilities in common visual question answering and logical reasoning, they still lack the ability to make reasonable decisions in complex real-world environments. We define this ability as spatial logical reasoning, which not only requires understanding the spatial relationships among objects in complex scenes, but also the logical dependencies between steps in multi-step tasks. To bridge this gap, we introduce Spatial Logical Question Answering (SpatiaLQA), a benchmark designed to evaluate the spatial logical reasoning capabilities of VLMs. SpatiaLQA consists of 9,605 question answer pairs derived from 241 real-world indoor scenes. We conduct extensive experiments on 41 mainstream VLMs, and the results show that even the most advanced models still struggle with spatial logical reasoning. To address this issue, we propose a method called recursive scene graph assisted reasoning, which leverages visual foundation models to progressively decompose complex scenes into task-relevant scene graphs, thereby enhancing the spatial logical reasoning ability of VLMs, outperforming all previous methods. Code and dataset are available at https://github.com/xieyc99/SpatiaLQA.

</details>


### [15] [UFO: Unifying Feed-Forward and Optimization-based Methods for Large Driving Scene Modeling](https://arxiv.org/abs/2602.20943)
*Kaiyuan Tan,Yingying Shen,Mingfei Tu,Haohui Zhu,Bing Wang,Guang Chen,Hangjun Ye,Haiyang Sun*

Main category: cs.CV

TL;DR: UFO是一种新型的循环范式，用于高效的长期4D驾驶场景重建，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 动态驾驶场景重建对自动驾驶模拟和闭环学习至关重要。

Method: 我们提出了一种名为UFO的新型循环范式，它结合了基于优化的和前馈方法的好处，以实现高效的长期4D重建。

Result: 在Waymo开放数据集上的实验表明，我们的方法在各个序列长度上均显著优于场景优化和现有前馈方法。

Conclusion: UFO能够高效地进行长期4D重建，并显著优于现有方法。

Abstract: Dynamic driving scene reconstruction is critical for autonomous driving simulation and closed-loop learning. While recent feed-forward methods have shown promise for 3D reconstruction, they struggle with long-range driving sequences due to quadratic complexity in sequence length and challenges in modeling dynamic objects over extended durations. We propose UFO, a novel recurrent paradigm that combines the benefits of optimization-based and feed-forward methods for efficient long-range 4D reconstruction. Our approach maintains a 4D scene representation that is iteratively refined as new observations arrive, using a visibility-based filtering mechanism to select informative scene tokens and enable efficient processing of long sequences. For dynamic objects, we introduce an object pose-guided modeling approach that supports accurate long-range motion capture. Experiments on the Waymo Open Dataset demonstrate that our method significantly outperforms both per-scene optimization and existing feed-forward methods across various sequence lengths. Notably, our approach can reconstruct 16-second driving logs within 0.5 second while maintaining superior visual quality and geometric accuracy.

</details>


### [16] [Are Multimodal Large Language Models Good Annotators for Image Tagging?](https://arxiv.org/abs/2602.20972)
*Ming-Kun Xie,Jia-Hao Xiao,Zhiqiang Kou,Zhongnian Li,Gang Niu,Masashi Sugiyama*

Main category: cs.CV

TL;DR: TagLLM框架有效缩小了MLLM生成的标注与人工标注之间的差距，提高了标注效率


<details>
  <summary>Details</summary>
Motivation: 降低标注成本和提高标注效率

Method: 分析MLLM生成的标注与人工标注之间的差距，提出TagLLM框架

Result: TagLLM显著缩小了MLLM生成的标注与人工标注之间的差距，尤其在下游训练性能方面，缩小了约60%到80%的差距

Conclusion: TagLLM是一种有效的图像标注框架，可以显著提高标注效率并降低成本

Abstract: Image tagging, a fundamental vision task, traditionally relies on human-annotated datasets to train multi-label classifiers, which incurs significant labor and costs. While Multimodal Large Language Models (MLLMs) offer promising potential to automate annotation, their capability to replace human annotators remains underexplored. This paper aims to analyze the gap between MLLM-generated and human annotations and to propose an effective solution that enables MLLM-based annotation to replace manual labeling. Our analysis of MLLM annotations reveals that, under a conservative estimate, MLLMs can reduce annotation cost to as low as one-thousandth of the human cost, mainly accounting for GPU usage, which is nearly negligible compared to manual efforts. Their annotation quality reaches about 50\% to 80\% of human performance, while achieving over 90\% performance on downstream training tasks.Motivated by these findings, we propose TagLLM, a novel framework for image tagging, which aims to narrow the gap between MLLM-generated and human annotations. TagLLM comprises two components: Candidates generation, which employs structured group-wise prompting to efficiently produce a compact candidate set that covers as many true labels as possible while reducing subsequent annotation workload; and label disambiguation, which interactively calibrates the semantic concept of categories in the prompts and effectively refines the candidate labels. Extensive experiments show that TagLLM substantially narrows the gap between MLLM-generated and human annotations, especially in downstream training performance, where it closes about 60\% to 80\% of the difference.

</details>


### [17] [CrystaL: Spontaneous Emergence of Visual Latents in MLLMs](https://arxiv.org/abs/2602.20980)
*Yang Zhang,Danyang Li,Yuxuan Li,Xin Zhang,Tianyu Xie,Mingming Cheng,Xiang Li*

Main category: cs.CV

TL;DR: CrystaL通过改进潜在CoT方法，提高了视觉语言模型在视觉理解方面的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的潜在链式思维（CoT）方法在保留中间潜在状态中的关键视觉信息方面提供了有限的指导。

Method: 提出了一种名为CrystaL的单一阶段框架，该框架具有两条路径来处理完整和损坏的图像。通过显式地对两条路径中的注意力模式和预测分布进行对齐，CrystaL将潜在表示结晶为与任务相关的视觉语义，而无需依赖于辅助注释或外部模块。

Result: 在感知密集型基准测试上进行了大量实验，表明CrystaL在细粒度视觉理解方面实现了显著的提升，同时保持了稳健的推理能力，并且一致优于最先进的基线。

Conclusion: CrystaL通过改进潜在CoT方法，在视觉语言整合和推理能力方面取得了显著的进展。

Abstract: Multimodal Large Language Models (MLLMs) have achieved remarkable performance by integrating powerful language backbones with large-scale visual encoders. Among these, latent Chain-of-Thought (CoT) methods enable implicit reasoning in continuous hidden states, facilitating seamless vision-language integration and faster inference. However, existing heuristically predefined supervision signals in latent CoT provide limited guidance for preserving critical visual information in intermediate latent states. To address this limitation, we propose CrystaL (Crystallized Latent Reasoning), a single-stage framework with two paths to process intact and corrupted images, respectively. By explicitly aligning the attention patterns and prediction distributions across the two paths, CrystaL crystallizes latent representations into task-relevant visual semantics, without relying on auxiliary annotations or external modules. Extensive experiments on perception-intensive benchmarks demonstrate that CrystaL consistently outperforms state-of-the-art baselines, achieving substantial gains in fine-grained visual understanding while maintaining robust reasoning capabilities.

</details>


### [18] [EW-DETR: Evolving World Object Detection via Incremental Low-Rank DEtection TRansformer](https://arxiv.org/abs/2602.20985)
*Munish Monga,Vishal Chudasama,Pankaj Wasnik,C. V. Jawahar*

Main category: cs.CV

TL;DR: EW-DETR for evolving-world object detection outperforms others by 57.24% in FOGS evaluation.


<details>
  <summary>Details</summary>
Motivation: Real-world object detection in evolving environments requires the ability to identify new classes and unseen objects without prior data access.

Method: EWOD, EW-DETR framework with Incremental LoRA Adapters, Query-Norm Objectness Adapter, and Entropy-Aware Unknown Mixing.

Result: EW-DETR improves FOGS by 57.24% on Pascal Series and Diverse Weather benchmarks.

Conclusion: EW-DETR is effective in evolving-world settings and outperforms other methods.

Abstract: Real-world object detection must operate in evolving environments where new classes emerge, domains shift, and unseen objects must be identified as "unknown": all without accessing prior data. We introduce Evolving World Object Detection (EWOD), a paradigm coupling incremental learning, domain adaptation, and unknown detection under exemplar-free constraints. To tackle EWOD, we propose EW-DETR framework that augments DETR-based detectors with three synergistic modules: Incremental LoRA Adapters for exemplar-free incremental learning under evolving domains; a Query-Norm Objectness Adapter that decouples objectness-aware features from DETR decoder queries; and Entropy-Aware Unknown Mixing for calibrated unknown detection. This framework generalises across DETR-based detectors, enabling state-of-the-art RF-DETR to operate effectively in evolving-world settings. We also introduce FOGS (Forgetting, Openness, Generalisation Score) to holistically evaluate performance across these dimensions. Extensive experiments on Pascal Series and Diverse Weather benchmarks show EW-DETR outperforms other methods, improving FOGS by 57.24%.

</details>


### [19] [Cycle-Consistent Tuning for Layered Image Decomposition](https://arxiv.org/abs/2602.20989)
*Zheng Gu,Min Lu,Zhida Sun,Dani Lischinski,Daniel Cohen-O,Hui Huang*

Main category: cs.CV

TL;DR: 提出了一种基于扩散模型的图像分解方法，能够有效地从图像中分离出标志和背景，并具有良好的鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 视觉层解耦是视觉和图形领域的一个持续挑战，特别是在将标志从其出现的表面上分离出来时。

Method: 提出了一种利用大型扩散基础模型进行分层分离的上下文图像分解框架。通过轻量级LoRA调整微调预训练的扩散模型，并引入了循环一致调整策略，该策略联合训练分解和组合模型，强制执行分解和重组图像之间的重建一致性。此外，还引入了一个渐进式自我改进过程，该过程迭代地使用高质量的模型生成示例来增强训练集，以改进性能。

Result: 在大量实验中，该方法实现了准确和连贯的分解，并有效地推广到其他分解类型，表明它作为分层图像分解的统一框架的潜力。

Conclusion: 本研究提出了一种基于扩散模型的图像分解方法，能够有效地从图像中分离出标志和背景，并具有良好的鲁棒性和泛化能力。

Abstract: Disentangling visual layers in real-world images is a persistent challenge in vision and graphics, as such layers often involve non-linear and globally coupled interactions, including shading, reflection, and perspective distortion. In this work, we present an in-context image decomposition framework that leverages large diffusion foundation models for layered separation. We focus on the challenging case of logo-object decomposition, where the goal is to disentangle a logo from the surface on which it appears while faithfully preserving both layers. Our method fine-tunes a pretrained diffusion model via lightweight LoRA adaptation and introduces a cycle-consistent tuning strategy that jointly trains decomposition and composition models, enforcing reconstruction consistency between decomposed and recomposed images. This bidirectional supervision substantially enhances robustness in cases where the layers exhibit complex interactions. Furthermore, we introduce a progressive self-improving process, which iteratively augments the training set with high-quality model-generated examples to refine performance. Extensive experiments demonstrate that our approach achieves accurate and coherent decompositions and also generalizes effectively across other decomposition types, suggesting its potential as a unified framework for layered image decomposition.

</details>


### [20] [Le-DETR: Revisiting Real-Time Detection Transformer with Efficient Encoder Design](https://arxiv.org/abs/2602.21010)
*Jiannan Huang,Aditya Kane,Fengzhe Zhou,Yunchao Wei,Humphrey Shi*

Main category: cs.CV

TL;DR: 高效设计实现高性能实时DETR模型。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有实时目标检测模型难以复现的问题，以及降低预训练成本，提出了一种高效的设计方法。

Method: 研究了骨干架构，提出了EfficientNAT，重新设计了混合编码器，并提出了Le-DETR模型。

Result: Le-DETR在COCO Val2017上取得了52.9/54.3/55.1 mAP，速度优于YOLOv12和DEIM-D-FINE。

Conclusion: 通过高效设计和优化，实时DETR模型可以实现高性能且无需复杂预训练。

Abstract: Real-time object detection is crucial for real-world applications as it requires high accuracy with low latency. While Detection Transformers (DETR) have demonstrated significant performance improvements, current real-time DETR models are challenging to reproduce from scratch due to excessive pre-training overheads on the backbone, constraining research advancements by hindering the exploration of novel backbone architectures. In this paper, we want to show that by using general good design, it is possible to have \textbf{high performance} with \textbf{low pre-training cost}. After a thorough study of the backbone architecture, we propose EfficientNAT at various scales, which incorporates modern efficient convolution and local attention mechanisms. Moreover, we re-design the hybrid encoder with local attention, significantly enhancing both performance and inference speed. Based on these advancements, we present Le-DETR (\textbf{L}ow-cost and \textbf{E}fficient \textbf{DE}tection \textbf{TR}ansformer), which achieves a new \textbf{SOTA} in real-time detection using only ImageNet1K and COCO2017 training datasets, saving about 80\% images in pre-training stage compared with previous methods. We demonstrate that with well-designed, real-time DETR models can achieve strong performance without the need for complex and computationally expensive pretraining. Extensive experiments show that Le-DETR-M/L/X achieves \textbf{52.9/54.3/55.1 mAP} on COCO Val2017 with \textbf{4.45/5.01/6.68 ms} on an RTX4090. It surpasses YOLOv12-L/X by \textbf{+0.6/-0.1 mAP} while achieving similar speed and \textbf{+20\%} speedup. Compared with DEIM-D-FINE, Le-DETR-M achieves \textbf{+0.2 mAP} with slightly faster inference, and surpasses DEIM-D-FINE-L by \textbf{+0.4 mAP} with only \textbf{0.4 ms} additional latency. Code and weights will be open-sourced.

</details>


### [21] [From Perception to Action: An Interactive Benchmark for Vision Reasoning](https://arxiv.org/abs/2602.21015)
*Yuhao Wu,Maojia Song,Yihuai Lan,Lei Wang,Zhiqiang Hu,Yao Xiao,Heng Zhou,Weihua Zheng,Dylan Raharja,Soujanya Poria,Roy Ka-Wei Lee*

Main category: cs.CV

TL;DR: CHAIN基准评估VLM在物理结构和因果约束方面的能力，发现现有模型仍存在困难。


<details>
  <summary>Details</summary>
Motivation: 理解物理结构对于实际应用至关重要，但现有的VLM评估方法无法评估模型在动态环境中推理几何、接触和支撑关系的能力。

Method: 提出CHAIN基准，一个交互式的3D物理驱动测试平台，用于评估模型是否能够理解、规划和执行基于物理约束的结构化动作序列。

Result: 最先进的模型在理解物理结构和因果约束方面仍存在困难，往往无法产生可靠的长期计划，也无法将感知到的结构转换为有效的动作。

Conclusion: CHAIN基准为评估VLM和基于扩散的模型在理解物理结构和因果约束方面的能力提供了一个新的方法。

Abstract: Understanding the physical structure is essential for real-world applications such as embodied agents, interactive design, and long-horizon manipulation. Yet, prevailing Vision-Language Model (VLM) evaluations still center on structure-agnostic, single-turn setups (e.g., VQA), which fail to assess agents' ability to reason about how geometry, contact, and support relations jointly constrain what actions are possible in a dynamic environment. To address this gap, we introduce the Causal Hierarchy of Actions and Interactions (CHAIN) benchmark, an interactive 3D, physics-driven testbed designed to evaluate whether models can understand, plan, and execute structured action sequences grounded in physical constraints. CHAIN shifts evaluation from passive perception to active problem solving, spanning tasks such as interlocking mechanical puzzles and 3D stacking and packing. We conduct a comprehensive study of state-of-the-art VLMs and diffusion-based models under unified interactive settings. Our results show that top-performing models still struggle to internalize physical structure and causal constraints, often failing to produce reliable long-horizon plans and cannot robustly translate perceived structure into effective actions. The project is available at https://social-ai-studio.github.io/CHAIN/.

</details>


### [22] [MIP Candy: A Modular PyTorch Framework for Medical Image Processing](https://arxiv.org/abs/2602.21033)
*Tianhao Fu,Yucheng Chen*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Medical image processing demands specialized software that handles high-dimensional volumetric data, heterogeneous file formats, and domain-specific training procedures. Existing frameworks either provide low-level components that require substantial integration effort or impose rigid, monolithic pipelines that resist modification. We present MIP Candy (MIPCandy), a freely available, PyTorch-based framework designed specifically for medical image processing. MIPCandy provides a complete, modular pipeline spanning data loading, training, inference, and evaluation, allowing researchers to obtain a fully functional process workflow by implementing a single method, $\texttt{build_network}$, while retaining fine-grained control over every component. Central to the design is $\texttt{LayerT}$, a deferred configuration mechanism that enables runtime substitution of convolution, normalization, and activation modules without subclassing. The framework further offers built-in $k$-fold cross-validation, dataset inspection with automatic region-of-interest detection, deep supervision, exponential moving average, multi-frontend experiment tracking (Weights & Biases, Notion, MLflow), training state recovery, and validation score prediction via quotient regression. An extensible bundle ecosystem provides pre-built model implementations that follow a consistent trainer--predictor pattern and integrate with the core framework without modification. MIPCandy is open-source under the Apache-2.0 license and requires Python~3.12 or later. Source code and documentation are available at https://github.com/ProjectNeura/MIPCandy.

</details>


### [23] [OmniOCR: Generalist OCR for Ethnic Minority Languages](https://arxiv.org/abs/2602.21042)
*Bonan Liu,Zeyu Zhang,Bingbing Meng,Han Wang,Hanshuo Zhang,Chengping Wang,Daji Ergu,Ying Cai*

Main category: cs.CV

TL;DR: OmniOCR是一个通用的少数民族文字OCR框架，通过动态低秩自适应和稀疏正则化，实现了高效且参数高效的OCR任务。


<details>
  <summary>Details</summary>
Motivation: 由于少数民族语言的书写系统复杂、标注稀缺以及历史和现代形式的多样性，导致在低资源或零样本设置下的泛化具有挑战性。

Method: 提出了OmniOCR，这是一个适用于少数民族文字的通用框架。OmniOCR引入了动态低秩自适应（Dynamic LoRA）来分配模型容量跨层和脚本，从而实现有效的自适应并保留知识。稀疏正则化剪枝冗余更新，确保紧凑高效的适应，无需额外的推理成本。

Result: 在TibetanMNIST、Shui、古代彝语和东巴数据集上的评估表明，OmniOCR优于零样本基础模型和标准后训练，实现了最先进的准确率，具有优越的参数效率。与最先进的基线模型相比，在四个数据集上提高了39%-66%的准确率。

Conclusion: OmniOCR在少数民族文字的OCR任务中取得了显著的性能提升。

Abstract: Optical character recognition (OCR) has advanced rapidly with deep learning and multimodal models, yet most methods focus on well-resourced scripts such as Latin and Chinese. Ethnic minority languages remain underexplored due to complex writing systems, scarce annotations, and diverse historical and modern forms, making generalization in low-resource or zero-shot settings challenging. To address these challenges, we present OmniOCR, a universal framework for ethnic minority scripts. OmniOCR introduces Dynamic Low-Rank Adaptation (Dynamic LoRA) to allocate model capacity across layers and scripts, enabling effective adaptation while preserving knowledge.A sparsity regularization prunes redundant updates, ensuring compact and efficient adaptation without extra inference cost. Evaluations on TibetanMNIST, Shui, ancient Yi, and Dongba show that OmniOCR outperforms zero-shot foundation models and standard post training, achieving state-of-the-art accuracy with superior parameter efficiency, and compared with the state-of-the-art baseline models, it improves accuracy by 39%-66% on these four datasets. Code: https://github.com/AIGeeksGroup/OmniOCR.

</details>


### [24] [OCR-Agent: Agentic OCR with Capability and Memory Reflection](https://arxiv.org/abs/2602.21053)
*Shimin Wen,Zeyu Zhang,Xingdou Bian,Hongjie Zhu,Lulu He,Layi Shama,Daji Ergu,Ying Cai*

Main category: cs.CV

TL;DR: 通过能力反思和记忆反思，我们的新框架显著提高了VLMs的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有的VLMs缺乏有效的自我校正机制，难以独立纠正认知偏差。

Method: 我们提出了一种新的迭代自我校正框架，该框架赋予模型两个关键能力：能力反思和记忆反思。

Result: 在OCRBench v2基准测试中，我们的OCR-Agent在英语和中文子集上分别比当前的开源SOTA模型InternVL3-8B高+2.0和+1.2，同时在视觉理解（79.9）和推理（66.5）方面取得了最先进的成果。

Conclusion: 我们的方法通过结构化、自我意识的反刍可以显著增强VLMs的推理鲁棒性，无需额外训练。

Abstract: Large Vision-Language Models (VLMs) have demonstrated significant potential on complex visual understanding tasks through iterative optimization methods.However, these models generally lack effective self-correction mechanisms, making it difficult for them to independently rectify cognitive biases. Consequently, during multi-turn revisions, they often fall into repetitive and ineffective attempts, failing to achieve stable improvements in answer quality.To address this issue, we propose a novel iterative self-correction framework that endows models with two key capabilities: Capability Reflection and Memory Reflection. This framework guides the model to first diagnose errors and generate a correction plan via Capability Reflection, then leverage Memory Reflection to review past attempts to avoid repetition and explore new solutions, and finally, optimize the answer through rigorous re-reasoning. Experiments on the challenging OCRBench v2 benchmark show that OCR-Agent outperforms the current open-source SOTA model InternVL3-8B by +2.0 on English and +1.2 on Chinese subsets, while achieving state-of-the-art results in Visual Understanding (79.9) and Reasoning (66.5) - surpassing even larger fine-tuned models. Our method demonstrates that structured, self-aware reflection can significantly enhance VLMs' reasoning robustness without additional training. Code: https://github.com/AIGeeksGroup/OCR-Agent.

</details>


### [25] [Optimizing Occupancy Sensor Placement in Smart Environments](https://arxiv.org/abs/2602.21098)
*Hao Lu,Richard J. Radke*

Main category: cs.CV

TL;DR: 提出了一种基于ILP的自动传感器放置方法，用于提高占用区域计数精度。


<details>
  <summary>Details</summary>
Motivation: 实现节能，通过在需要的地方提供照明、供暖和冷却，了解商业建筑环境中居民的位置至关重要。

Method: 提出了一种自动传感器放置方法，该方法确定给定数量传感器的最佳布局，并可以预测此类布局的计数精度。将传感器放置问题建模为整数线性规划（ILP）问题，并使用分支定界法解决。

Result: 基于对多个不同办公环境的模拟，证明了所提出方法的有效性。

Conclusion: 该研究提出了一种有效的方法，可以实时识别区域占用情况，同时不影响居民的日常活动或侵犯隐私。

Abstract: Understanding the locations of occupants in a commercial built environment is critical for realizing energy savings by delivering lighting, heating, and cooling only where it is needed. The key to achieving this goal is being able to recognize zone occupancy in real time, without impeding occupants' activities or compromising privacy. While low-resolution, privacy-preserving time-of-flight (ToF) sensor networks have demonstrated good performance in zone counting, the performance depends on careful sensor placement. To address this issue, we propose an automatic sensor placement method that determines optimal sensor layouts for a given number of sensors, and can predict the counting accuracy of such a layout. In particular, given the geometric constraints of an office environment, we simulate a large number of occupant trajectories. We then formulate the sensor placement problem as an integer linear programming (ILP) problem and solve it with the branch and bound method. We demonstrate the effectiveness of the proposed method based on simulations of several different office environments.

</details>


### [26] [SynthRender and IRIS: Open-Source Framework and Dataset for Bidirectional Sim-Real Transfer in Industrial Object Perception](https://arxiv.org/abs/2602.21141)
*Jose Moises Araya-Martinez,Thushar Tom,Adrián Sanchis Reig,Pablo Rey Valiente,Jens Lambrecht,Jörg Krüger*

Main category: cs.CV

TL;DR: SynthRender和IRIS在物体感知模型中提高了性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决现代监督深度学习感知模型在半受控条件下需要大量数据集的问题，提出了一种开源框架SynthRender，用于合成图像生成，并引入了IRIS数据集。

Method: 开发了一个开源框架SynthRender，用于合成图像生成，并引入了IRIS数据集，包含32个类别，约20000个标签。通过在多个基准测试中进行消融实验，验证了SynthRender的有效性。

Result: SynthRender在公共机器人数据集上达到了99.1%的mAP@50，在汽车基准测试上达到了98.3%的mAP@50，在IRIS数据集上达到了95.3%的mAP@50。

Conclusion: SynthRender框架和IRIS数据集在提高物体感知模型的性能方面具有显著效果。

Abstract: Object perception is fundamental for tasks such as robotic material handling and quality inspection. However, modern supervised deep-learning perception models require large datasets for robust automation under semi-uncontrolled conditions. The cost of acquiring and annotating such data for proprietary parts is a major barrier for widespread deployment. In this context, we release SynthRender, an open source framework for synthetic image generation with Guided Domain Randomization capabilities. Furthermore, we benchmark recent Reality-to-Simulation techniques for 3D asset creation from 2D images of real parts. Combined with Domain Randomization, these synthetic assets provide low-overhead, transferable data even for parts lacking 3D files. We also introduce IRIS, the Industrial Real-Sim Imagery Set, containing 32 categories with diverse textures, intra-class variation, strong inter-class similarities and about 20,000 labels. Ablations on multiple benchmarks outline guidelines for efficient data generation with SynthRender. Our method surpasses existing approaches, achieving 99.1% mAP@50 on a public robotics dataset, 98.3% mAP@50 on an automotive benchmark, and 95.3% mAP@50 on IRIS.

</details>


### [27] [Seeing Through Words: Controlling Visual Retrieval Quality with Language Models](https://arxiv.org/abs/2602.21175)
*Jianglin Lu,Simon Jenni,Kushal Kafle,Jing Shi,Handong Zhao,Yun Fu*

Main category: cs.CV

TL;DR: 提出一种新的质量可控的文本到图像检索方法，通过使用生成式语言模型来丰富短查询，从而提高检索结果和图像质量。


<details>
  <summary>Details</summary>
Motivation: 针对短和模糊的用户查询，提出一种新的质量可控检索方法，以丰富短查询并引入图像质量的概念。

Method: 利用生成式语言模型作为查询补全函数，将不明确的查询扩展为描述性形式，以捕捉细粒度的视觉属性，如姿态、场景和美学。

Result: 实验表明，该方法提高了检索结果，并提供了有效的质量控制。

Conclusion: 提出的质量可控检索方法显著提高了检索结果，并提供了有效的质量控制，弥合了现代VLM的表达能力与短用户查询的不明确性之间的差距。

Abstract: Text-to-image retrieval is a fundamental task in vision-language learning, yet in real-world scenarios it is often challenged by short and underspecified user queries. Such queries are typically only one or two words long, rendering them semantically ambiguous, prone to collisions across diverse visual interpretations, and lacking explicit control over the quality of retrieved images. To address these issues, we propose a new paradigm of quality-controllable retrieval, which enriches short queries with contextual details while incorporating explicit notions of image quality. Our key idea is to leverage a generative language model as a query completion function, extending underspecified queries into descriptive forms that capture fine-grained visual attributes such as pose, scene, and aesthetics. We introduce a general framework that conditions query completion on discretized quality levels, derived from relevance and aesthetic scoring models, so that query enrichment is not only semantically meaningful but also quality-aware. The resulting system provides three key advantages: 1) flexibility, it is compatible with any pretrained vision-language model (VLMs) without modification; 2) transparency, enriched queries are explicitly interpretable by users; and 3) controllability, enabling retrieval results to be steered toward user-preferred quality levels. Extensive experiments demonstrate that our proposed approach significantly improves retrieval results and provides effective quality control, bridging the gap between the expressive capacity of modern VLMs and the underspecified nature of short user queries. Our code is available at https://github.com/Jianglin954/QCQC.

</details>


### [28] [Mask-HybridGNet: Graph-based segmentation with emergent anatomical correspondence from pixel-level supervision](https://arxiv.org/abs/2602.21179)
*Nicolás Gaggion,Maria J. Ledesma-Carbayo,Stergios Christodoulidis,Maria Vakalopoulou,Enzo Ferrante*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Graph-based medical image segmentation represents anatomical structures using boundary graphs, providing fixed-topology landmarks and inherent population-level correspondences. However, their clinical adoption has been hindered by a major requirement: training datasets with manually annotated landmarks that maintain point-to-point correspondences across patients rarely exist in practice. We introduce Mask-HybridGNet, a framework that trains graph-based models directly using standard pixel-wise masks, eliminating the need for manual landmark annotations. Our approach aligns variable-length ground truth boundaries with fixed-length landmark predictions by combining Chamfer distance supervision and edge-based regularization to ensure local smoothness and regular landmark distribution, further refined via differentiable rasterization. A significant emergent property of this framework is that predicted landmark positions become consistently associated with specific anatomical locations across patients without explicit correspondence supervision. This implicit atlas learning enables temporal tracking, cross-slice reconstruction, and morphological population analyses. Beyond direct segmentation, Mask-HybridGNet can extract correspondences from existing segmentation masks, allowing it to generate stable anatomical atlases from any high-quality pixel-based model. Experiments across chest radiography, cardiac ultrasound, cardiac MRI, and fetal imaging demonstrate that our model achieves competitive results against state-of-the-art pixel-based methods, while ensuring anatomical plausibility by enforcing boundary connectivity through a fixed graph adjacency matrix. This framework leverages the vast availability of standard segmentation masks to build structured models that maintain topological integrity and provide implicit correspondences.

</details>


### [29] [Spa3R: Predictive Spatial Field Modeling for 3D Visual Reasoning](https://arxiv.org/abs/2602.21186)
*Haoyi Jiang,Liu Liu,Xinjie Wang,Yonghao He,Wei Sui,Zhizhong Su,Wenyu Liu,Xinggang Wang*

Main category: cs.CV

TL;DR: Spa3R通过PSFM在3D VQA上取得突破。


<details>
  <summary>Details</summary>
Motivation: 空间智能应该从2D视觉中内在地产生，而不是通过显式空间指令调整。

Method: Spa3R，一个自监督框架，直接从未摆放的多视角图像学习统一的、视角不变的空间表示。

Result: Spa3-VLM在3D VQA上实现了58.6%的准确率，显著优于先前方法。

Conclusion: PSFM是提高空间智能的可扩展路径。

Abstract: While Vision-Language Models (VLMs) exhibit exceptional 2D visual understanding, their ability to comprehend and reason about 3D space--a cornerstone of spatial intelligence--remains superficial. Current methodologies attempt to bridge this domain gap either by relying on explicit 3D modalities or by augmenting VLMs with partial, view-conditioned geometric priors. However, such approaches hinder scalability and ultimately burden the language model with the ill-posed task of implicitly reconstructing holistic 3D geometry from sparse cues. In this paper, we argue that spatial intelligence can emerge inherently from 2D vision alone, rather than being imposed via explicit spatial instruction tuning. To this end, we introduce Spa3R, a self-supervised framework that learns a unified, view-invariant spatial representation directly from unposed multi-view images. Spa3R is built upon the proposed Predictive Spatial Field Modeling (PSFM) paradigm, where Spa3R learns to synthesize feature fields for arbitrary unseen views conditioned on a compact latent representation, thereby internalizing a holistic and coherent understanding of the underlying 3D scene. We further integrate the pre-trained Spa3R Encoder into existing VLMs via a lightweight adapter to form Spa3-VLM, effectively grounding language reasoning in a global spatial context. Experiments on the challenging VSI-Bench demonstrate that Spa3-VLM achieves state-of-the-art accuracy of 58.6% on 3D VQA, significantly outperforming prior methods. These results highlight PSFM as a scalable path toward advancing spatial intelligence. Code is available at https://github.com/hustvl/Spa3R.

</details>


### [30] [Region of Interest Segmentation and Morphological Analysis for Membranes in Cryo-Electron Tomography](https://arxiv.org/abs/2602.21195)
*Xingyi Cheng,Julien Maufront,Aurélie Di Cicco,Daniël M. Pelt,Manuela Dezi,Daniel Lévy*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Cryo-electron tomography (cryo-ET) enables high resolution, three-dimensional reconstruction of biological structures, including membranes and membrane proteins. Identification of regions of interest (ROIs) is central to scientific imaging, as it enables isolation and quantitative analysis of specific structural features within complex datasets. In practice, however, ROIs are typically derived indirectly through full structure segmentation followed by post hoc analysis. This limitation is especially apparent for continuous and geometrically complex structures such as membranes, which are segmented as single entities. Here, we developed TomoROIS-SurfORA, a two step framework for direct, shape-agnostic ROI segmentation and morphological surface analysis. TomoROIS performs deep learning-based ROI segmentation and can be trained from scratch using small annotated datasets, enabling practical application across diverse imaging data. SurfORA processes segmented structures as point clouds and surface meshes to extract quantitative morphological features, including inter-membrane distances, curvature, and surface roughness. It supports both closed and open surfaces, with specific considerations for open surfaces, which are common in cryo-ET due to the missing wedge effect. We demonstrate both tools using in vitro reconstituted membrane systems containing deformable vesicles with complex geometries, enabling automatic quantitative analysis of membrane contact sites and remodeling events such as invagination. While demonstrated here on cryo-ET membrane data, the combined approach is applicable to ROI detection and surface analysis in broader scientific imaging contexts.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [31] [Talking to Yourself: Defying Forgetting in Large Language Models](https://arxiv.org/abs/2602.20162)
*Yutao Sun,Mingshuai Chen,Tiancheng Zhao,Phillip Miao,Zilun Zhang,Haozhan Shen,Ruizhe Zhu,Jianwei Yin*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Catastrophic forgetting remains a major challenge when fine-tuning large language models (LLMs) on narrow, task-specific data, often degrading their general knowledge and reasoning abilities. We propose SA-SFT, a lightweight self-augmentation routine in which an LLM generates self-dialogues prior to fine-tuning, and the resulting self-authored data are mixed with task data without modifying optimization or training schedules.
  Despite requiring no external data or additional tuning, SA-SFT consistently mitigates catastrophic forgetting while improving in-domain performance. Across 50 evaluation scenarios, it maintains performance comparable to the original model and achieves the best results in 40 cases, outperforming common baselines such as layer freezing and external data mixing. Guided by these empirical findings, we further present a theoretical analysis suggesting that forgetting can partly stem from style-induced parameter drift, and that self-alignment through self-generated data provides an effective means to counteract this effect. Overall, our results indicate that self-augmentation offers a simple and effective mechanism for robust LLM adaptation without incurring catastrophic forgetting.

</details>


### [32] [InterviewSim: A Scalable Framework for Interview-Grounded Personality Simulation](https://arxiv.org/abs/2602.20294)
*Yu Li,Pranav Narayanan Venkit,Yada Pruksachatkun,Chien-Sheng Wu*

Main category: cs.CL

TL;DR: 提出了一种基于访谈的大规模个性模拟评估框架，基于真实访谈数据的方法优于其他方法。


<details>
  <summary>Details</summary>
Motivation: 为了模拟真实的个性，需要将生成过程建立在真实的个人数据基础上。

Method: 提出了一种基于访谈的大规模个性模拟评估框架。从1,000位公共人物中提取了23,000个经过验证的访谈记录，共671,000个问答对。提出了一个包含四个维度的评估框架：内容相似度、事实一致性、个性匹配和事实知识保留。

Result: 基于真实访谈数据的方法在内容相似度、事实一致性、个性匹配和事实知识保留方面显著优于仅依赖传记资料或模型参数知识的方法。

Conclusion: 该评估框架可以基于应用需求进行原则性的方法选择，为个性模拟研究提供了可操作的见解。

Abstract: Simulating real personalities with large language models requires grounding generation in authentic personal data. Existing evaluation approaches rely on demographic surveys, personality questionnaires, or short AI-led interviews as proxies, but lack direct assessment against what individuals actually said. We address this gap with an interview-grounded evaluation framework for personality simulation at a large scale. We extract over 671,000 question-answer pairs from 23,000 verified interview transcripts across 1,000 public personalities, each with an average of 11.5 hours of interview content. We propose a multi-dimensional evaluation framework with four complementary metrics measuring content similarity, factual consistency, personality alignment, and factual knowledge retention. Through systematic comparison, we demonstrate that methods grounded in real interview data substantially outperform those relying solely on biographical profiles or the model's parametric knowledge. We further reveal a trade-off in how interview data is best utilized: retrieval-augmented methods excel at capturing personality style and response quality, while chronological-based methods better preserve factual consistency and knowledge retention. Our evaluation framework enables principled method selection based on application requirements, and our empirical findings provide actionable insights for advancing personality simulation research.

</details>


### [33] [What Makes a Good Query? Measuring the Impact of Human-Confusing Linguistic Features on LLM Performance](https://arxiv.org/abs/2602.20300)
*William Watson,Nicole Cho,Sumitra Ganesh,Manuela Veloso*

Main category: cs.CL

TL;DR: 研究揭示查询特征与LLM幻觉风险的相关性。


<details>
  <summary>Details</summary>
Motivation: 研究LLM幻觉问题，探讨查询形式对模型响应的影响。

Method: 构建22维查询特征向量，分析369,837个真实查询，揭示查询特征与幻觉风险的关系。

Result: 发现某些查询特征（如深层嵌套从句和下定义不充分）与更高的幻觉倾向相关，而明确的意图接地和可回答性与更低的幻觉率相关。

Conclusion: 查询特征与幻觉风险之间存在相关性，为引导查询重写和未来干预研究提供依据。

Abstract: Large Language Model (LLM) hallucinations are usually treated as defects of the model or its decoding strategy. Drawing on classical linguistics, we argue that a query's form can also shape a listener's (and model's) response. We operationalize this insight by constructing a 22-dimension query feature vector covering clause complexity, lexical rarity, and anaphora, negation, answerability, and intention grounding, all known to affect human comprehension. Using 369,837 real-world queries, we ask: Are there certain types of queries that make hallucination more likely? A large-scale analysis reveals a consistent "risk landscape": certain features such as deep clause nesting and underspecification align with higher hallucination propensity. In contrast, clear intention grounding and answerability align with lower hallucination rates. Others, including domain specificity, show mixed, dataset- and model-dependent effects. Thus, these findings establish an empirically observable query-feature representation correlated with hallucination risk, paving the way for guided query rewriting and future intervention studies.

</details>


### [34] [No One Size Fits All: QueryBandits for Hallucination Mitigation](https://arxiv.org/abs/2602.20332)
*Nicole Cho,William Watson,Alec Koppel,Sumitra Ganesh,Manuela Veloso*

Main category: cs.CL

TL;DR: QueryBandits 是一种有效的 LLM 幻觉缓解方法，适用于闭源模型。


<details>
  <summary>Details</summary>
Motivation: LLMs 在推理能力提升的同时，出现了更频繁的幻觉现象。大多数缓解工作集中在开源模型的后处理检测和参数编辑上。然而，针对闭源模型幻觉的研究却很少，而闭源模型在机构部署中占绝大多数。

Method: 提出了一种名为 QueryBandits 的模型无关的上下文赌博框架，通过利用经验验证和校准的奖励函数，自适应地在线学习选择最优查询重写策略。

Result: 在 16 个问答场景中，QueryBandit（Thompson Sampling）的胜率达到 87.5%，超过无重写基线，分别比零样本静态策略（如释义或扩展）高 42.6% 和 60.3%。此外，所有上下文赌博在所有数据集上都优于传统赌博，特征方差越大，臂选择方差也越大。这证实了没有单一的重写策略对所有查询都最优。还发现某些静态策略的累积后悔更高，表明僵化的查询重写策略会加剧幻觉。通过 QueryBandits 在语义特征上学习在线策略，可以通过前向传递机制纯粹地改变模型行为，使其适用于闭源模型，无需重新训练或基于梯度的适应。

Conclusion: QueryBandits 可以有效地减少 LLMs 中的幻觉现象，并适用于闭源模型，无需重新训练或基于梯度的适应。

Abstract: Advanced reasoning capabilities in Large Language Models (LLMs) have led to more frequent hallucinations; yet most mitigation work focuses on open-source models for post-hoc detection and parameter editing. The dearth of studies focusing on hallucinations in closed-source models is especially concerning, as they constitute the vast majority of models in institutional deployments. We introduce QueryBandits, a model-agnostic contextual bandit framework that adaptively learns online to select the optimal query-rewrite strategy by leveraging an empirically validated and calibrated reward function. Across 16 QA scenarios, our top QueryBandit (Thompson Sampling) achieves an 87.5% win rate over a No-Rewrite baseline and outperforms zero-shot static policies (e.g., Paraphrase or Expand) by 42.6% and 60.3%, respectively. Moreover, all contextual bandits outperform vanilla bandits across all datasets, with higher feature variance coinciding with greater variance in arm selection. This substantiates our finding that there is no single rewrite policy optimal for all queries. We also discover that certain static policies incur higher cumulative regret than No-Rewrite, indicating that an inflexible query-rewriting policy can worsen hallucinations. Thus, learning an online policy over semantic features with QueryBandits can shift model behavior purely through forward-pass mechanisms, enabling its use with closed-source models and bypassing the need for retraining or gradient-based adaptation.

</details>


### [35] [Natural Language Processing Models for Robust Document Categorization](https://arxiv.org/abs/2602.20336)
*Radoslaw Roszczyk,Pawel Tecza,Maciej Stodolski,Krzysztof Siwek*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This article presents an evaluation of several machine learning methods applied to automated text classification, alongside the design of a demonstrative system for unbalanced document categorization and distribution. The study focuses on balancing classification accuracy with computational efficiency, a key consideration when integrating AI into real world automation pipelines. Three models of varying complexity were examined: a Naive Bayes classifier, a bidirectional LSTM network, and a fine tuned transformer based BERT model.
  The experiments reveal substantial differences in performance. BERT achieved the highest accuracy, consistently exceeding 99\%, but required significantly longer training times and greater computational resources. The BiLSTM model provided a strong compromise, reaching approximately 98.56\% accuracy while maintaining moderate training costs and offering robust contextual understanding. Naive Bayes proved to be the fastest to train, on the order of milliseconds, yet delivered the lowest accuracy, averaging around 94.5\%. Class imbalance influenced all methods, particularly in the recognition of minority categories.
  A fully functional demonstrative system was implemented to validate practical applicability, enabling automated routing of technical requests with throughput unattainable through manual processing. The study concludes that BiLSTM offers the most balanced solution for the examined scenario, while also outlining opportunities for future improvements and further exploration of transformer architectures.

</details>


### [36] [Disentangling Geometry, Performance, and Training in Language Models](https://arxiv.org/abs/2602.20433)
*Atharva Kulkarni,Jacob Mitchell Springer,Arjun Subramonian,Swabha Swayamdipta*

Main category: cs.CL

TL;DR: 研究Transformer权重几何属性与模型性能之间的关系，发现现有指标主要反映训练选择，而非性能。


<details>
  <summary>Details</summary>
Motivation: 研究Transformer权重（尤其是unembedding矩阵）的几何属性在语言模型可解释性研究中的应用，以及这些属性对下游性能估计的效用。

Method: 通过在受控变异下训练一系列108个OLMo风格的语料模型，系统研究模型性能与unembedding矩阵几何属性（尤其是其有效秩）之间的关系。

Result: 发现最佳性能模型通常具有高有效秩，但这种趋势并非在所有任务和训练设置中都存在。低有效秩不会导致小型模型后期性能下降，而是与其共存；发现低秩模型不会出现饱和。有效秩受预训练超参数（如批大小和权重衰减）的强烈影响，这些超参数反过来又影响模型性能。扩展分析到其他几何指标和最终层表示，发现这些指标在很大程度上是一致的，但没有任何一个可以可靠地预测下游性能。

Conclusion: 模型的几何属性（由现有指标捕捉）主要反映训练选择，而不是性能。

Abstract: Geometric properties of Transformer weights, particularly the unembedding matrix, have been widely useful in language model interpretability research. Yet, their utility for estimating downstream performance remains unclear. In this work, we systematically investigate the relationship between model performance and the unembedding matrix geometry, particularly its effective rank. Our experiments, involving a suite of 108 OLMo-style language models trained under controlled variation, reveal several key findings. While the best-performing models often exhibit a high effective rank, this trend is not universal across tasks and training setups. Contrary to prior work, we find that low effective rank does not cause late-stage performance degradation in small models, but instead co-occurs with it; we find adversarial cases where low-rank models do not exhibit saturation. Moreover, we show that effective rank is strongly influenced by pre-training hyperparameters, such as batch size and weight decay, which in-turn affect the model's performance. Lastly, extending our analysis to other geometric metrics and final-layer representation, we find that these metrics are largely aligned, but none can reliably predict downstream performance. Overall, our findings suggest that the model's geometry, as captured by existing metrics, primarily reflects training choices rather than performance.

</details>


### [37] [Personal Information Parroting in Language Models](https://arxiv.org/abs/2602.20580)
*Nishant Subramani,Kshitish Ghate,Mona Diab*

Main category: cs.CL

TL;DR: 研究显示大型语言模型可能记住大量个人信息，建议对数据集进行严格过滤。


<details>
  <summary>Details</summary>
Motivation: 现代语言模型在训练过程中可能会记住大量个人信息，增加了隐私风险。

Method: 开发了一个正则表达式和规则（R&R）检测器套件来检测电子邮件地址、电话号码和IP地址。

Result: 在手动编纂的483个个人信息实例集中，发现13.6%被Pythia-6.9b模型原封不动地重复。模型大小和预训练时间与记忆能力正相关。

Conclusion: 强烈建议对预训练数据集进行严格过滤和匿名化，以最小化个人信息重复。

Abstract: Modern language models (LM) are trained on large scrapes of the Web, containing millions of personal information (PI) instances, many of which LMs memorize, increasing privacy risks. In this work, we develop the regexes and rules (R&R) detector suite to detect email addresses, phone numbers, and IP addresses, which outperforms the best regex-based PI detectors. On a manually curated set of 483 instances of PI, we measure memorization: finding that 13.6% are parroted verbatim by the Pythia-6.9b model, i.e., when the model is prompted with the tokens that precede the PI in the original document, greedy decoding generates the entire PI span exactly. We expand this analysis to study models of varying sizes (160M-6.9B) and pretraining time steps (70k-143k iterations) in the Pythia model suite and find that both model size and amount of pretraining are positively correlated with memorization. Even the smallest model, Pythia-160m, parrots 2.7% of the instances exactly. Consequently, we strongly recommend that pretraining datasets be aggressively filtered and anonymized to minimize PI parroting.

</details>


### [38] [FinAnchor: Aligned Multi-Model Representations for Financial Prediction](https://arxiv.org/abs/2602.20859)
*Zirui He,Huopu Zhang,Yanguang Liu,Sirui Wu,Mengnan Du*

Main category: cs.CL

TL;DR: FinAnchor通过锚定异构表示，提高了金融预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 金融预测从长文档中涉及重大挑战，因为可操作信号通常稀疏且被噪声所掩盖，且最优的LLM用于生成嵌入随任务和时间而变化。

Method: 提出FinAnchor（金融锚定表示）框架，集成多个LLM的嵌入，无需微调底层模型。通过选择锚嵌入空间并学习线性映射来对齐其他模型的表示。

Result: 在多个金融NLP任务中，FinAnchor优于强单模型基线和标准集成方法，证明了锚定异构表示对稳健金融预测的有效性。

Conclusion: FinAnchor框架通过锚定异构表示，有效提高了金融预测的准确性。

Abstract: Financial prediction from long documents involves significant challenges, as actionable signals are often sparse and obscured by noise, and the optimal LLM for generating embeddings varies across tasks and time periods. In this paper, we propose FinAnchor(Financial Anchored Representations), a lightweight framework that integrates embeddings from multiple LLMs without fine-tuning the underlying models. FinAnchor addresses the incompatibility of feature spaces by selecting an anchor embedding space and learning linear mappings to align representations from other models into this anchor. These aligned features are then aggregated to form a unified representation for downstream prediction. Across multiple financial NLP tasks, FinAnchor consistently outperforms strong single-model baselines and standard ensemble methods, demonstrating the effectiveness of anchoring heterogeneous representations for robust financial prediction.

</details>


### [39] [Exa-PSD: a new Persian sentiment analysis dataset on Twitter](https://arxiv.org/abs/2602.20892)
*Seyed Himan Ghaderi,Saeed Sarbazi Azad,Mohammad Mehdi Jaziriyan,Ahmad Akbari*

Main category: cs.CL

TL;DR: 提出Exa波斯语情感分析数据集，用于评估情感分析系统，宏F分数为79.87。


<details>
  <summary>Details</summary>
Motivation: 为了克服波斯语自然语言处理中的挑战，需要创建一个波斯语情感分析数据集。

Method: 收集了12,000条波斯语推文，由5名波斯语母语者标注，分为积极、中立和消极三类。使用预训练的Pars Bert和Roberta作为基础模型进行评估。

Result: 实现了79.87的宏F分数，表明模型和数据对于情感分析系统具有足够的价值。

Conclusion: 提出了Exa情感分析波斯语数据集，对波斯语情感分析系统具有重要价值。

Abstract: Today, Social networks such as Twitter are the most widely used platforms for communication of people. Analyzing this data has useful information to recognize the opinion of people in tweets. Sentiment analysis plays a vital role in NLP, which identifies the opinion of the individuals about a specific topic. Natural language processing in Persian has many challenges despite the adventure of strong language models. The datasets available in Persian are generally in special topics such as products, foods, hotels, etc while users may use ironies, colloquial phrases in social media To overcome these challenges, there is a necessity for having a dataset of Persian sentiment analysis on Twitter. In this paper, we introduce the Exa sentiment analysis Persian dataset, which is collected from Persian tweets. This dataset contains 12,000 tweets, annotated by 5 native Persian taggers. The aforementioned data is labeled in 3 classes: positive, neutral and negative. We present the characteristics and statistics of this dataset and use the pre-trained Pars Bert and Roberta as the base model to evaluate this dataset. Our evaluation reached a 79.87 Macro F-score, which shows the model and data can be adequately valuable for a sentiment analysis system.

</details>


### [40] [The Art of Efficient Reasoning: Data, Reward, and Optimization](https://arxiv.org/abs/2602.20945)
*Taiqiang Wu,Zenan Zu,Bo Zhou,Ngai Wong*

Main category: cs.CL

TL;DR: 本研究系统地研究了大型语言模型高效推理的机制，发现了一些关键发现，为提高推理效率和泛化能力提供了新的思路。


<details>
  <summary>Details</summary>
Motivation: 为了解决大型语言模型在推理过程中存在的计算开销问题，我们提出了高效推理的方法。

Method: 我们系统地研究了高效推理的机制，包括对训练过程、奖励塑造和优化策略进行深入分析。我们还进行了大量的实验来验证我们的发现。

Result: 我们提出了一个统一协议，对训练提示、输出、奖励塑造和优化策略进行了深入分析，并发现了一些关键的发现，如长度适应和推理细化，以及长度偏差的泛化能力。

Conclusion: 我们发现训练过程遵循两阶段范式：长度适应和推理细化。我们还发现，在相对较容易的提示上进行训练可以确保正奖励信号的密度，从而避免长度崩溃。此外，学习到的长度偏差可以跨领域泛化。

Abstract: Large Language Models (LLMs) consistently benefit from scaled Chain-of-Thought (CoT) reasoning, but also suffer from heavy computational overhead. To address this issue, efficient reasoning aims to incentivize short yet accurate thinking trajectories, typically through reward shaping with Reinforcement Learning (RL). In this paper, we systematically investigate the mechanics of efficient reasoning for LLMs. For comprehensive evaluation, we advocate for more fine-grained metrics, including length distribution conditioned on correctness and performance across a wide spectrum of token budgets ranging from 2k to 32k. First, we reveal that the training process follows a two-stage paradigm: length adaptation and reasoning refinement. After that, we conduct extensive experiments (about 0.2 million GPU hours) in a unified protocol, deconstructing training prompts and rollouts, reward shaping, and optimization strategies. In particular, a key finding is to train on relatively easier prompts, ensuring the density of positive reward signals and thus avoiding the length collapse. Meanwhile, the learned length bias can be generalized across domains. We distill all findings into valuable insights and practical guidelines, and further validate them across the Qwen3 series, ranging from 0.6B to 30B, demonstrating the robustness and generalization.

</details>


### [41] [Blackbird Language Matrices: A Framework to Investigate the Linguistic Competence of Language Models](https://arxiv.org/abs/2602.20966)
*Paola Merlo,Chunyang Jiang,Giuseppe Samo,Vivi Nastase*

Main category: cs.CL

TL;DR: 本文提出黑鸟语言矩阵任务，评估大型语言模型的语言理解能力，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 分析当前大型语言模型的能力，例如检测语言对象及其属性、检测和使用句子之间的系统性模式、以及语言或推理错误倾向及其交互作用。

Method: 提出黑鸟语言矩阵（BLM）任务，包括数据集的构建和基准测试，以及对分块和系统性进行的针对性实验。

Result: BLMs 在多个语言中可以以良好的性能解决，简单基线模型或更定制的模型均适用。这些表示包含与解决语言任务相关的语法对象和属性，通过检测句子间的系统性模式得出解决方案。

Conclusion: BLMs 有助于支持对语言和大型语言模型特性的多方面研究，有助于解释大型语言模型的行为。

Abstract: This article describes a novel language task, the Blackbird Language Matrices (BLM) task, inspired by intelligence tests, and illustrates the BLM datasets, their construction and benchmarking, and targeted experiments on chunking and systematicity. BLMs are multiple-choice problems, structured at multiple levels: within each sentence, across the input sequence, within each candidate answer. Because of their rich structure, these curated, but naturalistic datasets are key to answer some core questions about current large language models abilities: do LLMs detect linguistic objects and their properties? Do they detect and use systematic patterns across sentences? Are they more prone to linguistic or reasoning errors, and how do these interact?
  We show that BLMs, while challenging, can be solved at good levels of performance, in more than one language, with simple baseline models or, at better performance levels, with more tailored models. We show that their representations contain the grammatical objects and attributes relevant to solve a linguistic task. We also show that these solutions are reached by detecting systematic patterns across sentences.
  The paper supports the point of view that curated, structured datasets support multi-faceted investigations of properties of language and large language models. Because they present a curated, articulated structure, because they comprise both learning contexts and expected answers, and because they are partly built by hand, BLMs fall in the category of datasets that can support explainability investigations, and be useful to ask why large language models behave the way they do.

</details>


### [42] [Evaluating Proactive Risk Awareness of Large Language Models](https://arxiv.org/abs/2602.20976)
*Xuan Luo,Yubin Chen,Zhiyu Hou,Linpu Yu,Geng Tu,Jing Li,Ruifeng Xu*

Main category: cs.CL

TL;DR: 研究提出了一种评估LLMs主动风险意识的框架，发现现有模型在生态责任方面存在差距，需要主动保障措施。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）在日常决策中的广泛应用，其安全责任不仅限于对有害意图的响应，还应扩展到预测可能的不当但具有后果的风险。

Method: 提出了一种主动风险意识评估框架，构建了Butterfly数据集，并通过五个广泛使用的LLMs进行实验，分析了响应长度、语言和模态的影响。

Result: 实验结果表明，在长度限制的响应、跨语言相似性和（多模态）物种保护中的持续盲点下，主动意识显著下降。

Conclusion: 这些发现突显了当前安全对齐与实际生态责任要求之间的关键差距，强调了在LLMs部署中实施主动保障措施的需求。

Abstract: As large language models (LLMs) are increasingly embedded in everyday decision-making, their safety responsibilities extend beyond reacting to explicit harmful intent toward anticipating unintended but consequential risks. In this work, we introduce a proactive risk awareness evaluation framework that measures whether LLMs can anticipate potential harms and provide warnings before damage occurs. We construct the Butterfly dataset to instantiate this framework in the environmental and ecological domain. It contains 1,094 queries that simulate ordinary solution-seeking activities whose responses may induce latent ecological impact. Through experiments across five widely used LLMs, we analyze the effects of response length, languages, and modality. Experimental results reveal consistent, significant declines in proactive awareness under length-restricted responses, cross-lingual similarities, and persistent blind spots in (multimodal) species protection. These findings highlight a critical gap between current safety alignment and the requirements of real-world ecological responsibility, underscoring the need for proactive safeguards in LLM deployment.

</details>


### [43] [Prompt-Level Distillation: A Non-Parametric Alternative to Model Fine-Tuning for Efficient Reasoning](https://arxiv.org/abs/2602.21103)
*Sanket Badhe,Deep Shah*

Main category: cs.CL

TL;DR: PLD通过提取推理模式并组织成指令列表，提高了模型的性能和可解释性，适用于需要高准确性和透明度的行业和场景。


<details>
  <summary>Details</summary>
Motivation: 高级推理通常需要思维链提示，但这种方法准确但延迟高，推理成本高。微调小模型虽然是一种替代方案，但牺牲了可解释性，并引入了显著的资源和操作开销。为了解决这些限制，我们引入了提示级蒸馏（PLD）。

Method: 从教师模型中提取显式推理模式，并将其组织成结构化的指令列表，供学生模型的系统提示使用。

Result: 在StereoSet和Contract-NLI数据集上使用Gemma-3 4B进行评估，PLD将宏观F1分数从57%提高到90.0%，从67%提高到83%。

Conclusion: PLD使紧凑型模型能够以可忽略的延迟开销匹配前沿性能，这些表达性指令使决策过程透明，允许对逻辑进行完全的人类验证，因此该方法非常适合法律、金融和内容审核等监管行业，以及高容量使用场景和边缘设备。

Abstract: Advanced reasoning typically requires Chain-of-Thought prompting, which is accurate but incurs prohibitive latency and substantial test-time inference costs. The standard alternative, fine-tuning smaller models, often sacrifices interpretability while introducing significant resource and operational overhead. To address these limitations, we introduce Prompt-Level Distillation (PLD). We extract explicit reasoning patterns from a Teacher model and organize them into a structured list of expressive instructions for the Student model's System Prompt. Evaluated on the StereoSet and Contract-NLI datasets using Gemma-3 4B, PLD improved Macro F1 scores from 57\% to 90.0\% and 67\% to 83\% respectively, enabling this compact model to match frontier performance with negligible latency overhead. These expressive instructions render the decision-making process transparent, allowing for full human verification of logic, making this approach ideal for regulated industries such as law, finance, and content moderation, as well as high-volume use cases and edge devices.

</details>


### [44] [PVminer: A Domain-Specific Tool to Detect the Patient Voice in Patient Generated Data](https://arxiv.org/abs/2602.21165)
*Samah Fodeh,Linhai Ma,Yan Wang,Srivani Talakokkul,Ganesh Puthiaraju,Afshan Khan,Ashley Hagaman,Sarah Lowe,Aimee Roundtree*

Main category: cs.CL

TL;DR: PVminer：一种用于结构化患者声音的NLP框架，在理解患者沟通和健康社会决定因素方面表现出色


<details>
  <summary>Details</summary>
Motivation: 分析患者生成文本中的患者声音（PV），反映沟通行为和健康社会决定因素（SDOH）

Method: 提出PVminer，一个针对患者声音的NLP框架，用于结构化安全患者-提供者沟通中的患者声音

Result: PVminer在分层任务中表现出色，优于生物医学和临床预训练基线，F1分数分别为82.25%（代码）、80.14%（子代码）和77.87%（组合）

Conclusion: PVminer为结构化患者声音提供了一种有效的方法，有助于更好地理解患者沟通和健康社会决定因素

Abstract: Patient-generated text such as secure messages, surveys, and interviews contains rich expressions of the patient voice (PV), reflecting communicative behaviors and social determinants of health (SDoH). Traditional qualitative coding frameworks are labor intensive and do not scale to large volumes of patient-authored messages across health systems. Existing machine learning (ML) and natural language processing (NLP) approaches provide partial solutions but often treat patient-centered communication (PCC) and SDoH as separate tasks or rely on models not well suited to patient-facing language. We introduce PVminer, a domain-adapted NLP framework for structuring patient voice in secure patient-provider communication. PVminer formulates PV detection as a multi-label, multi-class prediction task integrating patient-specific BERT encoders (PV-BERT-base and PV-BERT-large), unsupervised topic modeling for thematic augmentation (PV-Topic-BERT), and fine-tuned classifiers for Code, Subcode, and Combo-level labels. Topic representations are incorporated during fine-tuning and inference to enrich semantic inputs. PVminer achieves strong performance across hierarchical tasks and outperforms biomedical and clinical pre-trained baselines, achieving F1 scores of 82.25% (Code), 80.14% (Subcode), and up to 77.87% (Combo). An ablation study further shows that author identity and topic-based augmentation each contribute meaningful gains. Pre-trained models, source code, and documentation will be publicly released, with annotated datasets available upon request for research use.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [45] [MoBiQuant: Mixture-of-Bits Quantization for Token-Adaptive Elastic LLMs](https://arxiv.org/abs/2602.20191)
*Dongwei Wang,Jinhee Kim,Seokho Han,Denis Gudovskiy,Yohei Nakata,Tomoyuki Okuno,KhayTze Peong,Kang Eun Jeon,Jong Hwan Ko,Yiran Chen,Huanrui Yang*

Main category: cs.LG

TL;DR: MoBiQuant是一种新的混合位量化框架，可以根据标记敏感性调整弹性LLM推理的权重精度，实现平滑的精度切换，并提高泛化能力。


<details>
  <summary>Details</summary>
Motivation: 为了解决在云和边缘设备上改变运行时复杂度的问题，需要弹性部署大型语言模型（LLM），其中LLM可以根据可用的计算资源以不同的量化精度进行推理。然而，观察到量化校准参数通常与特定的精度相关联，这在弹性精度校准和运行时精度切换过程中带来了挑战。受此观察的启发，我们提出了一种新的混合位量化框架MoBiQuant，该框架根据标记敏感性调整弹性LLM推理的权重精度。具体来说，我们提出了许多递归残差量化，可以迭代地重建更高精度的权重，以及标记感知路由器，可以动态选择残差位片数。MoBiQuant可以实现平滑的精度切换，同时提高标记异常分布的泛化能力。

Method: 提出了一种名为MoBiQuant的新颖混合位量化框架，该框架根据标记敏感性调整弹性LLM推理的权重精度。具体方法包括许多递归残差量化，可以迭代地重建更高精度的权重，以及标记感知路由器，可以动态选择残差位片数。

Result: 实验结果表明，MoBiQuant表现出强大的弹性，能够在不进行重复校准的情况下匹配特定位校准的PTQ在LLaMA3-8B上的性能。

Conclusion: MoBiQuant能够实现平滑的精度切换，同时提高标记异常分布的泛化能力，为弹性LLM推理提供了一种有效的解决方案。

Abstract: Changing runtime complexity on cloud and edge devices necessitates elastic large language model (LLM) deployment, where an LLM can be inferred with various quantization precisions based on available computational resources. However, it has been observed that the calibration parameters for quantization are typically linked to specific precisions, which presents challenges during elastic-precision calibration and precision switching at runtime. In this work, we attribute the source of varying calibration parameters to the varying token-level sensitivity caused by a precision-dependent outlier migration phenomenon.Motivated by this observation, we propose \texttt{MoBiQuant}, a novel Mixture-of-Bits quantization framework that adjusts weight precision for elastic LLM inference based on token sensitivity. Specifically, we propose the many-in-one recursive residual quantization that can iteratively reconstruct higher-precision weights and the token-aware router to dynamically select the number of residual bit slices. MoBiQuant enables smooth precision switching while improving generalization for the distribution of token outliers. Experimental results demonstrate that MoBiQuant exhibits strong elasticity, enabling it to match the performance of bit-specific calibrated PTQ on LLaMA3-8B without repeated calibration.

</details>


### [46] [FedAvg-Based CTMC Hazard Model for Federated Bridge Deterioration Assessment](https://arxiv.org/abs/2602.20194)
*Takato Yasuno*

Main category: cs.LG

TL;DR: 提出了一种联邦框架，用于估计桥梁退化的CTMC风险模型，实现了数据共享和模型优化。


<details>
  <summary>Details</summary>
Motivation: 现有的数据治理约束使得桥梁定期检查记录难以在组织间共享，因此提出了一种联邦框架来估计桥梁退化的连续时间马尔可夫链（CTMC）风险模型。

Method: 使用联邦学习框架，用户在本地训练基于桥梁年龄、海岸线距离和桥面面积的协变量进行退化的对数线性风险模型。通过小批量随机梯度下降对CTMC对数似然进行局部优化，并在每轮通信中仅上传一个12维伪梯度向量到中央服务器。服务器使用具有动量和梯度裁剪的样本加权的联邦平均（FedAvg）聚合用户更新。

Result: 在模拟实验中，异构用户表现出平均负对数似然的一致收敛，随着用户规模的增加，聚合梯度范数逐渐减小。此外，联邦更新机制提供了自然的参与激励，用户可以在共享技术标准平台上注册其本地检查数据集，并定期获得全局基准参数的更新，从而实现基于证据的生命周期规划，而无需放弃数据主权。

Conclusion: 提出的联邦框架有效解决了桥梁定期检查记录的数据共享问题，提高了模型的准确性和数据主权保护。

Abstract: Bridge periodic inspection records contain sensitive information about public infrastructure, making cross-organizational data sharing impractical under existing data governance constraints. We propose a federated framework for estimating a Continuous-Time Markov Chain (CTMC) hazard model of bridge deterioration, enabling municipalities to collaboratively train a shared benchmark model without transferring raw inspection records. Each User holds local inspection data and trains a log-linear hazard model over three deterioration-direction transitions -- Good$\to$Minor, Good$\to$Severe, and Minor$\to$Severe -- with covariates for bridge age, coastline distance, and deck area. Local optimization is performed via mini-batch stochastic gradient descent on the CTMC log-likelihood, and only a 12-dimensional pseudo-gradient vector is uploaded to a central server per communication round. The server aggregates User updates using sample-weighted Federated Averaging (FedAvg) with momentum and gradient clipping. All experiments in this paper are conducted on fully synthetic data generated from a known ground-truth parameter set with region-specific heterogeneity, enabling controlled evaluation of federated convergence behaviour. Simulation results across heterogeneous Users show consistent convergence of the average negative log-likelihood, with the aggregated gradient norm decreasing as User scale increases. Furthermore, the federated update mechanism provides a natural participation incentive: Users who register their local inspection datasets on a shared technical-standard platform receive in return the periodically updated global benchmark parameters -- information that cannot be obtained from local data alone -- thereby enabling evidence-based life-cycle planning without surrendering data sovereignty.

</details>


### [47] [Golden Layers and Where to Find Them: Improved Knowledge Editing for Large Language Models Via Layer Gradient Analysis](https://arxiv.org/abs/2602.20207)
*Shrestha Datta,Hongfu Liu,Anshuman Chhabra*

Main category: cs.LG

TL;DR: 提出了一种新的知识编辑方法，通过层梯度分析（LGA）找到固定黄金层，提高编辑性能。


<details>
  <summary>Details</summary>
Motivation: 在大型语言模型（LLMs）中进行知识编辑，旨在更新模型对特定查询的预测，同时保留其在所有其他输入上的行为。

Method: 提出了一种名为层梯度分析（LGA）的新方法，通过梯度归因高效地估计黄金层，避免在多次编辑运行中进行大量试错。

Result: 实验结果表明，该方法在不同LLM类型和多种知识编辑方法中均表现出有效性和鲁棒性。

Conclusion: 该研究假设存在固定黄金层，可以实现对近似的最佳编辑性能，并通过实验验证了这一假设。

Abstract: Knowledge editing in Large Language Models (LLMs) aims to update the model's prediction for a specific query to a desired target while preserving its behavior on all other inputs. This process typically involves two stages: identifying the layer to edit and performing the parameter update. Intuitively, different queries may localize knowledge at different depths of the model, resulting in different sample-wise editing performance for a fixed editing layer. In this work, we hypothesize the existence of fixed golden layers that can achieve near-optimal editing performance similar to sample-wise optimal layers. To validate this hypothesis, we provide empirical evidence by comparing golden layers against ground-truth sample-wise optimal layers. Furthermore, we show that golden layers can be reliably identified using a proxy dataset and generalize effectively to unseen test set queries across datasets. Finally, we propose a novel method, namely Layer Gradient Analysis (LGA) that estimates golden layers efficiently via gradient-attribution, avoiding extensive trial-and-error across multiple editing runs. Extensive experiments on several benchmark datasets demonstrate the effectiveness and robustness of our LGA approach across different LLM types and various knowledge editing methods.

</details>


### [48] [Multimodal Crystal Flow: Any-to-Any Modality Generation for Unified Crystal Modeling](https://arxiv.org/abs/2602.20210)
*Kiyoung Seong,Sungsoo Ahn,Sehui Han,Changyoung Park*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Crystal modeling spans a family of conditional and unconditional generation tasks across different modalities, including crystal structure prediction (CSP) and \emph{de novo} generation (DNG). While recent deep generative models have shown promising performance, they remain largely task-specific, lacking a unified framework that shares crystal representations across different generation tasks. To address this limitation, we propose \emph{Multimodal Crystal Flow (MCFlow)}, a unified multimodal flow model that realizes multiple crystal generation tasks as distinct inference trajectories via independent time variables for atom types and crystal structures. To enable multimodal flow in a standard transformer model, we introduce a composition- and symmetry-aware atom ordering with hierarchical permutation augmentation, injecting strong compositional and crystallographic priors without explicit structural templates. Experiments on the MP-20 and MPTS-52 benchmarks show that MCFlow achieves competitive performance against task-specific baselines across multiple crystal generation tasks.

</details>


### [49] [Wasserstein Distributionally Robust Online Learning](https://arxiv.org/abs/2602.20403)
*Guixian Chen,Salar Fattahi,Soroosh Shafiee*

Main category: cs.LG

TL;DR: 提出了一种新的在线学习算法，该算法通过利用问题几何形状来加速最坏情况期望问题的求解，从而提高了计算效率。


<details>
  <summary>Details</summary>
Motivation: 研究分布鲁棒在线学习，以保护学习者免受从以过去观测为中心的水晶距离模糊集抽取的最坏情况分布的影响。

Method: 将问题表述为决策者与选择最坏情况分布的对手之间的在线鞍点随机博弈，并提出一个通用的框架，该框架收敛到与对应离线Wasserstein分布鲁棒优化（DRO）问题解相一致的双重纳什均衡。针对分段凹损失函数，提出了一种利用问题几何形状来加速超过Gurobi等最先进求解器的定制算法。关键见解是关于最坏情况期望问题，一个本质上无限维优化问题，与一个经典且可处理的预算分配问题之间的新颖联系。

Result: 提出了一种新的在线学习算法，该算法通过利用问题几何形状来加速最坏情况期望问题的求解，从而提高了计算效率。

Conclusion: 该研究为分布鲁棒在线学习提供了一种新的方法，提高了计算效率，并有望在实际应用中得到广泛应用。

Abstract: We study distributionally robust online learning, where a risk-averse learner updates decisions sequentially to guard against worst-case distributions drawn from a Wasserstein ambiguity set centered at past observations. While this paradigm is well understood in the offline setting through Wasserstein Distributionally Robust Optimization (DRO), its online extension poses significant challenges in both convergence and computation. In this paper, we address these challenges. First, we formulate the problem as an online saddle-point stochastic game between a decision maker and an adversary selecting worst-case distributions, and propose a general framework that converges to a robust Nash equilibrium coinciding with the solution of the corresponding offline Wasserstein DRO problem. Second, we address the main computational bottleneck, which is the repeated solution of worst-case expectation problems. For the important class of piecewise concave loss functions, we propose a tailored algorithm that exploits problem geometry to achieve substantial speedups over state-of-the-art solvers such as Gurobi. The key insight is a novel connection between the worst-case expectation problem, an inherently infinite-dimensional optimization problem, and a classical and tractable budget allocation problem, which is of independent interest.

</details>


### [50] [Exploring Anti-Aging Literature via ConvexTopics and Large Language Models](https://arxiv.org/abs/2602.20224)
*Lana E. Yeganova,Won G. Kim,Shubo Tian,Natalie Xie,Donald C. Comeau,W. John Wilbur,Zhiyong Lu*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The rapid expansion of biomedical publications creates challenges for organizing knowledge and detecting emerging trends, underscoring the need for scalable and interpretable methods. Common clustering and topic modeling approaches such as K-means or LDA remain sensitive to initialization and prone to local optima, limiting reproducibility and evaluation. We propose a reformulation of a convex optimization based clustering algorithm that produces stable, fine-grained topics by selecting exemplars from the data and guaranteeing a global optimum. Applied to about 12,000 PubMed articles on aging and longevity, our method uncovers topics validated by medical experts. It yields interpretable topics spanning from molecular mechanisms to dietary supplements, physical activity, and gut microbiota. The method performs favorably, and most importantly, its reproducibility and interpretability distinguish it from common clustering approaches, including K-means, LDA, and BERTopic. This work provides a basis for developing scalable, web-accessible tools for knowledge discovery.

</details>


### [51] [Oracle-Robust Online Alignment for Large Language Models](https://arxiv.org/abs/2602.20457)
*Zimeng Li,Mudit Gaur,Vaneet Aggarwal*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We study online alignment of large language models under misspecified preference feedback, where the observed preference oracle deviates from an ideal but unknown ground-truth oracle. The online LLM alignment problem is a bi-level reinforcement problem due to the coupling between data collection and policy updates. Recently, the problem has been reduced to tractable single-level objective in the SAIL (Self-Improving Efficient Online Alignment) framework. In this paper, we introduce a pointwise oracle uncertainty set in this problem and formulate an oracle-robust online alignment objective as a worst-case optimization problem. For log-linear policies, we show that this robust objective admits an exact closed-form decomposition into the original loss function plus an explicit sensitivity penalty. We develop projected stochastic composite updates for the resulting weakly convex objective and prove $\widetilde{O}(\varepsilon^{-2})$ oracle complexity for reaching approximate stationarity.

</details>


### [52] [Momentum Guidance: Plug-and-Play Guidance for Flow Models](https://arxiv.org/abs/2602.20360)
*Runlong Liao,Jian Yu,Baiyu Su,Chi Zhang,Lizhang Chen,Qiang Liu*

Main category: cs.LG

TL;DR: 动量引导（MG）显著提升了基于流的生成模型的质量。


<details>
  <summary>Details</summary>
Motivation: 为了提高基于流的生成模型的质量，但预训练模型很少以条件形式使用，因为缺乏细粒度细节。

Method: 引入动量引导（MG），利用常微分方程（ODE）轨迹本身。MG使用过去速度的指数移动平均来外推当前速度，并保持每步评估一次的标准成本。

Result: MG在ImageNet-256上实现了平均FID改进36.68%（无CFG）和25.52%（有CFG），在64个采样步骤时达到FID 1.597。在大规模模型如Stable Diffusion 3和FLUX.1-dev上的评估进一步证实了在标准指标上的一致质量提升。

Conclusion: MG是一种有效的引导方法，可以显著提高基于流的生成模型的质量。

Abstract: Flow-based generative models have become a strong framework for high-quality generative modeling, yet pretrained models are rarely used in their vanilla conditional form: conditional samples without guidance often appear diffuse and lack fine-grained detail due to the smoothing effects of neural networks. Existing guidance techniques such as classifier-free guidance (CFG) improve fidelity but double the inference cost and typically reduce sample diversity. We introduce Momentum Guidance (MG), a new dimension of guidance that leverages the ODE trajectory itself. MG extrapolates the current velocity using an exponential moving average of past velocities and preserves the standard one-evaluation-per-step cost. It matches the effect of standard guidance without extra computation and can further improve quality when combined with CFG. Experiments demonstrate MG's effectiveness across benchmarks. Specifically, on ImageNet-256, MG achieves average improvements in FID of 36.68% without CFG and 25.52% with CFG across various sampling settings, attaining an FID of 1.597 at 64 sampling steps. Evaluations on large flow-based models like Stable Diffusion 3 and FLUX.1-dev further confirm consistent quality enhancements across standard metrics.

</details>


### [53] [cc-Shapley: Measuring Multivariate Feature Importance Needs Causal Context](https://arxiv.org/abs/2602.20396)
*Jörg Martin,Stefan Haufe*

Main category: cs.LG

TL;DR: 提出cc-Shapley方法，解决特征重要性评估中的误导性问题。


<details>
  <summary>Details</summary>
Motivation: 数据驱动特征重要性评估存在误导性关联问题。

Method: 提出cc-Shapley方法，结合因果结构进行特征重要性分析。

Result: cc-Shapley方法有效消除观察性分析中的误导性关联，并通过实验验证。

Conclusion: 提出cc-Shapley，解决数据驱动特征重要性评估的不足，消除由观察性分析带来的误导性关联。

Abstract: Explainable artificial intelligence promises to yield insights into relevant features, thereby enabling humans to examine and scrutinize machine learning models or even facilitating scientific discovery. Considering the widespread technique of Shapley values, we find that purely data-driven operationalization of multivariate feature importance is unsuitable for such purposes. Even for simple problems with two features, spurious associations due to collider bias and suppression arise from considering one feature only in the observational context of the other, which can lead to misinterpretations. Causal knowledge about the data-generating process is required to identify and correct such misleading feature attributions. We propose cc-Shapley (causal context Shapley), an interventional modification of conventional observational Shapley values leveraging knowledge of the data's causal structure, thereby analyzing the relevance of a feature in the causal context of the remaining features. We show theoretically that this eradicates spurious association induced by collider bias. We compare the behavior of Shapley and cc-Shapley values on various, synthetic, and real-world datasets. We observe nullification or reversal of associations compared to univariate feature importance when moving from observational to cc-Shapley.

</details>


### [54] [GeoPT: Scaling Physics Simulation via Lifted Geometric Pre-Training](https://arxiv.org/abs/2602.20399)
*Haixu Wu,Minghao Guo,Zongyi Li,Zhiyang Dou,Mingsheng Long,Kaiming He,Wojciech Matusik*

Main category: cs.LG

TL;DR: GeoPT通过合成动力学提升几何形状，提高物理模拟效率，减少数据需求。


<details>
  <summary>Details</summary>
Motivation: Neural simulators在物理模拟中具有高效性，但扩展性受限于生成高保真训练数据的高昂成本。

Method: 提出GeoPT，一个基于提升几何预训练的通用物理模拟统一预训练模型。核心思想是通过合成动力学增强几何形状，实现无需物理标签的动态感知自监督。

Result: GeoPT在超过一百万个样本上进行预训练，在流体力学、固体力学等领域提高工业保真度基准，减少20-60%的标记数据需求，加速收敛2倍。

Conclusion: 通过合成动力学提升几何形状，弥合几何-物理差距，为神经模拟开辟可扩展的道路。

Abstract: Neural simulators promise efficient surrogates for physics simulation, but scaling them is bottlenecked by the prohibitive cost of generating high-fidelity training data. Pre-training on abundant off-the-shelf geometries offers a natural alternative, yet faces a fundamental gap: supervision on static geometry alone ignores dynamics and can lead to negative transfer on physics tasks. We present GeoPT, a unified pre-trained model for general physics simulation based on lifted geometric pre-training. The core idea is to augment geometry with synthetic dynamics, enabling dynamics-aware self-supervision without physics labels. Pre-trained on over one million samples, GeoPT consistently improves industrial-fidelity benchmarks spanning fluid mechanics for cars, aircraft, and ships, and solid mechanics in crash simulation, reducing labeled data requirements by 20-60% and accelerating convergence by 2$\times$. These results show that lifting with synthetic dynamics bridges the geometry-physics gap, unlocking a scalable path for neural simulation and potentially beyond. Code is available at https://github.com/Physics-Scaling/GeoPT.

</details>


### [55] [Three Concrete Challenges and Two Hopes for the Safety of Unsupervised Elicitation](https://arxiv.org/abs/2602.20400)
*Callum Canavan,Aditya Shrivastava,Allison Qi,Jonathan Michala,Fabien Roger*

Main category: cs.LG

TL;DR: 构建数据集测试无监督诱导技术，发现这些技术无法可靠地应对挑战；集成和结合技术只能部分缓解性能下降。


<details>
  <summary>Details</summary>
Motivation: 为了引导语言模型在人类能力之外的任务上产生真实的输出，先前的研究建议在简单任务上训练模型以引导它们在更难的任务上（简单到困难泛化），或者使用无监督训练算法来引导没有外部标签的模型（无监督诱导）。尽管这两种范式中的技术已被证明可以广泛提高各种任务的模型精度，但我们认为用于这些评估的数据集可能导致过于乐观的评估结果。与许多现实世界的数据集不同，它们通常（1）没有比真实性更显著的特征，（2）具有平衡的训练集，并且（3）只包含模型可以给出明确定答的数据点。我们构建了缺乏这些特性的数据集，以对一系列标准的无监督诱导和简单到困难泛化技术进行压力测试。我们发现没有任何技术在任何这些挑战上都能可靠地表现良好。我们还研究了集成和结合简单到困难和无监督技术，发现它们只能部分缓解这些挑战导致的性能下降。我们认为克服这些挑战应该是未来无监督诱导工作的重点。

Method: 构建缺乏特定特性的数据集，以对一系列标准的无监督诱导和简单到困难泛化技术进行压力测试。研究了集成和结合简单到困难和无监督技术。

Result: 没有技术在任何挑战上都能可靠地表现良好；集成和结合技术只能部分缓解性能下降。

Conclusion: 克服这些挑战应该是未来无监督诱导工作的重点。

Abstract: To steer language models towards truthful outputs on tasks which are beyond human capability, previous work has suggested training models on easy tasks to steer them on harder ones (easy-to-hard generalization), or using unsupervised training algorithms to steer models with no external labels at all (unsupervised elicitation). Although techniques from both paradigms have been shown to improve model accuracy on a wide variety of tasks, we argue that the datasets used for these evaluations could cause overoptimistic evaluation results. Unlike many real-world datasets, they often (1) have no features with more salience than truthfulness, (2) have balanced training sets, and (3) contain only data points to which the model can give a well-defined answer. We construct datasets that lack each of these properties to stress-test a range of standard unsupervised elicitation and easy-to-hard generalization techniques. We find that no technique reliably performs well on any of these challenges. We also study ensembling and combining easy-to-hard and unsupervised techniques, and find they only partially mitigate performance degradation due to these challenges. We believe that overcoming these challenges should be a priority for future work on unsupervised elicitation.

</details>


### [56] [$κ$-Explorer: A Unified Framework for Active Model Estimation in MDPs](https://arxiv.org/abs/2602.20404)
*Xihe Gu,Urbashi Mitra,Tara Javidi*

Main category: cs.LG

TL;DR: 提出了一种新的探索算法$κ$-Explorer，通过优化状态-动作占用度量，提高了模型估计的准确性。


<details>
  <summary>Details</summary>
Motivation: 为了提高在完美状态可观测的表格马尔可夫决策过程（MDP）中的模型估计准确性，研究了探索策略如何根据每个转移分布的内在复杂性分配访问频率。

Method: 提出了一种参数化的可分解和凹目标函数族$U_κ$，该函数族明确地结合了内在估计复杂性和外部访问频率。使用闭式梯度描述符，提出了$κ$-Explorer算法，该算法在状态-动作占用度量上进行Frank-Wolfe风格的优化。

Result: $κ$-Explorer算法在基准MDP上的实验表明，与现有的探索策略相比，提供了更好的性能。

Conclusion: 提出了一种新的探索算法$κ$-Explorer，通过优化状态-动作占用度量，提高了模型估计的准确性。

Abstract: In tabular Markov decision processes (MDPs) with perfect state observability, each trajectory provides active samples from the transition distributions conditioned on state-action pairs. Consequently, accurate model estimation depends on how the exploration policy allocates visitation frequencies in accordance with the intrinsic complexity of each transition distribution. Building on recent work on coverage-based exploration, we introduce a parameterized family of decomposable and concave objective functions $U_κ$ that explicitly incorporate both intrinsic estimation complexity and extrinsic visitation frequency. Moreover, the curvature $κ$ provides a unified treatment of various global objectives, such as the average-case and worst-case estimation error objectives. Using the closed-form characterization of the gradient of $U_κ$, we propose $κ$-Explorer, an active exploration algorithm that performs Frank-Wolfe-style optimization over state-action occupancy measures. The diminishing-returns structure of $U_κ$ naturally prioritizes underexplored and high-variance transitions, while preserving smoothness properties that enable efficient optimization. We establish tight regret guarantees for $κ$-Explorer and further introduce a fully online and computationally efficient surrogate algorithm for practical use. Experiments on benchmark MDPs demonstrate that $κ$-Explorer provides superior performance compared to existing exploration strategies.

</details>


### [57] [Nonparametric Teaching of Attention Learners](https://arxiv.org/abs/2602.20461)
*Chen Zhang,Jianghui Wang,Bingyang Cheng,Zhongtao Chen,Wendong XU,Cong Wang,Marco Canini,Francesco Orabona,Yik Chung WU,Ngai Wong*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Attention learners, neural networks built on the attention mechanism, e.g., transformers, excel at learning the implicit relationships that relate sequences to their corresponding properties, e.g., mapping a given sequence of tokens to the probability of the next token. However, the learning process tends to be costly. To address this, we present a novel paradigm named Attention Neural Teaching (AtteNT) that reinterprets the learning process through a nonparametric teaching perspective. Specifically, the latter provides a theoretical framework for teaching mappings that are implicitly defined (i.e., nonparametric) via example selection. Such an implicit mapping is embodied through a dense set of sequence-property pairs, with the AtteNT teacher selecting a subset to accelerate convergence in attention learner training. By analytically investigating the role of attention on parameter-based gradient descent during training, and recasting the evolution of attention learners, shaped by parameter updates, through functional gradient descent in nonparametric teaching, we show for the first time that teaching attention learners is consistent with teaching importance-adaptive nonparametric learners. These new findings readily commit AtteNT to enhancing learning efficiency of attention learners. Specifically, we observe training time reductions of 13.01% for LLMs and 20.58% for ViTs, spanning both fine-tuning and training-from-scratch regimes. Crucially, these gains are achieved without compromising accuracy; in fact, performance is consistently preserved and often enhanced across a diverse set of downstream tasks.

</details>


### [58] [A Long-Short Flow-Map Perspective for Drifting Models](https://arxiv.org/abs/2602.20463)
*Zhiqi Li,Bo Zhu*

Main category: cs.LG

TL;DR: 重新解释漂移模型，提出新方法，验证并解释结果


<details>
  <summary>Details</summary>
Motivation: 对漂移模型进行重新解释

Method: 半群一致的长短流图分解

Result: 提出新的似然学习公式，并通过理论和实证验证

Conclusion: 为特征空间优化提供理论解释，并提出未来研究方向

Abstract: This paper provides a reinterpretation of the Drifting Model~\cite{deng2026generative} through a semigroup-consistent long-short flow-map factorization. We show that a global transport process can be decomposed into a long-horizon flow map followed by a short-time terminal flow map admitting a closed-form optimal velocity representation, and that taking the terminal interval length to zero recovers exactly the drifting field together with a conservative impulse term required for flow-map consistency. Based on this perspective, we propose a new likelihood learning formulation that aligns the long-short flow-map decomposition with density evolution under transport. We validate the framework through both theoretical analysis and empirical evaluations on benchmark tests, and further provide a theoretical interpretation of the feature-space optimization while highlighting several open problems for future study.

</details>


### [59] [Hierarchic-EEG2Text: Assessing EEG-To-Text Decoding across Hierarchical Abstraction Levels](https://arxiv.org/abs/2602.20932)
*Anupam Sharma,Harish Katti,Prajwal Singh,Shanmuganathan Raman,Krishna Miyapuram*

Main category: cs.LG

TL;DR: 本研究通过层次感知的事件分析，探讨了EEG在多级层次上捕捉物体表征的能力，并发现模型对抽象敏感。


<details>
  <summary>Details</summary>
Motivation: 研究EEG在多级层次上捕捉物体表征的能力，并提出了一种基于记忆的事件分析（episodic analysis）方法。

Method: 使用WordNet进行层次感知的事件采样，构建了最大的EEG事件框架，用于从PEERS数据集中的EEG信号中检测观察到的文本。

Result: 发现模型的性能在分类类别来自层次结构更高层时有所提高，表明对抽象的敏感性。

Conclusion: 强调了抽象深度作为EEG解码的一个未充分探索的维度，并激励了未来在这一方向上的研究。

Abstract: An electroencephalogram (EEG) records the spatially averaged electrical activity of neurons in the brain, measured from the human scalp. Prior studies have explored EEG-based classification of objects or concepts, often for passive viewing of briefly presented image or video stimuli, with limited classes. Because EEG exhibits a low signal-to-noise ratio, recognizing fine-grained representations across a large number of classes remains challenging; however, abstract-level object representations may exist. In this work, we investigate whether EEG captures object representations across multiple hierarchical levels, and propose episodic analysis, in which a Machine Learning (ML) model is evaluated across various, yet related, classification tasks (episodes). Unlike prior episodic EEG studies that rely on fixed or randomly sampled classes of equal cardinality, we adopt hierarchy-aware episode sampling using WordNet to generate episodes with variable classes of diverse hierarchy. We also present the largest episodic framework in the EEG domain for detecting observed text from EEG signals in the PEERS dataset, comprising $931538$ EEG samples under $1610$ object labels, acquired from $264$ human participants (subjects) performing controlled cognitive tasks, enabling the study of neural dynamics underlying perception, decision-making, and performance monitoring.
  We examine how the semantic abstraction level affects classification performance across multiple learning techniques and architectures, providing a comprehensive analysis. The models tend to improve performance when the classification categories are drawn from higher levels of the hierarchy, suggesting sensitivity to abstraction. Our work highlights abstraction depth as an underexplored dimension of EEG decoding and motivates future research in this direction.

</details>


### [60] [MAST: A Multi-fidelity Augmented Surrogate model via Spatial Trust-weighting](https://arxiv.org/abs/2602.20974)
*Ahmed Mohamed Eisa Nasr,Haris Moazam Sheikh*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: In engineering design and scientific computing, computational cost and predictive accuracy are intrinsically coupled. High-fidelity simulations provide accurate predictions but at substantial computational costs, while lower-fidelity approximations offer efficiency at the expense of accuracy. Multi-fidelity surrogate modelling addresses this trade-off by combining abundant low-fidelity data with sparse high-fidelity observations. However, existing methods suffer from expensive training cost or rely on global correlation assumptions that often fail in practice to capture how fidelity relationships vary across the input space, leading to poor performance particularly under tight budget constraints. We introduce MAST, a method that blends corrected low-fidelity observations with high-fidelity predictions, trusting high-fidelity near observed samples and relying on corrected low-fidelity elsewhere. MAST achieves this through explicit discrepancy modelling and distance-based weighting with closed-form variance propagation, producing a single heteroscedastic Gaussian process. Across multi-fidelity synthetic benchmarks, MAST shows a marked improvement over the current state-of-the-art techniques. Crucially, MAST maintains robust performance across varying total budget and fidelity gaps, conditions under which competing methods exhibit significant degradation or unstable behaviour.

</details>


### [61] [Matching Multiple Experts: On the Exploitability of Multi-Agent Imitation Learning](https://arxiv.org/abs/2602.21020)
*Antoine Bergerault,Volkan Cevher,Negar Mehr*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Multi-agent imitation learning (MA-IL) aims to learn optimal policies from expert demonstrations of interactions in multi-agent interactive domains. Despite existing guarantees on the performance of the resulting learned policies, characterizations of how far the learned polices are from a Nash equilibrium are missing for offline MA-IL. In this paper, we demonstrate impossibility and hardness results of learning low-exploitable policies in general $n$-player Markov Games. We do so by providing examples where even exact measure matching fails, and demonstrating a new hardness result on characterizing the Nash gap given a fixed measure matching error. We then show how these challenges can be overcome using strategic dominance assumptions on the expert equilibrium. Specifically, for the case of dominant strategy expert equilibria, assuming Behavioral Cloning error $ε_{\text{BC}}$, this provides a Nash imitation gap of $\mathcal{O}\left(nε_{\text{BC}}/(1-γ)^2\right)$ for a discount factor $γ$. We generalize this result with a new notion of best-response continuity, and argue that this is implicitly encouraged by standard regularization techniques.

</details>


### [62] [T1: One-to-One Channel-Head Binding for Multivariate Time-Series Imputation](https://arxiv.org/abs/2602.21043)
*Dongik Park,Hyunwoo Ryu,Suahn Bae,Keondo Park,Hyung-Sin Kim*

Main category: cs.LG

TL;DR: T1是一种CNN-Transformer混合架构，通过通道-头部绑定机制实现鲁棒填充，在多变量时间序列中表现出色。


<details>
  <summary>Details</summary>
Motivation: 多变量时间序列中缺失值的填充仍然具有挑战性，尤其是在多样化的缺失模式和严重缺失的情况下。现有方法由于损坏的时间特征阻碍了有效的跨变量信息传递，从而放大了重建误差。鲁棒填充需要从每个变量的稀疏观测中提取时间模式，并选择性地跨变量传递信息——然而当前的方法在其中一个方面表现出色，而在另一方面有所妥协。

Method: 提出了一种名为T1的CNN-Transformer混合架构，通过通道-头部绑定机制实现鲁棒填充。该设计允许选择性地传递信息：当缺失性损坏某些时间模式时，相应的注意力路径会根据剩余可观察模式自适应地降低权重，同时通过未受影响的通道保留可靠的跨变量连接。

Result: 在11个基准数据集上的实验表明，T1实现了最先进的性能，平均降低了46%的均方误差，与第二好的基线相比，尤其是在极端稀疏性（70%缺失率）下有特别强的收益。该模型无需重新训练即可泛化到未见过的缺失模式，并在所有数据集上使用一致的超参数配置。

Conclusion: T1是一种有效的鲁棒填充方法，在多变量时间序列中表现出色。

Abstract: Imputing missing values in multivariate time series remains challenging, especially under diverse missing patterns and heavy missingness. Existing methods suffer from suboptimal performance as corrupted temporal features hinder effective cross-variable information transfer, amplifying reconstruction errors. Robust imputation requires both extracting temporal patterns from sparse observations within each variable and selectively transferring information across variables--yet current approaches excel at one while compromising the other. We introduce T1 (Time series imputation with 1-to-1 channel-head binding), a CNN-Transformer hybrid architecture that achieves robust imputation through Channel-Head Binding--a mechanism creating one-to-one correspondence between CNN channels and attention heads. This design enables selective information transfer: when missingness corrupts certain temporal patterns, their corresponding attention pathways adaptively down-weight based on remaining observable patterns while preserving reliable cross-variable connections through unaffected channels. Experiments on 11 benchmark datasets demonstrate that T1 achieves state-of-the-art performance, reducing MSE by 46% on average compared to the second-best baseline, with particularly strong gains under extreme sparsity (70% missing ratio). The model generalizes to unseen missing patterns without retraining and uses a consistent hyperparameter configuration across all datasets. The code is available at https://github.com/Oppenheimerdinger/T1.

</details>


### [63] [Localized Dynamics-Aware Domain Adaption for Off-Dynamics Offline Reinforcement Learning](https://arxiv.org/abs/2602.21072)
*Zhangjie Xia,Yu Yang,Pan Xu*

Main category: cs.LG

TL;DR: LoDADA通过利用局部动态差异，在离线强化学习中实现更有效的源数据重用。


<details>
  <summary>Details</summary>
Motivation: 为了更好地利用源数据，提出了一种名为LoDADA的方法，该方法利用局部动态差异来提高源数据的重用率。

Method: LoDADA通过聚类源和目标数据集的转换，并通过领域判别估计聚类级别的动态差异。保留来自差异小的聚类的源转换，而过滤掉来自差异大的聚类的转换。

Result: 结果表明，LoDADA在利用局部分布差异方面优于最先进的离线强化学习方法，并且在具有不同全局和局部动态变化的多个环境中都取得了优异的性能。

Conclusion: LoDADA是一种有效的方法，可以解决离线强化学习中的动态不匹配问题，并提高源数据的重用率。

Abstract: Off-dynamics offline reinforcement learning (RL) aims to learn a policy for a target domain using limited target data and abundant source data collected under different transition dynamics. Existing methods typically address dynamics mismatch either globally over the state space or via pointwise data filtering; these approaches can miss localized cross-domain similarities or incur high computational cost. We propose Localized Dynamics-Aware Domain Adaptation (LoDADA), which exploits localized dynamics mismatch to better reuse source data. LoDADA clusters transitions from source and target datasets and estimates cluster-level dynamics discrepancy via domain discrimination. Source transitions from clusters with small discrepancy are retained, while those from clusters with large discrepancy are filtered out. This yields a fine-grained and scalable data selection strategy that avoids overly coarse global assumptions and expensive per-sample filtering. We provide theoretical insights and extensive experiments across environments with diverse global and local dynamics shifts. Results show that LoDADA consistently outperforms state-of-the-art off-dynamics offline RL methods by better leveraging localized distribution mismatch.

</details>


### [64] [Sequential Counterfactual Inference for Temporal Clinical Data: Addressing the Time Traveler Dilemma](https://arxiv.org/abs/2602.21168)
*Jingya Cheng,Alaleh Azhir,Jiazi Tian,Hossein Estiri*

Main category: cs.LG

TL;DR: 提出了一个新的顺序反事实框架，用于分析临床数据，以更准确地预测患者结果并提供基于生物学合理性的临床见解。


<details>
  <summary>Details</summary>
Motivation: 为了解决标准方法在纵向临床数据中假设特征独立性和同时可修改性的问题，引入了一种新的框架。

Method: 提出了一个顺序反事实框架，通过区分不可变特征（慢性诊断）和可控制特征（实验室值），并模拟干预措施随时间传播的过程，来尊重电子健康记录中的时间依赖性。

Result: 在2,723名COVID-19患者（383例长期COVID心脏衰竭病例，2,340例匹配对照）中应用，结果表明，在简单方法下，38-67%的慢性病患者的反事实是不可能的。我们确定了一个心血管肾连锁反应（CKD -> AKI -> HF），每个步骤的相对风险分别为2.27和1.19，这说明了顺序反事实可以捕捉的时间传播。框架将反事实解释从“如果这个特征不同会怎样？”转变为“如果我们早点干预，结果会如何，并如何向前传播？”——从而产生基于生物学合理性的临床可操作见解。

Conclusion: 顺序反事实框架能够更准确地预测患者结果，并提供了基于生物学合理性的临床见解。

Abstract: Counterfactual inference enables clinicians to ask "what if" questions about patient outcomes, but standard methods assume feature independence and simultaneous modifiability -- assumptions violated by longitudinal clinical data. We introduce the Sequential Counterfactual Framework, which respects temporal dependencies in electronic health records by distinguishing immutable features (chronic diagnoses) from controllable features (lab values) and modeling how interventions propagate through time. Applied to 2,723 COVID-19 patients (383 Long COVID heart failure cases, 2,340 matched controls), we demonstrate that 38-67% of patients with chronic conditions would require biologically impossible counterfactuals under naive methods. We identify a cardiorenal cascade (CKD -> AKI -> HF) with relative risks of 2.27 and 1.19 at each step, illustrating temporal propagation that sequential -- but not naive -- counterfactuals can capture. Our framework transforms counterfactual explanation from "what if this feature were different?" to "what if we had intervened earlier, and how would that propagate forward?" --  yielding clinically actionable insights grounded in biological plausibility.

</details>


### [65] [The Diffusion Duality, Chapter II: $Ψ$-Samplers and Efficient Curriculum](https://arxiv.org/abs/2602.21185)
*Justin Deschenaux,Caglar Gulcehre,Subham Sekhar Sahoo*

Main category: cs.LG

TL;DR: 提出了一种新的PC采样器和高效的训练课程，提高了离散扩散模型的采样质量和训练效率，挑战了Masked扩散模型的主导地位。


<details>
  <summary>Details</summary>
Motivation: 为了提高离散扩散模型的采样质量，并挑战Masked扩散模型在扩散语言模型中的主导地位。

Method: 引入了一组预测-校正（PC）采样器，并将其与均匀状态扩散模型相结合。同时，开发了一种内存高效的课程，用于高斯松弛训练阶段。

Result: PC采样器在语言和图像建模方面优于传统的祖先采样，并且在匹配的单语熵上实现了更低的生成困惑度，同时在CIFAR10上取得了更好的FID/IS分数。此外，高斯松弛训练阶段的课程减少了25%的训练时间和33%的内存消耗。

Conclusion: PC采样器在离散扩散模型中优于祖先采样，并提出了一种新的高斯松弛训练课程，挑战了Masked扩散模型在扩散语言模型中的地位。

Abstract: Uniform-state discrete diffusion models excel at few-step generation and guidance due to their ability to self-correct, making them preferred over autoregressive or Masked diffusion models in these settings. However, their sampling quality plateaus with ancestral samplers as the number of steps increases. We introduce a family of Predictor-Corrector (PC) samplers for discrete diffusion that generalize prior methods and apply to arbitrary noise processes. When paired with uniform-state diffusion, our samplers outperform ancestral sampling on both language and image modeling, achieving lower generative perplexity at matched unigram entropy on OpenWebText and better FID/IS scores on CIFAR10. Crucially, unlike conventional samplers, our PC methods continue to improve with more sampling steps. Taken together, these findings call into question the assumption that Masked diffusion is the inevitable future of diffusion-based language modeling. Beyond sampling, we develop a memory-efficient curriculum for the Gaussian relaxation training phase, reducing training time by 25% and memory by 33% compared to Duo while maintaining comparable perplexity on OpenWebText and LM1B and strong downstream performance. We release code, checkpoints, and a video-tutorial on: https://s-sahoo.com/duo-ch2

</details>


### [66] [Why Pass@k Optimization Can Degrade Pass@1: Prompt Interference in LLM Post-training](https://arxiv.org/abs/2602.21189)
*Anas Barakat,Souradip Chakraborty,Khushbu Pahwa,Amrit Singh Bedi*

Main category: cs.LG

TL;DR: 研究揭示了Pass@k优化可能降低Pass@1性能，尤其是在负干扰提示的情况下。


<details>
  <summary>Details</summary>
Motivation: Pass@k作为可验证大型语言模型任务（包括数学推理、代码生成和简答题推理）的广泛使用性能指标，它定义了成功，如果k个独立采样的解决方案中任何一个通过验证器。这种多样本推理指标推动了推理感知微调方法，这些方法直接优化pass@k。然而，先前的工作报告了一个反复出现的权衡：在这种方法下，pass@k提高的同时，pass@1下降。这种权衡在实际上很重要，因为pass@1通常仍然是由于延迟和成本预算、验证器覆盖率不完美以及需要可靠的单一击退而成为一个难以操作的约束。我们研究了这种权衡的起源，并提供了通过由提示干扰引起的梯度冲突来减少pass@1的pass@k策略优化的理论特征。我们表明，pass@$k$策略梯度可能与pass@1梯度冲突，因为pass@$k$优化隐式地重新加权提示，使其偏向低成功率提示；当这些提示是我们所说的负干扰时，它们的加重要将pass@$k$更新方向旋转离开pass@1方向。我们使用在可验证数学推理任务上对大型语言模型进行的实验来说明我们的理论发现。

Method: 研究了pass@k与pass@1之间的权衡，并提供了通过梯度冲突引起的理论特征，当pass@k策略优化可以通过提示干扰减少pass@1时。使用pass@$k$策略梯度与pass@1梯度可能发生冲突，因为pass@$k$优化隐式地重新加权提示，使其偏向低成功率提示；当这些提示是负干扰时，它们的加重要将pass@$k$更新方向旋转离开pass@1方向。在可验证数学推理任务上进行了实验。

Result: 研究发现pass@k策略梯度可能与pass@1梯度冲突，因为pass@$k$优化隐式地重新加权提示，使其偏向低成功率提示；当这些提示是负干扰时，它们的加重要将pass@$k$更新方向旋转离开pass@1方向。通过在可验证数学推理任务上的实验，验证了理论发现。

Conclusion: Pass@k策略优化可能会通过梯度冲突减少pass@1，尤其是在负干扰提示的情况下。实验结果表明，在可验证数学推理任务上，pass@k优化可能会对pass@1产生负面影响。

Abstract: Pass@k is a widely used performance metric for verifiable large language model tasks, including mathematical reasoning, code generation, and short-answer reasoning. It defines success if any of $k$ independently sampled solutions passes a verifier. This multi-sample inference metric has motivated inference-aware fine-tuning methods that directly optimize pass@$k$. However, prior work reports a recurring trade-off: pass@k improves while pass@1 degrades under such methods. This trade-off is practically important because pass@1 often remains a hard operational constraint due to latency and cost budgets, imperfect verifier coverage, and the need for a reliable single-shot fallback. We study the origin of this trade-off and provide a theoretical characterization of when pass@k policy optimization can reduce pass@1 through gradient conflict induced by prompt interference. We show that pass@$k$ policy gradients can conflict with pass@1 gradients because pass@$k$ optimization implicitly reweights prompts toward low-success prompts; when these prompts are what we term negatively interfering, their upweighting can rotate the pass@k update direction away from the pass@1 direction. We illustrate our theoretical findings with large language model experiments on verifiable mathematical reasoning tasks.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [67] [When Backdoors Go Beyond Triggers: Semantic Drift in Diffusion Models Under Encoder Attacks](https://arxiv.org/abs/2602.20193)
*Shenyang Chen,Liuwan Zhu*

Main category: cs.CR

TL;DR: Challenges standard T2I backdoor evaluations, reveals deep structural risks, and emphasizes geometric audits importance.


<details>
  <summary>Details</summary>
Motivation: Standard evaluations of backdoor attacks on T2I models primarily measure trigger activation and visual fidelity.

Method: Jacobian-based analysis, introduction of SEMAD (Semantic Alignment and Drift) framework

Result: Persistent, trigger-free semantic corruption, structural degradation, deep structural risks of encoder poisoning

Conclusion: Highlight the necessity of geometric audits beyond simple attack success rates.

Abstract: Standard evaluations of backdoor attacks on text-to-image (T2I) models primarily measure trigger activation and visual fidelity. We challenge this paradigm, demonstrating that encoder-side poisoning induces persistent, trigger-free semantic corruption that fundamentally reshapes the representation manifold. We trace this vulnerability to a geometric mechanism: a Jacobian-based analysis reveals that backdoors act as low-rank, target-centered deformations that amplify local sensitivity, causing distortion to propagate coherently across semantic neighborhoods. To rigorously quantify this structural degradation, we introduce SEMAD (Semantic Alignment and Drift), a diagnostic framework that measures both internal embedding drift and downstream functional misalignment. Our findings, validated across diffusion and contrastive paradigms, expose the deep structural risks of encoder poisoning and highlight the necessity of geometric audits beyond simple attack success rates.

</details>


### [68] [The TCF doesn't really A(A)ID -- Automatic Privacy Analysis and Legal Compliance of TCF-based Android Applications](https://arxiv.org/abs/2602.20222)
*Victor Morel,Cristiana Santos,Pontus Carlsson,Joel Ahlinder,Romaric Duvignau*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The Transparency and Consent Framework (TCF), developed by the Interactive Advertising Bureau (IAB) Europe, provides a de facto standard for requesting, recording, and managing user consent from European end-users. This framework has previously been found to infringe European data protection law and has subsequently been regularly updated. Previous research on the TCF focused exclusively on web contexts, with no attention given to its implementation in mobile applications. No work has systematically studied the privacy implications of the TCF on Android apps. To address this gap, we investigate the prevalence of the TCF in popular Android apps from the Google Play Store, and assess whether these apps respect users' consent banner choices. By scraping and downloading 4482 of the most popular Google Play Store apps on an emulated Android device, we automatically determine which apps use the TCF, automatically interact with consent banners, and analyze the apps' traffic in two different stages, passive (post choices) and active (during banner interaction and post choices).
  We found that 576 (12.85%) of the 4482 downloadable apps in our dataset implemented the TCF, and we identified potential privacy violations within this subset. In 15 (2.6%) of these apps, users' choices are stored only when consent is granted. Users who refuse consent are shown the consent banner again each time they launch the app. Network traffic analysis conducted during the passive stage reveals that 66.2% of the analyzed TCF-based apps share personal data, through the Android Advertising ID (AAID), in the absence of a lawful basis for processing. 55.3% of apps analyzed during the active stage share AAID before users interact with the apps' consent banners, violating the prior consent requirement.

</details>


### [69] [OptiLeak: Efficient Prompt Reconstruction via Reinforcement Learning in Multi-tenant LLM Services](https://arxiv.org/abs/2602.20595)
*Longxiang Wang,Xiang Zheng,Xuhao Zhang,Yao Zhang,Ye Wu,Cong Wang*

Main category: cs.CR

TL;DR: OptiLeak通过强化学习和微调技术显著降低了LLM服务框架中的提示泄露风险。


<details>
  <summary>Details</summary>
Motivation: 多租户LLM服务框架广泛采用共享键值缓存以提高效率，但这也创造了侧信道漏洞，使提示泄露攻击成为可能。

Method: 提出了一种名为OptiLeak的强化学习增强框架，通过两阶段微调来最大化提示重建效率。

Result: 在医疗和金融领域的三个基准测试中，OptiLeak将平均每token的请求次数与基线方法相比减少了高达12.48倍。

Conclusion: 基于缓存的提示泄露比之前报道的更具威胁，强调了在生产部署中实现强大缓存隔离的必要性。

Abstract: Multi-tenant LLM serving frameworks widely adopt shared Key-Value caches to enhance efficiency. However, this creates side-channel vulnerabilities enabling prompt leakage attacks. Prior studies identified these attack surfaces yet focused on expanding attack vectors rather than optimizing attack performance, reporting impractically high attack costs that underestimate the true privacy risk. We propose OptiLeak, a reinforcement learning-enhanced framework that maximizes prompt reconstruction efficiency through two-stage fine-tuning. Our key insight is that domain-specific ``hard tokens'' -- terms difficult to predict yet carrying sensitive information -- can be automatically identified via likelihood ranking and used to construct preference pairs for Direct Preference Optimization, eliminating manual annotation. This enables effective preference alignment while avoiding the overfitting issues of extended supervised fine-tuning. Evaluated on three benchmarks spanning medical and financial domains, OptiLeak achieves up to $12.48\times$ reduction in average requests per token compared to baseline approaches, with consistent improvements across model scales from 3B to 14B parameters. Our findings demonstrate that cache-based prompt leakage poses a more severe threat than previously reported, underscoring the need for robust cache isolation in production deployments.

</details>


### [70] [Post-Quantum Sanitizable Signatures from McEliece-Based Chameleon Hashing](https://arxiv.org/abs/2602.20657)
*Shahzad Ahmad,Stefan Rass,Zahra Seyedi*

Main category: cs.CR

TL;DR: 本文提出了一种基于麦科利夫密码系统的后量子可净化签名方案，具有透明性和强大的安全性。


<details>
  <summary>Details</summary>
Motivation: 为了解决量子计算对现有密码系统构成的威胁，本文提出了一种基于麦科利夫密码系统的混沌哈希函数的新型后量子可净化签名方案。

Method: 设计了一种新的签名方案，利用Goppa码的固有陷门，通过Patterson解码实现控制碰撞查找，并通过随机化技术实现透明性。

Result: 实现了透明、基于编码的后量子可净化签名方案，提供了强大的理论保证和实际应用的可能性。

Conclusion: 本文提出的方法在理论上具有优势，为后量子加密提供了新的思路，具有实际应用价值。

Abstract: We introduce a novel post-quantum sanitizable signature scheme constructed upon a chameleon hash function derived from the McEliece cryptosystem. In this design, the designated sanitizer possesses the inherent trapdoor of a Goppa code, which facilitates controlled collision-finding via Patterson decoding. This mechanism enables authorized modification of specific message blocks while ensuring all other content remains immutably bound. We provide formal security definitions and rigorous proofs of existential unforgeability and immutability, grounded in the hardness of syndrome decoding in the random-oracle model, where a robust random oracle thwarts trivial linear hash collisions. A key innovation lies in our precise characterization of the transparency property: by imposing a specific weight constraint on the randomizers generated by the signer, we achieve perfect transparency, rendering sanitized signatures indistinguishable from freshly signed ones. This work establishes the first transparent, code-based, post-quantum sanitizable signature scheme, offering strong theoretical guarantees and a pathway for practical deployment in long-term secure applications.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [71] [Selecting Optimal Variable Order in Autoregressive Ising Models](https://arxiv.org/abs/2602.20394)
*Shiba Biswal,Marc Vuffray,Andrey Y. Lokhov*

Main category: stat.ML

TL;DR: 提出了一种基于图信息顺序的自回归模型优化方法，实验结果表明其性能优于朴素方法


<details>
  <summary>Details</summary>
Motivation: 提高自回归模型的性能

Method: 学习描述数据的马尔可夫随机场，并利用推断的图形模型结构构建优化的变量顺序

Result: 在Ising模型上的数值实验表明，与朴素变量顺序相比，图信息顺序生成更高保真度的样本

Conclusion: 结构感知的变量顺序可以降低模型复杂度，提高自回归模型的性能

Abstract: Autoregressive models enable tractable sampling from learned probability distributions, but their performance critically depends on the variable ordering used in the factorization via complexities of the resulting conditional distributions. We propose to learn the Markov random field describing the underlying data, and use the inferred graphical model structure to construct optimized variable orderings. We illustrate our approach on two-dimensional image-like models where a structure-aware ordering leads to restricted conditioning sets, thereby reducing model complexity. Numerical experiments on Ising models with discrete data demonstrate that graph-informed orderings yield higher-fidelity generated samples compared to naive variable orderings.

</details>


### [72] [Standard Transformers Achieve the Minimax Rate in Nonparametric Regression with $C^{s,λ}$ Targets](https://arxiv.org/abs/2602.20555)
*Yanming Lai,Defeng Sun*

Main category: stat.ML

TL;DR: 本文证明了标准Transformer在逼近Hölder函数和优化非参数回归方面的理论优势，并提供了对Transformer结构的新理解。


<details>
  <summary>Details</summary>
Motivation: Transformer模型在大型语言模型和计算机视觉等领域的巨大成功，需要严格的理论研究。

Method: 证明了标准Transformer可以在L^t距离（t属于[1,∞]）下以任意精度逼近Hölder函数C^{s,λ}([0,1]^{d×n})（s属于N_{≥0}，0<λ≤1）。

Result: 标准Transformer在非参数回归中对于Hölder目标函数达到了最小-最大最优速率。提出了两个度量：大小元组和维度向量，对Transformer结构进行了细致的描述，有助于未来研究不同结构Transformer的泛化和优化误差。推导了标准Transformer的Lipschitz常数的上界及其记忆能力。

Conclusion: 这些发现为Transformer模型强大的能力提供了理论依据。

Abstract: The tremendous success of Transformer models in fields such as large language models and computer vision necessitates a rigorous theoretical investigation. To the best of our knowledge, this paper is the first work proving that standard Transformers can approximate Hölder functions $ C^{s,λ}\left([0,1]^{d\times n}\right) $$ (s\in\mathbb{N}_{\geq0},0<λ\leq1) $ under the $L^t$ distance ($t \in [1, \infty]$) with arbitrary precision. Building upon this approximation result, we demonstrate that standard Transformers achieve the minimax optimal rate in nonparametric regression for Hölder target functions. It is worth mentioning that, by introducing two metrics: the size tuple and the dimension vector, we provide a fine-grained characterization of Transformer structures, which facilitates future research on the generalization and optimization errors of Transformers with different structures. As intermediate results, we also derive the upper bounds for the Lipschitz constant of standard Transformers and their memorization capacity, which may be of independent interest. These findings provide theoretical justification for the powerful capabilities of Transformer models.

</details>


### [73] [Characterizing Online and Private Learnability under Distributional Constraints via Generalized Smoothness](https://arxiv.org/abs/2602.20585)
*Moïse Blanchard,Abhishek Shetty,Alexander Rakhlin*

Main category: stat.ML

TL;DR: The research provides a near complete understanding of learnability under distributional adversaries and shows the connection between generalized smoothness and private learnability under distributional constraints.


<details>
  <summary>Details</summary>
Motivation: Understanding minimal assumptions for learning and generalization in learning theory.

Method: Analyzing sequential decision-making under distributional adversaries, providing a near complete characterization of families U that admit learnability in terms of generalized smoothness. Providing universal algorithms with low regret. Providing refined bounds when U is known.

Result: Near complete understanding of learnability under distributional adversaries, showing that generalized smoothness characterizes private learnability under distributional constraints.

Conclusion: The research provides significant insights into learning theory and has implications for private learning under distributional constraints.

Abstract: Understanding minimal assumptions that enable learning and generalization is perhaps the central question of learning theory. Several celebrated results in statistical learning theory, such as the VC theorem and Littlestone's characterization of online learnability, establish conditions on the hypothesis class that allow for learning under independent data and adversarial data, respectively. Building upon recent work bridging these extremes, we study sequential decision making under distributional adversaries that can adaptively choose data-generating distributions from a fixed family $U$ and ask when such problems are learnable with sample complexity that behaves like the favorable independent case. We provide a near complete characterization of families $U$ that admit learnability in terms of a notion known as generalized smoothness i.e. a distribution family admits VC-dimension-dependent regret bounds for every finite-VC hypothesis class if and only if it is generalized smooth. Further, we give universal algorithms that achieve low regret under any generalized smooth adversary without explicit knowledge of $U$. Finally, when $U$ is known, we provide refined bounds in terms of a combinatorial parameter, the fragmentation number, that captures how many disjoint regions can carry nontrivial mass under $U$. These results provide a nearly complete understanding of learnability under distributional adversaries. In addition, building upon the surprising connection between online learning and differential privacy, we show that the generalized smoothness also characterizes private learnability under distributional constraints.

</details>


### [74] [Amortized Bayesian inference for actigraph time sheet data from mobile devices](https://arxiv.org/abs/2602.20611)
*Daniel Zhou,Sudipto Banerjee*

Main category: stat.ML

TL;DR: 本文提出了一种基于贝叶斯方法和人工智能框架的活动计数据时间序列分析新方法。


<details>
  <summary>Details</summary>
Motivation: 研究移动数据技术在健康变量方面的应用，以及分析高分辨率活动计数据的方法。

Method: 采用贝叶斯方法和分层动态线性模型，结合人工智能框架进行数据分析和不确定性量化。

Result: 实现对活动计时间表的概率插补，并学习解释变量对受试者加速度（MAG）的影响。

Conclusion: 提出了适用于活动计数据的时间序列分析新方法，有助于提高健康研究的准确性。

Abstract: Mobile data technologies use ``actigraphs'' to furnish information on health variables as a function of a subject's movement. The advent of wearable devices and related technologies has propelled the creation of health databases consisting of human movement data to conduct research on mobility patterns and health outcomes. Statistical methods for analyzing high-resolution actigraph data depend on the specific inferential context, but the advent of Artificial Intelligence (AI) frameworks require that the methods be congruent to transfer learning and amortization. This article devises amortized Bayesian inference for actigraph time sheets. We pursue a Bayesian approach to ensure full propagation of uncertainty and its quantification using a hierarchical dynamic linear model. We build our analysis around actigraph data from the Physical Activity through Sustainable Transport Approaches in Los Angeles (PASTA-LA) study conducted by the Fielding School of Public Health in the University of California, Los Angeles. Apart from achieving probabilistic imputation of actigraph time sheets, we are also able to statistically learn about the time-varying impact of explanatory variables on the magnitude of acceleration (MAG) for a cohort of subjects.

</details>


### [75] [DANCE: Doubly Adaptive Neighborhood Conformal Estimation](https://arxiv.org/abs/2602.20652)
*Brandon R. Feng,Brian J. Reich,Daniel Beaglehole,Xihaier Luo,David Keetae Park,Shinjae Yoo,Zhechao Huang,Xueyu Mao,Olcay Boz,Jungeum Kim*

Main category: stat.ML

TL;DR: 提出DANCE算法，结合两种新的非一致性分数，有效提高不确定性量化能力。


<details>
  <summary>Details</summary>
Motivation: 复杂深度学习模型在多数据表示类型上的预测能力不断提高，但需要准确量化这些模型的不确定性。

Method: 提出了一种名为DANCE的双局部自适应最近邻基于的一致性算法，结合两种新的非一致性分数，直接使用数据的嵌入表示。DANCE首先对嵌入层拟合一个任务自适应核回归模型，然后使用学习到的核空间产生最终的预测集进行不确定性量化。

Result: 与最先进的本地、任务自适应和零样本一致性基线进行了测试，证明了DANCE在各个数据集上具有优越的集大小效率和鲁棒性的结合。

Conclusion: DANCE在不确定性量化方面提供了一种有效的方法，优于现有的一致性方法。

Abstract: The recent developments of complex deep learning models have led to unprecedented ability to accurately predict across multiple data representation types. Conformal prediction for uncertainty quantification of these models has risen in popularity, providing adaptive, statistically-valid prediction sets. For classification tasks, conformal methods have typically focused on utilizing logit scores. For pre-trained models, however, this can result in inefficient, overly conservative set sizes when not calibrated towards the target task. We propose DANCE, a doubly locally adaptive nearest-neighbor based conformal algorithm combining two novel nonconformity scores directly using the data's embedded representation. DANCE first fits a task-adaptive kernel regression model from the embedding layer before using the learned kernel space to produce the final prediction sets for uncertainty quantification. We test against state-of-the-art local, task-adapted and zero-shot conformal baselines, demonstrating DANCE's superior blend of set size efficiency and robustness across various datasets.

</details>


### [76] [Is Multi-Distribution Learning as Easy as PAC Learning: Sharp Rates with Bounded Label Noise](https://arxiv.org/abs/2602.21039)
*Rafael Hanashiro,Abhishek Shetty,Patrick Jaillet*

Main category: stat.ML

TL;DR: 多分布学习存在固有难度，样本复杂度与k成正比，需要更复杂的统计方法


<details>
  <summary>Details</summary>
Motivation: 理解从异构来源学习统计复杂度

Method: 研究多分布学习问题，利用共享结构减少样本复杂度

Result: 证明在多个分布学习情况下，样本复杂度与k成正比，存在统计分离

Conclusion: 多分布学习存在固有难度，需要更复杂的统计方法

Abstract: Towards understanding the statistical complexity of learning from heterogeneous sources, we study the problem of multi-distribution learning. Given $k$ data sources, the goal is to output a classifier for each source by exploiting shared structure to reduce sample complexity. We focus on the bounded label noise setting to determine whether the fast $1/ε$ rates achievable in single-task learning extend to this regime with minimal dependence on $k$. Surprisingly, we show that this is not the case. We demonstrate that learning across $k$ distributions inherently incurs slow rates scaling with $k/ε^2$, even under constant noise levels, unless each distribution is learned separately. A key technical contribution is a structured hypothesis-testing framework that captures the statistical cost of certifying near-optimality under bounded noise-a cost we show is unavoidable in the multi-distribution setting.
  Finally, we prove that when competing with the stronger benchmark of each distribution's optimal Bayes error, the sample complexity incurs a \textit{multiplicative} penalty in $k$. This establishes a \textit{statistical} separation between random classification noise and Massart noise, highlighting a fundamental barrier unique to learning from multiple sources.

</details>


### [77] [An Enhanced Projection Pursuit Tree Classifier with Visual Methods for Assessing Algorithmic Improvements](https://arxiv.org/abs/2602.21130)
*Natalia da Silva,Dianne Cook,Eun-Kyung Lee*

Main category: stat.ML

TL;DR: 改进了投影追求树分类器，提高了其在高维数据分类中的性能。


<details>
  <summary>Details</summary>
Motivation: 为了提高投影追求树分类器和可视化诊断方法在处理高维数据时的性能和实用性。

Method: 提出改进的投影追求树分类器算法，并开发两种可视化诊断方法来验证改进的效果。

Result: 改进后的算法在多类设置、不等方差协方差结构和非线性类别分离的情况下表现出更好的性能。

Conclusion: 通过改进算法和可视化诊断方法，提高了投影追求树分类器在高维数据分类中的性能和实用性。

Abstract: This paper presents enhancements to the projection pursuit tree classifier and visual diagnostic methods for assessing their impact in high dimensions. The original algorithm uses linear combinations of variables in a tree structure where depth is constrained to be less than the number of classes -- a limitation that proves too rigid for complex classification problems. Our extensions improve performance in multi-class settings with unequal variance-covariance structures and nonlinear class separations by allowing more splits and more flexible class groupings in the projection pursuit computation. Proposing algorithmic improvements is straightforward; demonstrating their actual utility is not. We therefore develop two visual diagnostic approaches to verify that the enhancements perform as intended. Using high-dimensional visualization techniques, we examine model fits on benchmark datasets to assess whether the algorithm behaves as theorized. An interactive web application enables users to explore the behavior of both the original and enhanced classifiers under controlled scenarios. The enhancements are implemented in the R package PPtreeExt.

</details>


### [78] [Not Just How Much, But Where: Decomposing Epistemic Uncertainty into Per-Class Contributions](https://arxiv.org/abs/2602.21160)
*Mame Diarra Toure,David A. Stephens*

Main category: stat.ML

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: In safety-critical classification, the cost of failure is often asymmetric, yet Bayesian deep learning summarises epistemic uncertainty with a single scalar, mutual information (MI), that cannot distinguish whether a model's ignorance involves a benign or safety-critical class. We decompose MI into a per-class vector $C_k(x)=σ_k^{2}/(2μ_k)$, with $μ_k{=}\mathbb{E}[p_k]$ and $σ_k^2{=}\mathrm{Var}[p_k]$ across posterior samples. The decomposition follows from a second-order Taylor expansion of the entropy; the $1/μ_k$ weighting corrects boundary suppression and makes $C_k$ comparable across rare and common classes. By construction $\sum_k C_k \approx \mathrm{MI}$, and a companion skewness diagnostic flags inputs where the approximation degrades. After characterising the axiomatic properties of $C_k$, we validate it on three tasks: (i) selective prediction for diabetic retinopathy, where critical-class $C_k$ reduces selective risk by 34.7\% over MI and 56.2\% over variance baselines; (ii) out-of-distribution detection on clinical and image benchmarks, where $\sum_k C_k$ achieves the highest AUROC and the per-class view exposes asymmetric shifts invisible to MI; and (iii) a controlled label-noise study in which $\sum_k C_k$ shows less sensitivity to injected aleatoric noise than MI under end-to-end Bayesian training, while both metrics degrade under transfer learning. Across all tasks, the quality of the posterior approximation shapes uncertainty at least as strongly as the choice of metric, suggesting that how uncertainty is propagated through the network matters as much as how it is measured.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [79] [Multilevel Determinants of Overweight and Obesity Among U.S. Children Aged 10-17: Comparative Evaluation of Statistical and Machine Learning Approaches Using the 2021 National Survey of Children's Health](https://arxiv.org/abs/2602.20303)
*Joyanta Jyoti Mondal*

Main category: cs.AI

TL;DR: 研究比较了不同模型的预测性能，发现逻辑回归、梯度提升和多层感知器在平衡判别和校准方面表现最佳，但模型性能在不同群体中存在差异。


<details>
  <summary>Details</summary>
Motivation: 研究美国青少年超重和肥胖的多层次预测因素，并比较统计、机器学习和深度学习模型的预测性能、校准和子群体公平性。

Method: 分析2021年美国儿童健康调查中的18,792名10-17岁的儿童数据，包括饮食、身体活动、睡眠、父母压力、社会经济条件、不良经历和社区特征等预测因素。使用逻辑回归、随机森林、梯度提升、XGBoost、LightGBM、多层感知器和TabNet等模型进行分析。

Result: 预测性能从0.66到0.79不等。逻辑回归、梯度提升和多层感知器在判别和校准之间表现出最稳定的平衡。增强学习和深度学习适度提高了召回率和F1分数。没有模型在所有方面都优于其他模型。不同种族和贫困群体在算法上的性能差异持续存在。

Conclusion: 模型复杂度的增加在逻辑回归之上带来的收益有限。预测因素始终跨越行为、家庭和社区领域。持续的子群体差异表明需要改进数据质量和以公平为重点的监测，而不是增加算法复杂度。

Abstract: Background: Childhood and adolescent overweight and obesity remain major public health concerns in the United States and are shaped by behavioral, household, and community factors. Their joint predictive structure at the population level remains incompletely characterized. Objectives: The study aims to identify multilevel predictors of overweight and obesity among U.S. adolescents and compare the predictive performance, calibration, and subgroup equity of statistical, machine-learning, and deep-learning models. Data and Methods: We analyze 18,792 children aged 10-17 years from the 2021 National Survey of Children's Health. Overweight/obesity is defined using BMI categories. Predictors included diet, physical activity, sleep, parental stress, socioeconomic conditions, adverse experiences, and neighborhood characteristics. Models include logistic regression, random forest, gradient boosting, XGBoost, LightGBM, multilayer perceptron, and TabNet. Performance is evaluated using AUC, accuracy, precision, recall, F1 score, and Brier score. Results: Discrimination range from 0.66 to 0.79. Logistic regression, gradient boosting, and MLP showed the most stable balance of discrimination and calibration. Boosting and deep learning modestly improve recall and F1 score. No model was uniformly superior. Performance disparities across race and poverty groups persist across algorithms. Conclusion: Increased model complexity yields limited gains over logistic regression. Predictors consistently span behavioral, household, and neighborhood domains. Persistent subgroup disparities indicate the need for improved data quality and equity-focused surveillance rather than greater algorithmic complexity.

</details>


### [80] [An artificial intelligence framework for end-to-end rare disease phenotyping from clinical notes using large language models](https://arxiv.org/abs/2602.20324)
*Cathy Shyr,Yan Hu,Rory J. Tinker,Thomas A. Cassini,Kevin W. Byram,Rizwan Hamid,Daniel V. Fabbri,Adam Wright,Josh F. Peterson,Lisa Bastarache,Hua Xu*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Phenotyping is fundamental to rare disease diagnosis, but manual curation of structured phenotypes from clinical notes is labor-intensive and difficult to scale. Existing artificial intelligence approaches typically optimize individual components of phenotyping but do not operationalize the full clinical workflow of extracting features from clinical text, standardizing them to Human Phenotype Ontology (HPO) terms, and prioritizing diagnostically informative HPO terms. We developed RARE-PHENIX, an end-to-end AI framework for rare disease phenotyping that integrates large language model-based phenotype extraction, ontology-grounded standardization to HPO terms, and supervised ranking of diagnostically informative phenotypes. We trained RARE-PHENIX using data from 2,671 patients across 11 Undiagnosed Diseases Network clinical sites, and externally validated it on 16,357 real-world clinical notes from Vanderbilt University Medical Center. Using clinician-curated HPO terms as the gold standard, RARE-PHENIX consistently outperformed a state-of-the-art deep learning baseline (PhenoBERT) across ontology-based similarity and precision-recall-F1 metrics in end-to-end evaluation (i.e., ontology-based similarity of 0.70 vs. 0.58). Ablation analyses demonstrated performance improvements with the addition of each module in RARE-PHENIX (extraction, standardization, and prioritization), supporting the value of modeling the full clinical phenotyping workflow. By modeling phenotyping as a clinically aligned workflow rather than a single extraction task, RARE-PHENIX provides structured, ranked phenotypes that are more concordant with clinician curation and has the potential to support human-in-the-loop rare disease diagnosis in real-world settings.

</details>


### [81] [DMCD: Semantic-Statistical Framework for Causal Discovery](https://arxiv.org/abs/2602.20333)
*Samarth KaPatel,Sofia Nikiforova,Giacinto Paolo Saggese,Paul Smith*

Main category: cs.AI

TL;DR: DMCD是一种结合语义先验和统计验证的因果发现框架，在真实世界数据集上表现出色。


<details>
  <summary>Details</summary>
Motivation: 为了提高因果发现的效果和效率，本文提出了一种名为DMCD的因果发现框架。

Method: DMCD框架分为两个阶段：第一阶段使用大型语言模型根据变量元数据生成稀疏的DAG草图；第二阶段通过条件独立性测试对草图进行审计和优化。

Result: 在三个真实世界的数据集上，DMCD在召回率和F1分数方面取得了优异的性能，尤其是在语义推理方面。

Conclusion: DMCD通过结合语义先验和统计验证，实现了因果结构学习的高效和准确。

Abstract: We present DMCD (DataMap Causal Discovery), a two-phase causal discovery framework that integrates LLM-based semantic drafting from variable metadata with statistical validation on observational data. In Phase I, a large language model proposes a sparse draft DAG, serving as a semantically informed prior over the space of possible causal structures. In Phase II, this draft is audited and refined via conditional independence testing, with detected discrepancies guiding targeted edge revisions.
  We evaluate our approach on three metadata-rich real-world benchmarks spanning industrial engineering, environmental monitoring, and IT systems analysis. Across these datasets, DMCD achieves competitive or leading performance against diverse causal discovery baselines, with particularly large gains in recall and F1 score. Probing and ablation experiments suggest that these improvements arise from semantic reasoning over metadata rather than memorization of benchmark graphs. Overall, our results demonstrate that combining semantic priors with principled statistical verification yields a high-performing and practically effective approach to causal structure learning.

</details>


### [82] [Diffusion Modulation via Environment Mechanism Modeling for Planning](https://arxiv.org/abs/2602.20422)
*Hanping Zhang,Yuhong Guo*

Main category: cs.AI

TL;DR: DMEMM通过环境机制调节扩散模型训练，在离线强化学习轨迹生成中取得最先进的性能。


<details>
  <summary>Details</summary>
Motivation: Diffusion models have shown promising capabilities in trajectory generation for planning in offline reinforcement learning (RL). However, conventional diffusion-based planning methods often fail to account for the fact that generating trajectories in RL requires unique consistency between transitions to ensure coherence in real environments.

Method: We propose a novel diffusion-based planning method, termed as Diffusion Modulation via Environment Mechanism Modeling (DMEMM). DMEMM modulates diffusion model training by incorporating key RL environment mechanisms, particularly transition dynamics and reward functions.

Result: Experimental results demonstrate that DMEMM achieves state-of-the-art performance for planning with offline reinforcement learning.

Conclusion: DMEMM provides a novel and effective solution for trajectory generation in offline reinforcement learning by modulating diffusion model training with environment mechanisms.

Abstract: Diffusion models have shown promising capabilities in trajectory generation for planning in offline reinforcement learning (RL). However, conventional diffusion-based planning methods often fail to account for the fact that generating trajectories in RL requires unique consistency between transitions to ensure coherence in real environments. This oversight can result in considerable discrepancies between the generated trajectories and the underlying mechanisms of a real environment. To address this problem, we propose a novel diffusion-based planning method, termed as Diffusion Modulation via Environment Mechanism Modeling (DMEMM). DMEMM modulates diffusion model training by incorporating key RL environment mechanisms, particularly transition dynamics and reward functions. Experimental results demonstrate that DMEMM achieves state-of-the-art performance for planning with offline reinforcement learning.

</details>


### [83] [Implicit Intelligence -- Evaluating Agents on What Users Don't Say](https://arxiv.org/abs/2602.20424)
*Ved Sirdeshmukh,Marc Wetter*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Real-world requests to AI agents are fundamentally underspecified. Natural human communication relies on shared context and unstated constraints that speakers expect listeners to infer. Current agentic benchmarks test explicit instruction-following but fail to evaluate whether agents can reason about implicit requirements spanning accessibility needs, privacy boundaries, catastrophic risks, and contextual constraints. We present Implicit Intelligence, an evaluation framework testing whether AI agents can move beyond prompt-following to become genuine goal-fulfillers, paired with Agent-as-a-World (AaW), a harness where interactive worlds are defined in human-readable YAML files and simulated by language models. Our scenarios feature apparent simplicity in user requests, hidden complexity in correct solutions, and discoverability of constraints through environmental exploration. Evaluating 16 frontier and open-weight models across 205 scenarios, we find that even the best-performing model achieves only 48.3% scenario pass rate, revealing substantial room for improvement in bridging the gap between literal instruction-following and human-like contextual reasoning.

</details>


### [84] [PreScience: A Benchmark for Forecasting Scientific Contributions](https://arxiv.org/abs/2602.20459)
*Anirudh Ajith,Amanpreet Singh,Jay DeYoung,Nadav Kunievsky,Austin C. Kozlowski,Oyvind Tafjord,James Evans,Daniel S. Weld,Tom Hope,Doug Downey*

Main category: cs.AI

TL;DR: PreScience基准通过分解研究过程预测科学进步，但当前模型在多样性和新颖性方面仍有提升空间。


<details>
  <summary>Details</summary>
Motivation: 预测科学进步以帮助研究人员识别合作者和有影响力的研究方向，并预测哪些问题和方法将成为未来中心。

Method: 提出PreScience基准，将研究过程分解为四个相互依存的生成任务：合作者预测、先前工作选择、贡献生成和影响预测。

Result: 发现每个任务都存在大量提升空间，例如在贡献生成中，前沿LLM与真实情况（GPT-5，平均得分为5.6分）只有适度的相似性。当组成12个月的端到端科学生产模拟时，生成的合成语料库在多样性和新颖性方面都系统地低于同一时期的人类作者研究。

Conclusion: PreScience基准为科学预测提供了有价值的工具，但当前模型在多样性和新颖性方面仍有提升空间。

Abstract: Can AI systems trained on the scientific record up to a fixed point in time forecast the scientific advances that follow? Such a capability could help researchers identify collaborators and impactful research directions, and anticipate which problems and methods will become central next. We introduce PreScience -- a scientific forecasting benchmark that decomposes the research process into four interdependent generative tasks: collaborator prediction, prior work selection, contribution generation, and impact prediction. PreScience is a carefully curated dataset of 98K recent AI-related research papers, featuring disambiguated author identities, temporally aligned scholarly metadata, and a structured graph of companion author publication histories and citations spanning 502K total papers. We develop baselines and evaluations for each task, including LACERScore, a novel LLM-based measure of contribution similarity that outperforms previous metrics and approximates inter-annotator agreement. We find substantial headroom remains in each task -- e.g. in contribution generation, frontier LLMs achieve only moderate similarity to the ground-truth (GPT-5, averages 5.6 on a 1-10 scale). When composed into a 12-month end-to-end simulation of scientific production, the resulting synthetic corpus is systematically less diverse and less novel than human-authored research from the same period.

</details>


### [85] [CausalReasoningBenchmark: A Real-World Benchmark for Disentangled Evaluation of Causal Identification and Estimation](https://arxiv.org/abs/2602.20571)
*Ayush Sawarni,Jiyuan Tan,Vasilis Syrgkanis*

Main category: cs.AI

TL;DR: CausalReasoningBenchmark是一个用于评估自动因果推理系统性能的基准，它揭示了研究设计细节在因果推理中的重要性。


<details>
  <summary>Details</summary>
Motivation: 许多自动因果推理的基准评估系统性能是基于单个数值输出，如平均处理效应（ATE）。这种方法混淆了因果分析中的两个不同步骤：识别-在给定假设下制定有效的科研设计-估计-在有限数据上实现该设计。

Method: 我们引入了CausalReasoningBenchmark，这是一个包含173个查询的基准，涵盖了138个真实世界数据集，这些数据集来自85篇同行评审的研究论文和四本广泛使用的因果推理教科书。对于每个查询，系统必须生成（i）一个结构化的识别规范，其中包含策略、处理、结果和控制变量以及所有设计特定元素，以及（ii）一个点估计和标准误差。通过分别评分这两个组件，我们的基准可以实现细粒度诊断：它区分了因果推理失败和数值执行错误。

Result: 基准结果表明，虽然该模型在84%的情况下正确地识别了高级策略，但完整的识别规范正确率降至只有30%，表明瓶颈在于研究设计的细微细节，而不是计算。CausalReasoningBenchmark在Hugging Face上公开提供，旨在促进更稳健的自动因果推理系统的发展。

Conclusion: CausalReasoningBenchmark有助于提高自动因果推理系统的稳健性，并揭示了研究设计细节在因果推理中的重要性。

Abstract: Many benchmarks for automated causal inference evaluate a system's performance based on a single numerical output, such as an Average Treatment Effect (ATE). This approach conflates two distinct steps in causal analysis: identification-formulating a valid research design under stated assumptions-and estimation-implementing that design numerically on finite data. We introduce CausalReasoningBenchmark, a benchmark of 173 queries across 138 real-world datasets, curated from 85 peer-reviewed research papers and four widely-used causal-inference textbooks. For each query a system must produce (i) a structured identification specification that names the strategy, the treatment, outcome, and control variables, and all design-specific elements, and (ii) a point estimate with a standard error. By scoring these two components separately, our benchmark enables granular diagnosis: it distinguishes failures in causal reasoning from errors in numerical execution. Baseline results with a state-of-the-art LLM show that, while the model correctly identifies the high-level strategy in 84 % of cases, full identification-specification correctness drops to only 30 %, revealing that the bottleneck lies in the nuanced details of research design rather than in computation. CausalReasoningBenchmark is publicly available on Hugging Face and is designed to foster the development of more robust automated causal-inference systems.

</details>


### [86] [POMDPPlanners: Open-Source Package for POMDP Planning](https://arxiv.org/abs/2602.20810)
*Yaacov Pariente,Vadim Indelman*

Main category: cs.AI

TL;DR: POMDPPlanners是一个用于评估POMDP规划算法的Python包，旨在提高不确定性决策研究的可扩展性和可重复性。


<details>
  <summary>Details</summary>
Motivation: 为了使决策在不确定性下的研究可扩展和可重复，特别是在标准工具包不足的风险敏感设置中。

Method: 开发了一个名为POMDPPlanners的Python包，用于评估POMDP规划算法。该包集成了最先进的规划算法、一系列基准环境以及安全关键变体。它还提供了自动化的超参数优化、持久缓存和并行模拟配置。

Result: POMDPPlanners可以减少大量模拟研究的工作量，并促进在不确定性决策领域的可扩展、可重复的研究。

Conclusion: POMDPPlanners为在不确定性决策领域的风险敏感设置提供了一个强大的工具，有助于提高研究的质量和效率。

Abstract: We present POMDPPlanners, an open-source Python package for empirical evaluation of Partially Observable Markov Decision Process (POMDP) planning algorithms. The package integrates state-of-the-art planning algorithms, a suite of benchmark environments with safety-critical variants, automated hyperparameter optimization via Optuna, persistent caching with failure recovery, and configurable parallel simulation -- reducing the overhead of extensive simulation studies. POMDPPlanners is designed to enable scalable, reproducible research on decision-making under uncertainty, with particular emphasis on risk-sensitive settings where standard toolkits fall short.

</details>


### [87] [Qwen-BIM: developing large language model for BIM-based design with domain-specific benchmark and dataset](https://arxiv.org/abs/2602.20812)
*Jia-Rui Lin,Yun-Hong Cai,Xiang-Rui Ni,Shaojie Zhou,Peng Pan*

Main category: cs.AI

TL;DR: 开发了一个基于BIM的领域特定LLM，提高了LLM在BIM设计任务中的性能。


<details>
  <summary>Details</summary>
Motivation: BIM基于设计的发展需要LLM的推动，但缺乏特定数据集和LLM评估基准限制了LLM的性能。

Method: 提出了一种BIM基于设计的评估基准，包括相应的定量指标，用于评估LLM的性能；开发了一种从BIM生成文本数据的方法，构建相应的BIM衍生数据集，用于LLM评估和微调；提出了一种微调策略，以适应BIM基于设计。

Result: 提出的方法和基准提高了LLM在BIM基于设计任务中的性能，Qwen-BIM在G-Eval评分上比基线LLM模型平均提高了21.0%。

Conclusion: 该研究通过引入全面的基准和高质量的数据集，开发出了第一个基于BIM的领域特定LLM，为各种领域的BIM相关LLM的发展奠定了坚实的基础。

Abstract: As the construction industry advances toward digital transformation, BIM (Building Information Modeling)-based design has become a key driver supporting intelligent construction. Despite Large Language Models (LLMs) have shown potential in promoting BIM-based design, the lack of specific datasets and LLM evaluation benchmarks has significantly hindered the performance of LLMs. Therefore, this paper addresses this gap by proposing: 1) an evaluation benchmark for BIM-based design together with corresponding quantitative indicators to evaluate the performance of LLMs, 2) a method for generating textual data from BIM and constructing corresponding BIM-derived datasets for LLM evaluation and fine-tuning, and 3) a fine-tuning strategy to adapt LLMs for BIM-based design. Results demonstrate that the proposed domain-specific benchmark effectively and comprehensively assesses LLM capabilities, highlighting that general LLMs are still incompetent for domain-specific tasks. Meanwhile, with the proposed benchmark and datasets, Qwen-BIM is developed and achieves a 21.0% average increase in G-Eval score compared to the base LLM model. Notably, with only 14B parameters, performance of Qwen-BIM is comparable to that of general LLMs with 671B parameters for BIM-based design tasks. Overall, this study develops the first domain-specific LLM for BIM-based design by introducing a comprehensive benchmark and high-quality dataset, which provide a solid foundation for developing BIM-related LLMs in various fields.

</details>


### [88] [Pressure Reveals Character: Behavioural Alignment Evaluation at Depth](https://arxiv.org/abs/2602.20813)
*Nora Petrova,John Burden*

Main category: cs.AI

TL;DR: 我们需要一个全面的评估框架来评估语言模型的对齐性，我们提供了一个新的基准和排行榜来支持持续评估。


<details>
  <summary>Details</summary>
Motivation: 评估语言模型的对齐性需要测试它们在现实压力下的行为，而不仅仅是它们声称会做什么。随着对齐失败越来越导致现实世界的危害，仍然缺乏具有现实多轮场景的全面评估框架。

Method: 我们引入了一个对齐基准，包含904个场景，涵盖六个类别：诚实、安全、非操纵、鲁棒性、可纠正性和策划。这些场景被人类评审验证为现实。我们评估了24个前沿模型，使用LLM评审员与人类标注进行验证，发现即使表现最好的模型在某些类别中也有差距，而大多数模型在各方面都表现出一致的弱点。因素分析显示，对齐行为作为一个统一的结构（类似于认知研究中的g因素），在某个类别得分高的模型往往在其他类别中也得分高。

Result: 我们发现即使是表现最好的模型在某些类别中也有差距，而大多数模型在各方面都表现出一致的弱点。我们还发现对齐行为作为一个统一的结构，在某个类别得分高的模型往往在其他类别中也得分高。

Conclusion: 我们需要一个全面、具有现实多轮场景的评估框架来评估语言模型的对齐性。我们的基准和交互式排行榜旨在支持持续评估，并计划在未来扩展场景和添加新模型。

Abstract: Evaluating alignment in language models requires testing how they behave under realistic pressure, not just what they claim they would do. While alignment failures increasingly cause real-world harm, comprehensive evaluation frameworks with realistic multi-turn scenarios remain lacking. We introduce an alignment benchmark spanning 904 scenarios across six categories -- Honesty, Safety, Non-Manipulation, Robustness, Corrigibility, and Scheming -- validated as realistic by human raters. Our scenarios place models under conflicting instructions, simulated tool access, and multi-turn escalation to reveal behavioural tendencies that single-turn evaluations miss. Evaluating 24 frontier models using LLM judges validated against human annotations, we find that even top-performing models exhibit gaps in specific categories, while the majority of models show consistent weaknesses across the board. Factor analysis reveals that alignment behaves as a unified construct (analogous to the g-factor in cognitive research) with models scoring high on one category tending to score high on others. We publicly release the benchmark and an interactive leaderboard to support ongoing evaluation, with plans to expand scenarios in areas where we observe persistent weaknesses and to add new models as they are released.

</details>


### [89] [Diagnosing Causal Reasoning in Vision-Language Models via Structured Relevance Graphs](https://arxiv.org/abs/2602.20878)
*Dhita Putri Pratama,Soyeon Caren Han,Yihao Ding*

Main category: cs.AI

TL;DR: 通过引入VLCGs和ViLCaR基准，发现LVLM的因果推理局限性源于结构指导不足。


<details>
  <summary>Details</summary>
Motivation: 评估视觉-语言模型在视觉问答基准上的表现，但它们通常依赖于虚假的相关性而不是真正的因果推理。

Method: 引入视觉-语言因果图（VLCGs），这是一种结构化、查询条件的表示，明确编码因果相关的对象、属性、关系和场景基础假设。基于这种表示，我们提出了ViLCaR，这是一个包含因果归因、因果推理和问答任务的诊断基准，以及与图对齐的评估指标，以评估相关性识别，而不仅仅是最终答案的准确性。

Result: 在最新的视觉-语言大模型（LVLM）中的实验表明，注入结构化相关性信息与零样本和标准情境学习相比，显著提高了归因和推理的一致性。

Conclusion: 当前LVLM因果推理的局限性主要源于结构指导不足，而不是推理能力不足。

Abstract: Large Vision-Language Models (LVLMs) achieve strong performance on visual question answering benchmarks, yet often rely on spurious correlations rather than genuine causal reasoning. Existing evaluations primarily assess the correctness of the answers, making it unclear whether failures arise from limited reasoning capability or from misidentifying causally relevant information. We introduce Vision-Language Causal Graphs (VLCGs), a structured, query-conditioned representation that explicitly encodes causally relevant objects, attributes, relations, and scene-grounded assumptions. Building on this representation, we present ViLCaR, a diagnostic benchmark comprising tasks for Causal Attribution, Causal Inference, and Question Answering, along with graph-aligned evaluation metrics that assess relevance identification beyond final answer accuracy. Experiments in state-of-the-art LVLMs show that injecting structured relevance information significantly improves attribution and inference consistency compared to zero-shot and standard in-context learning. These findings suggest that current limitations in LVLM causal reasoning stem primarily from insufficient structural guidance rather than a lack of reasoning capacity.

</details>


### [90] [HELP: HyperNode Expansion and Logical Path-Guided Evidence Localization for Accurate and Efficient GraphRAG](https://arxiv.org/abs/2602.20926)
*Yuqi Huang,Ning Liao,Kai Yang,Anning Hu,Shengchao Hu,Xiaoxing Wang,Junchi Yan*

Main category: cs.AI

TL;DR: 提出了一种新的GraphRAG框架，通过HyperNode Expansion和Logical Path-Guided Evidence Localization策略，提高了RAG的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: LLMs在知识密集型任务中的可靠性受限，因为它们往往存在固有的知识边界和幻觉问题。

Method: 提出HyperNode Expansion和Logical Path-Guided Evidence Localization策略，用于GraphRAG（HELP）框架，以平衡准确性和效率。

Result: 实验表明，HELP在多个简单和多跳QA基准测试中表现出竞争力，并且比领先的基于图的RAG基线快28.8倍。

Conclusion: HELP通过避免昂贵的随机游走和语义扭曲，在保持知识完整性的同时，显著降低了检索延迟。

Abstract: Large Language Models (LLMs) often struggle with inherent knowledge boundaries and hallucinations, limiting their reliability in knowledge-intensive tasks. While Retrieval-Augmented Generation (RAG) mitigates these issues, it frequently overlooks structural interdependencies essential for multi-hop reasoning. Graph-based RAG approaches attempt to bridge this gap, yet they typically face trade-offs between accuracy and efficiency due to challenges such as costly graph traversals and semantic noise in LLM-generated summaries. In this paper, we propose HyperNode Expansion and Logical Path-Guided Evidence Localization strategies for GraphRAG (HELP), a novel framework designed to balance accuracy with practical efficiency through two core strategies: 1) HyperNode Expansion, which iteratively chains knowledge triplets into coherent reasoning paths abstracted as HyperNodes to capture complex structural dependencies and ensure retrieval accuracy; and 2) Logical Path-Guided Evidence Localization, which leverages precomputed graph-text correlations to map these paths directly to the corpus for superior efficiency. HELP avoids expensive random walks and semantic distortion, preserving knowledge integrity while drastically reducing retrieval latency. Extensive experiments demonstrate that HELP achieves competitive performance across multiple simple and multi-hop QA benchmarks and up to a 28.8$\times$ speedup over leading Graph-based RAG baselines.

</details>


### [91] [CG-DMER: Hybrid Contrastive-Generative Framework for Disentangled Multimodal ECG Representation Learning](https://arxiv.org/abs/2602.21154)
*Ziwei Niu,Hao Sun,Shujun Bian,Xihong Yang,Lanfen Lin,Yuxin Liu,Yueming Jin*

Main category: cs.AI

TL;DR: CG-DMER是一种新的ECG表示学习方法，在心血管疾病诊断中表现出色。


<details>
  <summary>Details</summary>
Motivation: 准确解释心电图（ECG）信号对于诊断心血管疾病至关重要。

Method: 提出了一种名为CG-DMER的对比生成框架，用于解耦多模态ECG表示学习。

Result: 在三个公共数据集上的实验表明，CG-DMER在各种下游任务中实现了最先进的性能。

Conclusion: CG-DMER能够有效解决现有方法的模态内和模态间问题，提高了ECG信号处理的准确性。

Abstract: Accurate interpretation of electrocardiogram (ECG) signals is crucial for diagnosing cardiovascular diseases. Recent multimodal approaches that integrate ECGs with accompanying clinical reports show strong potential, but they still face two main concerns from a modality perspective: (1) intra-modality: existing models process ECGs in a lead-agnostic manner, overlooking spatial-temporal dependencies across leads, which restricts their effectiveness in modeling fine-grained diagnostic patterns; (2) inter-modality: existing methods directly align ECG signals with clinical reports, introducing modality-specific biases due to the free-text nature of the reports. In light of these two issues, we propose CG-DMER, a contrastive-generative framework for disentangled multimodal ECG representation learning, powered by two key designs: (1) Spatial-temporal masked modeling is designed to better capture fine-grained temporal dynamics and inter-lead spatial dependencies by applying masking across both spatial and temporal dimensions and reconstructing the missing information. (2) A representation disentanglement and alignment strategy is designed to mitigate unnecessary noise and modality-specific biases by introducing modality-specific and modality-shared encoders, ensuring a clearer separation between modality-invariant and modality-specific representations. Experiments on three public datasets demonstrate that CG-DMER achieves state-of-the-art performance across diverse downstream tasks.

</details>
