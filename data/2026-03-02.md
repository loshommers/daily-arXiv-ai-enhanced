<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 77]
- [cs.CL](#cs.CL) [Total: 27]
- [stat.ML](#stat.ML) [Total: 7]
- [cs.CR](#cs.CR) [Total: 11]
- [cs.AI](#cs.AI) [Total: 20]
- [cs.LG](#cs.LG) [Total: 53]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [DesignSense: A Human Preference Dataset and Reward Modeling Framework for Graphic Layout Generation](https://arxiv.org/abs/2602.23438)
*Varun Gopal,Rishabh Jain,Aradhya Mathur,Nikitha SR,Sohan Patnaik,Sudhir Yarram,Mayur Hemani,Balaji Krishnamurthy,Mausoom Sarkar*

Main category: cs.CV

TL;DR: DesignSense模型在图形布局评估和生成方面表现出色，为视觉语言模型的发展提供了新的方向。


<details>
  <summary>Details</summary>
Motivation: 图形布局作为视觉通信的重要和吸引人的媒介，现有的布局生成模型在细微的人类审美判断方面存在不足。

Method: 创建DesignSense-10k数据集，提出五阶段编辑流程，并训练DesignSense视觉语言模型分类器。

Result: DesignSense在多项评估指标上显著优于现有模型，并在布局生成方面带来实际效益。

Conclusion: 设计Sense模型在图形布局评估和生成方面表现出色，但前沿的视觉语言模型仍需改进。

Abstract: Graphic layouts serve as an important and engaging medium for visual communication across different channels. While recent layout generation models have demonstrated impressive capabilities, they frequently fail to align with nuanced human aesthetic judgment. Existing preference datasets and reward models trained on text-to-image generation do not generalize to layout evaluation, where the spatial arrangement of identical elements determines quality. To address this critical gap, we introduce DesignSense-10k, a large-scale dataset of 10,235 human-annotated preference pairs for graphic layout evaluation. We propose a five-stage curation pipeline that generates visually coherent layout transformations across diverse aspect ratios, using semantic grouping, layout prediction, filtering, clustering, and VLM-based refinement to produce high-quality comparison pairs. Human preferences are annotated using a 4-class scheme (left, right, both good, both bad) to capture subjective ambiguity. Leveraging this dataset, we train DesignSense, a vision-language model-based classifier that substantially outperforms existing open-source and proprietary models across comprehensive evaluation metrics (54.6% improvement in Macro F1 over the strongest proprietary baseline). Our analysis shows that frontier VLMs remain unreliable overall and fail catastrophically on the full four-class task, underscoring the need for specialized, preference-aware models. Beyond the dataset, our reward model DesignSense yields tangible downstream gains in layout generation. Using our judge during RL based training improves generator win rate by about 3%, while inference-time scaling, which involves generating multiple candidates and selecting the best one, provides a 3.6% improvement. These results highlight the practical impact of specialized, layout-aware preference modeling on real-world layout generation quality.

</details>


### [2] [Modelling and Simulation of Neuromorphic Datasets for Anomaly Detection in Computer Vision](https://arxiv.org/abs/2602.23514)
*Mike Middleton,Teymoor Ali,Hakan Kayan,Basabdatta Sen Bhattacharya,Charith Perera,Oliver Rhodes,Elena Gheorghiu,Mark Vousden,Martin A. Trefzer*

Main category: cs.CV

TL;DR: ANTShapes是一种模拟神经形态视觉数据集的新框架，旨在解决数据可用性问题。


<details>
  <summary>Details</summary>
Motivation: 限制动态视觉传感器（DVS）的可用性对神经形态计算机视觉研究人员构成挑战。

Method: 我们引入了异常神经形态工具形状（ANTShapes），这是一个新的数据集模拟框架。在Unity引擎中构建，ANTShapes模拟了由具有随机生成行为（描述运动和旋转等属性）的对象组成的抽象、可配置的3D场景。

Result: ANTShapes可以创建和导出包含任意数量样本的数据集，包括伴随的标签和帧数据，通过调整软件中的少量参数。

Conclusion: ANTShapes通过允许模拟定制数据集来解决基于事件的计算机视觉研究人员的数据可用性限制，以适应包括对象识别、定位和异常检测在内的用途。

Abstract: Limitations on the availability of Dynamic Vision Sensors (DVS) present a fundamental challenge to researchers of neuromorphic computer vision applications. In response, datasets have been created by the research community, but often contain a limited number of samples or scenarios. To address the lack of a comprehensive simulator of neuromorphic vision datasets, we introduce the Anomalous Neuromorphic Tool for Shapes (ANTShapes), a novel dataset simulation framework. Built in the Unity engine, ANTShapes simulates abstract, configurable 3D scenes populated by objects displaying randomly-generated behaviours describing attributes such as motion and rotation. The sampling of object behaviours, and the labelling of anomalously-acting objects, is a statistical process following central limit theorem principles. Datasets containing an arbitrary number of samples can be created and exported from ANTShapes, along with accompanying label and frame data, through the adjustment of a limited number of parameters within the software. ANTShapes addresses the limitations of data availability to researchers of event-based computer vision by allowing for the simulation of bespoke datasets to suit purposes including object recognition and localisation alongside anomaly detection.

</details>


### [3] [All in One: Unifying Deepfake Detection, Tampering Localization, and Source Tracing with a Robust Landmark-Identity Watermark](https://arxiv.org/abs/2602.23523)
*Junjiang Wu,Liejun Wang,Zhiqing Guo*

Main category: cs.CV

TL;DR: 提出了一种统一的主动取证框架，用于检测、定位和追踪深度伪造内容，具有统一、鲁棒和不易察觉的特点。


<details>
  <summary>Details</summary>
Motivation: 随着深度伪造技术的快速发展，恶意的人脸操纵对个人隐私和社会安全构成了重大威胁。然而，现有的主动取证方法通常将深度伪造检测、篡改定位和溯源视为独立的任务，缺乏一个统一的框架来共同解决这些问题。

Method: 我们提出了一种统一的主动取证框架，该框架采用了一种创新的152维地标-身份水印，称为LIDMark，它将面部地标与独特的源标识符结构性地交织在一起。为了鲁棒地提取LIDMark，我们设计了一种新的因子头解码器（FHD）。其架构将共享骨干特征分解为两个专用头（即回归和分类），分别鲁棒地重建嵌入的地标和标识符，即使在严重扭曲或篡改的情况下也是如此。这种设计实现了一个“一站式”的三功能取证解决方案：回归头为检测和定位提供了“内在-外在”一致性检查，而分类头鲁棒地解码源标识符以进行追踪。

Result: 广泛的实验表明，所提出的LIDMark框架为深度伪造内容的检测、定位和追踪提供了一个统一、鲁棒且不易察觉的解决方案。

Conclusion: LIDMark框架为深度伪造内容的检测、定位和溯源提供了一种有效的解决方案，具有统一、鲁棒和不易察觉的特点。

Abstract: With the rapid advancement of deepfake technology, malicious face manipulations pose a significant threat to personal privacy and social security. However, existing proactive forensics methods typically treat deepfake detection, tampering localization, and source tracing as independent tasks, lacking a unified framework to address them jointly. To bridge this gap, we propose a unified proactive forensics framework that jointly addresses these three core tasks. Our core framework adopts an innovative 152-dimensional landmark-identity watermark termed LIDMark, which structurally interweaves facial landmarks with a unique source identifier. To robustly extract the LIDMark, we design a novel Factorized-Head Decoder (FHD). Its architecture factorizes the shared backbone features into two specialized heads (i.e., regression and classification), robustly reconstructing the embedded landmarks and identifier, respectively, even when subjected to severe distortion or tampering. This design realizes an "all-in-one" trifunctional forensic solution: the regression head underlies an "intrinsic-extrinsic" consistency check for detection and localization, while the classification head robustly decodes the source identifier for tracing. Extensive experiments show that the proposed LIDMark framework provides a unified, robust, and imperceptible solution for the detection, localization, and tracing of deepfake content. The code is available at https://github.com/vpsg-research/LIDMark.

</details>


### [4] [Synthetic Visual Genome 2: Extracting Large-scale Spatio-Temporal Scene Graphs from Videos](https://arxiv.org/abs/2602.23543)
*Ziqi Gao,Jieyu Zhang,Wisdom Oluchi Ikezogwo,Jae Sung Park,Tario G. You,Daniel Ogbu,Chenhao Zheng,Weikai Huang,Yinuo Yang,Winson Han,Quan Kong,Rajat Saini,Ranjay Krishna*

Main category: cs.CV

TL;DR: 我们开发了SVG2，一个大规模跨时空场景图数据集，并基于此训练了TRaSER模型，提高了视频场景图生成的准确性。


<details>
  <summary>Details</summary>
Motivation: 为了提供更大的规模和多样性，我们介绍了Synthetic Visual Genome 2（SVG2），这是一个大规模的跨时空场景图数据集。

Method: 我们设计了一个全自动流程来创建SVG2，该流程结合了多尺度全景分割、在线-离线轨迹跟踪、自动新对象发现、轨迹语义解析和基于GPT-5的时空关系推理。

Result: 基于SVG2数据集，我们训练了TRaSER，一个视频场景图生成模型。TRaSER在PVSG、VIPSeg、VidOR和SVG2测试数据集上提高了关系检测、对象预测和属性预测的准确性。

Conclusion: TRaSER生成的场景图在视频问答任务中表现良好，证明了显式时空场景图作为中间表示的效用。

Abstract: We introduce Synthetic Visual Genome 2 (SVG2), a large-scale panoptic video scene graph dataset. SVG2 contains over 636K videos with 6.6M objects, 52.0M attributes, and 6.7M relations, providing an order-of-magnitude increase in scale and diversity over prior spatio-temporal scene graph datasets. To create SVG2, we design a fully automated pipeline that combines multi-scale panoptic segmentation, online-offline trajectory tracking with automatic new-object discovery, per-trajectory semantic parsing, and GPT-5-based spatio-temporal relation inference. Building on this resource, we train TRaSER, a video scene graph generation model. TRaSER augments VLMs with a trajectory-aligned token arrangement mechanism and new modules: an object-trajectory resampler and a temporal-window resampler to convert raw videos and panoptic trajectories into compact spatio-temporal scene graphs in a single forward pass. The temporal-window resampler binds visual tokens to short trajectory segments to preserve local motion and temporal semantics, while the object-trajectory resampler aggregates entire trajectories to maintain global context for objects. On the PVSG, VIPSeg, VidOR and SVG2 test datasets, TRaSER improves relation detection by +15 to 20%, object prediction by +30 to 40% over the strongest open-source baselines and by +13% over GPT-5, and attribute prediction by +15%. When TRaSER's generated scene graphs are sent to a VLM for video question answering, it delivers a +1.5 to 4.6% absolute accuracy gain over using video only or video augmented with Qwen2.5-VL's generated scene graphs, demonstrating the utility of explicit spatio-temporal scene graphs as an intermediate representation.

</details>


### [5] [LE-NeuS: Latency-Efficient Neuro-Symbolic Video Understanding via Adaptive Temporal Verification](https://arxiv.org/abs/2602.23553)
*Shawn Liang,Sahil Shah,Chengwei Zhou,SP Sharan,Harsh Goel,Arnab Sanyal,Sandeep Chinchali,Gourav Datta*

Main category: cs.CV

TL;DR: LE-NeuS improves LVQA efficiency with reduced latency and maintained accuracy.


<details>
  <summary>Details</summary>
Motivation: Neuro-symbolic approaches to LVQA have shown significant accuracy improvements, but existing methods have high latency, making them impractical for edge deployments.

Method: LE-NeuS, a latency-efficient neuro-symbolic framework that optimizes automaton construction through two-stage adaptive sampling and batched proposition detection.

Result: LE-NeuS reduces latency from 90x to approximately 10x while maintaining >10% accuracy gains on temporally complex queries.

Conclusion: LE-NeuS is a practical solution for LVQA with reduced latency and maintained accuracy.

Abstract: Neuro-symbolic approaches to long-form video question answering (LVQA) have demonstrated significant accuracy improvements by grounding temporal reasoning in formal verification. However, existing methods incur prohibitive latency overheads, up to 90x slower than base VLM prompting, rendering them impractical for latency-sensitive edge deployments. We present LE-NeuS, a latency-efficient neuro-symbolic framework that preserves the accuracy benefits of temporal logic-guided video understanding while drastically reducing inference latency. Our key insight is that the dominant computational bottleneck arises from sequential and dense proposition detection across video frames during automaton construction. We address this through two principled optimizations: (1) CLIP guided two-stage adaptive sampling that exploits visual redundancy to skip semantically similar frames while preserving temporal boundaries, and (2) batched proposition detection that parallelizes VLM inference across temporal windows. Theoretically, we derive latency bounds as a function of video length, proposition complexity, and sampling density, establishing conditions under which latency efficiency is achievable. Empirically, on LongVideoBench and Video-MME benchmarks deployed on NVIDIA H100 GPUs, LE-NeuS reduces the latency gap from 90x to approximately 10x while maintaining >10% accuracy gains on temporally complex queries.

</details>


### [6] [No Calibration, No Depth, No Problem: Cross-Sensor View Synthesis with 3D Consistency](https://arxiv.org/abs/2602.23559)
*Cho-Ying Wu,Zixun Huang,Xinyu Huang,Liu Ren*

Main category: cs.CV

TL;DR: 本研究提出了一种无校准的RGB-X视角合成方法，提高了跨传感器学习的普及率。


<details>
  <summary>Details</summary>
Motivation: 研究跨传感器视角合成在不同模态之间的第一个研究，解决RGB-X数据对齐的问题，减少工程量，提高跨传感器学习的普及率。

Method: 提出了一种匹配-细化-巩固的方法，包括RGB-X图像匹配、引导点细化、置信度感知细化、自匹配过滤和3D高斯分层（3DGS）。

Result: 实现更好的视角合成，无需3D先验知识，仅假设RGB的COLMAP成本极低。

Conclusion: 该研究为RGB-X传感器提供了无繁琐校准的解决方案，突破了大规模真实世界RGB-X数据收集的瓶颈。

Abstract: We present the first study of cross-sensor view synthesis across different modalities. We examine a practical, fundamental, yet widely overlooked problem: getting aligned RGB-X data, where most RGB-X prior work assumes such pairs exist and focuses on modality fusion, but it empirically requires huge engineering effort in calibration. We propose a match-densify-consolidate method. First, we perform RGB-X image matching followed by guided point densification. Using the proposed confidence-aware densification and self-matching filtering, we attain better view synthesis and later consolidate them in 3D Gaussian Splatting (3DGS). Our method uses no 3D priors for X-sensor and only assumes nearly no-cost COLMAP for RGB. We aim to remove the cumbersome calibration for various RGB-X sensors and advance the popularity of cross-sensor learning by a scalable solution that breaks through the bottleneck in large-scale real-world RGB-X data collection.

</details>


### [7] [Evidential Neural Radiance Fields](https://arxiv.org/abs/2602.23574)
*Ruxiao Duan,Alex Wong*

Main category: cs.CV

TL;DR: Evidential Neural Radiance Fields provides a novel approach to uncertainty quantification in NeRFs, improving scene reconstruction fidelity and uncertainty estimation quality.


<details>
  <summary>Details</summary>
Motivation: Understanding sources of uncertainty is fundamental to trustworthy three-dimensional scene modeling.

Method: Introducing Evidential Neural Radiance Fields, a probabilistic approach that seamlessly integrates with the NeRF rendering process and enables direct quantification of both aleatoric and epistemic uncertainty from a single forward pass.

Result: State-of-the-art scene reconstruction fidelity and uncertainty estimation quality demonstrated on three standardized benchmarks.

Conclusion: Evidential Neural Radiance Fields effectively addresses uncertainty quantification issues in NeRFs.

Abstract: Understanding sources of uncertainty is fundamental to trustworthy three-dimensional scene modeling. While recent advances in neural radiance fields (NeRFs) achieve impressive accuracy in scene reconstruction and novel view synthesis, the lack of uncertainty estimation significantly limits their deployment in safety-critical settings. Existing uncertainty quantification methods for NeRFs fail to capture both aleatoric and epistemic uncertainty. Among those that do quantify one or the other, many of them either compromise rendering quality or incur significant computational overhead to obtain uncertainty estimates. To address these issues, we introduce Evidential Neural Radiance Fields, a probabilistic approach that seamlessly integrates with the NeRF rendering process and enables direct quantification of both aleatoric and epistemic uncertainty from a single forward pass. We compare multiple uncertainty quantification methods on three standardized benchmarks, where our approach demonstrates state-of-the-art scene reconstruction fidelity and uncertainty estimation quality.

</details>


### [8] [Hyperdimensional Cross-Modal Alignment of Frozen Language and Image Models for Efficient Image Captioning](https://arxiv.org/abs/2602.23588)
*Abhishek Dalvi,Vasant Honavar*

Main category: cs.CV

TL;DR: HDFLIM是一种新的跨模态对齐框架，它可以在不修改模型本身的情况下实现跨模态对齐，并通过符号操作在超维空间中构建关联的跨模态表示。


<details>
  <summary>Details</summary>
Motivation: 为了解决大型多模态基础模型在视觉和语言领域的语义结构编码问题，以及通常需要计算密集型多模态微调来对齐模型的问题。

Method: 提出了一种名为HDFLIM的框架，该框架在保持预训练的视觉和语言模型完全冻结的情况下建立跨模态映射。HDFLIM将单模态嵌入投影到共享的超维空间，并利用轻量级的符号操作（绑定、捆绑和基于相似性的检索）在单次数据遍历中构建关联的跨模态表示。

Result: HDFLIM在性能上与端到端视觉语言训练方法相当，并生成的字幕在语义上比零样本基线更扎实。

Conclusion: 通过将对齐与参数调整分离，结果表明，通过各自嵌入的超维编码上的符号操作可以实现基础模型之间的语义映射。更广泛地说，这项工作指向了一种替代范式，在这种范式中，冻结的模型通过结构化表示映射而不是通过大规模重新训练来集成。

Abstract: Large unimodal foundation models for vision and language encode rich semantic structures, yet aligning them typically requires computationally intensive multimodal fine-tuning. Such approaches depend on large-scale parameter updates, are resource intensive, and can perturb pretrained representations. Emerging evidence suggests, however, that independently trained foundation models may already exhibit latent semantic compatibility, reflecting shared structures in the data they model. This raises a fundamental question: can cross-modal alignment be achieved without modifying the models themselves? Here we introduce HDFLIM (HyperDimensional computing with Frozen Language and Image Models), a framework that establishes cross-modal mappings while keeping pretrained vision and language models fully frozen. HDFLIM projects unimodal embeddings into a shared hyperdimensional space and leverages lightweight symbolic operations -- binding, bundling, and similarity-based retrieval to construct associative cross-modal representations in a single pass over the data. Caption generation emerges from high-dimensional memory retrieval rather than iterative gradient-based optimization. We show that HDFLIM achieves performance comparable to end-to-end vision-language training methods and produces captions that are more semantically grounded than zero-shot baselines. By decoupling alignment from parameter tuning, our results suggest that semantic mapping across foundation models can be realized through symbolic operations on hyperdimensional encodings of the respective embeddings. More broadly, this work points toward an alternative paradigm for foundation model alignment in which frozen models are integrated through structured representational mappings rather than through large-scale retraining. The codebase for our implementation can be found at https://github.com/Abhishek-Dalvi410/HDFLIM.

</details>


### [9] [Pseudo Contrastive Learning for Diagram Comprehension in Multimodal Models](https://arxiv.org/abs/2602.23589)
*Hiroshi Sasaki*

Main category: cs.CV

TL;DR: 提出了一种新的训练方法，通过引入伪对比样本来提高视觉-语言模型在图解理解方面的性能。


<details>
  <summary>Details</summary>
Motivation: 由于现有的视觉-语言模型对细微结构变化的敏感性有限，因此在图解理解等领域的应用仍存在挑战。

Method: 提出了一种新的训练范式，通过引入由图解渲染器生成的伪对比样本来增强图解理解。这些样本通过随机选择文本元素创建合成图解，突出了图解图像中的结构差异，而无需对原始数据进行任何修改或编辑。

Result: 在流程图基准数据集上的实验评估表明，与标准CLIP和硬负CLIP训练相比，在图像-文本匹配和视觉问答任务中都有显著提升。

Conclusion: 这种方法强调了特定领域训练策略的价值，并有助于在视觉-语言学习的更广泛背景下推进图解理解。

Abstract: Recent multimodal models such as Contrastive Language-Image Pre-training (CLIP) have shown remarkable ability to align visual and linguistic representations. However, domains where small visual differences carry large semantic significance, such as diagram understanding, remain challenging due to the models' limited sensitivity to fine-grained structural variations.
  We propose a new training paradigm designed to enhance diagram comprehension in vision-language models. Our approach introduces pseudo contrastive samples generated by a diagram renderer that creates synthetic diagrams using randomly picked text elements. These samples highlight structural differences in diagrammatic imagery without requiring any modification or editing of the original data. By incorporating these pseudo contrastive samples into the training objective, the model learns to capture more precise and semantically consistent diagram structures.
  Empirical evaluations on a benchmark dataset of flowcharts demonstrate substantial improvements over standard CLIP and hard-negative CLIP training in both image-text matching and visual question answering tasks. The results underscore the value of domain-specific training strategies and contribute to advancing diagrammatic understanding within the broader context of vision-language learning.

</details>


### [10] [Incremental dimension reduction for efficient and accurate visual anomaly detection](https://arxiv.org/abs/2602.23595)
*Teng-Yok Lee*

Main category: cs.CV

TL;DR: 提出了一种增量降维算法，用于加速大数据集上的异常检测算法训练


<details>
  <summary>Details</summary>
Motivation: 减少从图像中提取的特征的维度，以处理包含数千张图像的大数据集

Method: 增量降维算法，将向量分组并计算截断奇异值分解

Result: 加速最先进异常检测算法的训练，精度接近

Conclusion: 该算法有效解决了特征维度过高的问题，提高了大数据集处理的效率

Abstract: While nowadays visual anomaly detection algorithms use deep neural networks to extract salient features from images, the high dimensionality of extracted features makes it difficult to apply those algorithms to large data with 1000s of images. To address this issue, we present an incremental dimension reduction algorithm to reduce the extracted features. While our algorithm essentially computes truncated singular value decomposition of these features, other than processing all vectors at once, our algorithm groups the vectors into batches. At each batch, our algorithm updates the truncated singular values and vectors that represent all visited vectors, and reduces each batch by its own singular values and vectors so they can be stored in the memory with low overhead. After processing all batches, we re-transform these batch-wise singular vectors to the space spanned by the singular vectors of all features. We show that our algorithm can accelerate the training of state-of-the-art anomaly detection algorithm with close accuracy.

</details>


### [11] [Annotation-Free Visual Reasoning for High-Resolution Large Multimodal Models via Reinforcement Learning](https://arxiv.org/abs/2602.23615)
*Jiacheng Yang,Anqi Chen,Yunkai Dang,Qi Fan,Cong Wang,Wenbin Li,Feng Miao,Yang Gao*

Main category: cs.CV

TL;DR: HART是一种无需额外注释即可增强LMMs处理高分辨率视觉输入推理能力的技术。


<details>
  <summary>Details</summary>
Motivation: 当前大型多模态模型（LMMs）在处理高分辨率视觉输入时存在困难，因为图像标记的数量随着分辨率的增加而呈二次方增长，引入了大量的冗余和不相关信息。

Method: 提出了一种名为HART的闭循环框架，使LMMs能够关注并自我验证高分辨率视觉输入的关键区域。HART采用后训练范式，设计了一种名为AP-GRPO的优势偏好组相对策略优化方法，以鼓励对关键区域的准确定位。

Result: HART在各种高分辨率视觉任务中提高了性能，并且优于强大的基线。在应用于Qwen2.5-VL-7B后训练模型时，HART在视觉中心基准测试中甚至超过了Qwen2.5-VL-72B和LLaVA-OneVision-72B等更大规模的模型。

Conclusion: HART是一种有效的技术，可以增强LMMs在处理高分辨率视觉输入时的推理能力，而无需依赖额外的注释。

Abstract: Current Large Multimodal Models (LMMs) struggle with high-resolution visual inputs during the reasoning process, as the number of image tokens increases quadratically with resolution, introducing substantial redundancy and irrelevant information. A common practice is to identify key image regions and refer to their high-resolution counterparts during reasoning, typically trained with external visual supervision. However, such visual supervision cues require costly grounding labels from human annotators. Meanwhile, it remains an open question how to enhance a model's grounding abilities to support reasoning without relying on additional annotations. In this paper, we propose High-resolution Annotation-free Reasoning Technique (HART), a closed-loop framework that enables LMMs to focus on and self-verify key regions of high-resolution visual inputs. HART incorporates a post-training paradigm in which we design Advantage Preference Group Relative Policy Optimization (AP-GRPO) to encourage accurate localization of key regions. Notably, HART provides explainable reasoning pathways and enables efficient optimization of localization. Extensive experiments demonstrate that HART improves performance across a wide range of high-resolution visual tasks, consistently outperforming strong baselines. When applied to post-train Qwen2.5-VL-7B, HART even surpasses larger-scale models such as Qwen2.5-VL-72B and LLaVA-OneVision-72B on high-resolution, vision-centric benchmarks.

</details>


### [12] [Egocentric Visibility-Aware Human Pose Estimation](https://arxiv.org/abs/2602.23618)
*Peng Dai,Yu Zhang,Yiqiang Feng,Zhen Fan,Yang Zhang*

Main category: cs.CV

TL;DR: EvaPose: A novel egocentric visibility-aware HPE method achieving state-of-the-art performance


<details>
  <summary>Details</summary>
Motivation: Egocentric human pose estimation (HPE) using a head-mounted device is crucial for various VR and AR applications, but it faces significant challenges due to keypoint invisibility.

Method: We first present Eva-3M, a large-scale egocentric visibility-aware HPE dataset comprising over 3.0M frames, with 435K of them annotated with keypoint visibility labels. Additionally, we augment the existing EMHI dataset with keypoint visibility annotations to further facilitate the research in this direction. Furthermore, we propose EvaPose, a novel egocentric visibility-aware HPE method that explicitly incorporates visibility information to enhance pose estimation accuracy.

Result: Extensive experiments validate the significant value of ground-truth visibility labels in egocentric HPE settings, and demonstrate that our EvaPose achieves state-of-the-art performance in both Eva-3M and EMHI datasets.

Conclusion: The proposed EvaPose method significantly improves the accuracy of egocentric HPE by incorporating visibility information, and achieves state-of-the-art performance on the Eva-3M and EMHI datasets.

Abstract: Egocentric human pose estimation (HPE) using a head-mounted device is crucial for various VR and AR applications, but it faces significant challenges due to keypoint invisibility. Nevertheless, none of the existing egocentric HPE datasets provide keypoint visibility annotations, and the existing methods often overlook the invisibility problem, treating visible and invisible keypoints indiscriminately during estimation. As a result, their capacity to accurately predict visible keypoints is compromised. In this paper, we first present Eva-3M, a large-scale egocentric visibility-aware HPE dataset comprising over 3.0M frames, with 435K of them annotated with keypoint visibility labels. Additionally, we augment the existing EMHI dataset with keypoint visibility annotations to further facilitate the research in this direction. Furthermore, we propose EvaPose, a novel egocentric visibility-aware HPE method that explicitly incorporates visibility information to enhance pose estimation accuracy. Extensive experiments validate the significant value of ground-truth visibility labels in egocentric HPE settings, and demonstrate that our EvaPose achieves state-of-the-art performance in both Eva-3M and EMHI datasets.

</details>


### [13] [DLEBench: Evaluating Small-scale Object Editing Ability for Instruction-based Image Editing Model](https://arxiv.org/abs/2602.23622)
*Shibo Hong,Boxian Ai,Jun Kuang,Wei Wang,FengJiao Chen,Zhongyuan Peng,Chenhao Huang,Yixin Cao*

Main category: cs.CV

TL;DR: 提出了DLEBench，以解决IIEMs在小规模对象编辑中的能力不足问题。


<details>
  <summary>Details</summary>
Motivation: 在现有的图像编辑模型中，小规模对象编辑的能力仍被低估，尽管这在精确的局部编辑和细化细节方面非常重要。

Method: 提出了DeepLookEditBench（DLEBench），这是一个专门用于评估IIEMs在小规模对象编辑能力的基准。构建了一个包含1889个样本的测试平台，其中目标对象仅占图像面积的1%-10%，涵盖了部分遮挡和多对象编辑等复杂场景。提出了一种评估协议，包含细化的评分标准，以减少主观性和模糊性，并引入了双模式评估框架（工具驱动和Oracle引导模式）。

Result: 实证结果表明，在10个IIEMs中，小规模对象编辑能力存在显著差异，突出了发展这一能力所需的专门基准。

Conclusion: DLEBench是一个重要的基准，有助于评估和推动小规模对象编辑在IIEMs中的发展。

Abstract: Significant progress has been made in the field of Instruction-based Image Editing Models (IIEMs). However, while these models demonstrate plausible adherence to instructions and strong reasoning ability on current benchmarks, their ability to edit small objects remains underexplored, despite its importance for precise local editing and refining details in both real and generated images. In this paper, we introduce DeepLookEditBench (DLEBench), the first benchmark dedicated to assessing the abilities of IIEMs in editing small-scale objects. Specifically, we construct a challenging testbed comprising 1889 samples across seven instruction types. In these samples, target objects occupy only 1%-10% of the image area, covering complex scenarios such as partial occlusion and multi-object editing. To ensure robust evaluation on this benchmark, we propose an evaluation protocol with refined score rubrics to minimize subjectivity and ambiguity in two criteria: Instruction Following and Visual Consistency. This protocol also introduces a dual-mode evaluation framework (Tool-driven and Oracle-guided Modes) addressing the misalignment between LMM-as-a-Judge and human judgements on DLEBench. Empirical results on 10 IIEMs reveal significant performance gaps in small-scale object editing, highlighting the need for specialized benchmarks to advance this ability.

</details>


### [14] [BuildAnyPoint: 3D Building Structured Abstraction from Diverse Point Clouds](https://arxiv.org/abs/2602.23645)
*Tongyan Hua,Haoran Gong,Yuan Liu,Di Wang,Ying-Cong Chen,Wufan Zhao*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We introduce BuildAnyPoint, a novel generative framework for structured 3D building reconstruction from point clouds with diverse distributions, such as those captured by airborne LiDAR and Structure-from-Motion. To recover artist-created building abstraction in this highly underconstrained setting, we capitalize on the role of explicit 3D generative priors in autoregressive mesh generation. Specifically, we design a Loosely Cascaded Diffusion Transformer (Loca-DiT) that initially recovers the underlying distribution from noisy or sparse points, followed by autoregressively encapsulating them into compact meshes. We first formulate distribution recovery as a conditional generation task by training latent diffusion models conditioned on input point clouds, and then tailor a decoder-only transformer for conditional autoregressive mesh generation based on the recovered point clouds. Our method delivers substantial qualitative and quantitative improvements over prior building abstraction methods. Furthermore, the effectiveness of our approach is evidenced by the strong performance of its recovered point clouds on building point cloud completion benchmarks, which exhibit improved surface accuracy and distribution uniformity.

</details>


### [15] [3D Modality-Aware Pre-training for Vision-Language Model in MRI Multi-organ Abnormality Detection](https://arxiv.org/abs/2602.23652)
*Haowen Zhu,Ning Yin,Xiaogen Zhou*

Main category: cs.CV

TL;DR: MedMAP是一种新的医学影像分析框架，在多器官异常检测方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在医学影像中，视觉-语言模型（VLMs）在复杂诊断任务中显示出强大的潜力。然而，将VLMs应用于多器官医学影像引入了两个主要挑战：（1）模态特定的视觉-语言对齐和（2）跨模态特征融合。

Method: 提出了一种名为MedMAP的医学模态感知预训练框架，用于增强3D MRI中的视觉-语言表示学习。MedMAP包括一个模态感知的视觉-语言对齐阶段和一个用于多器官异常检测的微调阶段。在预训练阶段，模态感知编码器隐式地捕获联合模态分布，并提高视觉和文本表示之间的对齐。然后，我们微调预训练的视觉编码器（同时冻结文本编码器）以进行下游任务。为此，我们创建了一个名为MedMoM-MRI3D的数据集，包含7,392个3D MRI体积报告对，涵盖十二种MRI模态和九种异常，针对各种3D医学分析任务。

Result: 在MedMoM-MRI3D上的大量实验表明，MedMAP在基于3D MRI的多器官异常检测方面显著优于现有的VLMs。

Conclusion: MedMAP在3D MRI多器官异常检测方面表现出色，为医学影像分析提供了新的方法。

Abstract: Vision-language models (VLMs) show strong potential for complex diagnostic tasks in medical imaging. However, applying VLMs to multi-organ medical imaging introduces two principal challenges: (1) modality-specific vision-language alignment and (2) cross-modal feature fusion. In this work, we propose MedMAP, a Medical Modality-Aware Pretraining framework that enhances vision-language representation learning in 3D MRI. MedMAP comprises a modality-aware vision-language alignment stage and a fine-tuning stage for multi-organ abnormality detection. During the pre-training stage, the modality-aware encoders implicitly capture the joint modality distribution and improve alignment between visual and textual representations. We then fine-tune the pre-trained vision encoders (while keeping the text encoder frozen) for downstream tasks. To this end, we curated MedMoM-MRI3D, comprising 7,392 3D MRI volume-report pairs spanning twelve MRI modalities and nine abnormalities tailored for various 3D medical analysis tasks. Extensive experiments on MedMoM-MRI3D demonstrate that MedMAP significantly outperforms existing VLMs in 3D MRI-based multi-organ abnormality detection. Our code is available at https://github.com/RomantiDr/MedMAP.

</details>


### [16] [ProtoDCS: Towards Robust and Efficient Open-Set Test-Time Adaptation for Vision-Language Models](https://arxiv.org/abs/2602.23653)
*Wei Luo,Yangfan Ou,Jin Deng,Zeshuai Deng,Xiquan Yan,Zhiquan Wen,Mingkui Tan*

Main category: cs.CV

TL;DR: ProtoDCS: A robust framework for open-set TTA in VLMs, improving known-class accuracy and OOD detection metrics.


<details>
  <summary>Details</summary>
Motivation: Existing VLM-based TTA methods fail in open-set scenarios with both csID and csOOD data, leading to misclassification and overconfident predictions.

Method: Prototype-based Double-Check Separation (ProtoDCS) using probabilistic Gaussian Mixture Model (GMM) and evidence-driven adaptation.

Result: ProtoDCS achieves significant improvements in known-class accuracy and OOD detection metrics.

Conclusion: ProtoDCS is a robust framework for OSTTA that achieves state-of-the-art performance in OOD detection metrics.

Abstract: Large-scale Vision-Language Models (VLMs) exhibit strong zero-shot recognition, yet their real-world deployment is challenged by distribution shifts. While Test-Time Adaptation (TTA) can mitigate this, existing VLM-based TTA methods operate under a closed-set assumption, failing in open-set scenarios where test streams contain both covariate-shifted in-distribution (csID) and out-of-distribution (csOOD) data. This leads to a critical difficulty: the model must discriminate unknown csOOD samples to avoid interference while simultaneously adapting to known csID classes for accuracy. Current open-set TTA (OSTTA) methods rely on hard thresholds for separation and entropy minimization for adaptation. These strategies are brittle, often misclassifying ambiguous csOOD samples and inducing overconfident predictions, and their parameter-update mechanism is computationally prohibitive for VLMs. To address these limitations, we propose Prototype-based Double-Check Separation (ProtoDCS), a robust framework for OSTTA that effectively separates csID and csOOD samples, enabling safe and efficient adaptation of VLMs to csID data. Our main contributions are: (1) a novel double-check separation mechanism employing probabilistic Gaussian Mixture Model (GMM) verification to replace brittle thresholding; and (2) an evidence-driven adaptation strategy utilizing uncertainty-aware loss and efficient prototype-level updates, mitigating overconfidence and reducing computational overhead. Extensive experiments on CIFAR-10/100-C and Tiny-ImageNet-C demonstrate that ProtoDCS achieves state-of-the-art performance, significantly boosting both known-class accuracy and OOD detection metrics. Code will be available at https://github.com/O-YangF/ProtoDCS.

</details>


### [17] [Suppressing Prior-Comparison Hallucinations in Radiology Report Generation via Semantically Decoupled Latent Steering](https://arxiv.org/abs/2602.23676)
*Ao Li,Rui Liu,Mingjie Li,Sheng Liu,Lei Wang,Xiaodan Liang,Lina Yao,Xiaojun Chang,Lei Xing*

Main category: cs.CV

TL;DR: 通过SDLS方法显著降低历史幻觉，提高临床标签准确性。


<details>
  <summary>Details</summary>
Motivation: 解决使用视觉语言模型进行自动放射学报告生成时，由于历史比较幻觉导致的局限性。

Method: 采用训练免费的SDLS框架，通过语义分解和$QR$正交化构建语义无关的干预向量。

Result: 在MIMIC-CXR上进行的实验和CheXpert Plus和IU-Xray上的零样本迁移评估显示，该方法具有鲁棒性。

Conclusion: 通过使用SDLS方法，我们的方法显著降低了历史幻觉的可能性并提高了临床标签的准确性。

Abstract: Automated radiology report generation using vision-language models (VLMs) is limited by the risk of prior-comparison hallucination, where the model generates historical findings unsupported by the current study. We address this challenge with a training-free, inference-time control framework termed Semantically Decoupled Latent Steering (SDLS). Unlike generic activation steering, which often suffers from semantic entanglement, our approach constructs a semantic-free intervention vector via large language model (LLM)-driven semantic decomposition followed by $QR$-based orthogonalization. This orthogonalization step is critical. It leverages geometric constraints to filter out the clinical semantics often entangled in standard principal component analysis (PCA) directions, ensuring that the steering vector targets only the ``historical comparison" axis. We validate our method on the BiomedGPT foundation model, demonstrating that it overcomes the trade-off between hallucination suppression and clinical accuracy. Extensive experiments on MIMIC-CXR, and zero-shot transfer evaluation on CheXpert Plus and IU-Xray, demonstrate the robustness of our approach. Quantitative evaluations on MIMIC-CXR show that our approach significantly reduces the probability of historical hallucinations (FilBERT score decreases from 0.2373 to 0.1889) and improves clinical label fidelity (CheXpert macro-F1 increases from 0.2242 to 0.3208). Supplementary evaluations confirm that the structural integrity of the clinical narrative is maintained.

</details>


### [18] [Vision-Language Semantic Grounding for Multi-Domain Crop-Weed Segmentation](https://arxiv.org/abs/2602.23677)
*Nazia Hossain,Xintong Jiang,Yu Tian,Philippe Seguin,O. Grant Clark,Shangpeng Sun*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Fine-grained crop-weed segmentation is essential for enabling targeted herbicide application in precision agriculture. However, existing deep learning models struggle to generalize across heterogeneous agricultural environments due to reliance on dataset-specific visual features. We propose Vision-Language Weed Segmentation (VL-WS), a novel framework that addresses this limitation by grounding pixel-level segmentation in semantically aligned, domain-invariant representations. Our architecture employs a dual-encoder design, where frozen Contrastive Language-Image Pretraining (CLIP) embeddings and task-specific spatial features are fused and modulated via Feature-wise Linear Modulation (FiLM) layers conditioned on natural language captions. This design enables image level textual descriptions to guide channel-wise feature refinement while preserving fine-grained spatial localization. Unlike prior works restricted to training and evaluation on single-source datasets, VL-WS is trained on a unified corpus that includes close-range ground imagery (robotic platforms) and high-altitude UAV imagery, covering diverse crop types, weed species, growth stages, and sensing conditions. Experimental results across four benchmark datasets demonstrate the effectiveness of our framework, with VL-WS achieving a mean Dice score of 91.64% and outperforming the CNN baseline by 4.98%. The largest gains occur on the most challenging weed class, where VL-WS attains 80.45% Dice score compared to 65.03% for the best baseline, representing a 15.42% improvement. VL-WS further maintains stable weed segmentation performance under limited target-domain supervision, indicating improved generalization and data efficiency. These findings highlight the potential of vision-language alignment to enable scalable, label-efficient segmentation models deployable across diverse real-world agricultural domains.

</details>


### [19] [Any Model, Any Place, Any Time: Get Remote Sensing Foundation Model Embeddings On Demand](https://arxiv.org/abs/2602.23678)
*Dingqi Ye,Daniel Kiv,Wei Hu,Jimeng Shi,Shaowen Wang*

Main category: cs.CV

TL;DR: rs-embed库提供统一接口，简化遥感模型嵌入的获取和评估。


<details>
  <summary>Details</summary>
Motivation: 解决遥感社区中模型发布格式、平台和接口以及输入数据规范的不一致性，导致实际采用和公平比较困难的问题。

Method: 提出rs-embed，一个Python库，提供统一的、以区域兴趣为中心的接口。

Result: 用户可以一行代码检索任何支持的模型在任何位置和任何时间范围内的嵌入。库还提供高效的批量处理，以实现大规模嵌入生成和评估。

Conclusion: rs-embed库有助于降低获取、使用和基准测试嵌入的成本，促进遥感社区中模型的应用和比较。

Abstract: The remote sensing community is witnessing a rapid growth of foundation models, which provide powerful embeddings for a wide range of downstream tasks. However, practical adoption and fair comparison remain challenging due to substantial heterogeneity in model release formats, platforms and interfaces, and input data specifications. These inconsistencies significantly increase the cost of obtaining, using, and benchmarking embeddings across models. To address this issue, we propose rs-embed, a Python library that offers a unified, region of interst (ROI) centric interface: with a single line of code, users can retrieve embeddings from any supported model for any location and any time range. The library also provides efficient batch processing to enable large-scale embedding generation and evaluation. The code is available at: https://github.com/cybergis/rs-embed

</details>


### [20] [Towards Source-Aware Object Swapping with Initial Noise Perturbation](https://arxiv.org/abs/2602.23697)
*Jiahui Zhan,Xianbing Sun,Xiangnan Zhu,Yikun Ji,Ruitong Liu,Liqing Zhang,Jianfu Zhang*

Main category: cs.CV

TL;DR: SourceSwap是一种有效的物体替换方法，能显著提高替换效果，具有广泛的应用前景。


<details>
  <summary>Details</summary>
Motivation: 为了提高场景中对象的替换质量，同时保持场景真实性和物体和谐。

Method: 提出SourceSwap框架，通过合成高质量伪对，进行跨物体对齐，并训练一个双U-Net模型。

Result: 实验表明，SourceSwap在保持真实性、场景保留和自然和谐方面表现优异，并且能够迁移到主体驱动优化和面部交换等编辑中。

Conclusion: SourceSwap是一个有效的自监督和源感知框架，能够实现高质量的物体替换，具有很好的应用前景。

Abstract: Object swapping aims to replace a source object in a scene with a reference object while preserving object fidelity, scene fidelity, and object-scene harmony. Existing methods either require per-object finetuning and slow inference or rely on extra paired data that mostly depict the same object across contexts, forcing models to rely on background cues rather than learning cross-object alignment. We propose SourceSwap, a self-supervised and source-aware framework that learns cross-object alignment. Our key insight is to synthesize high-quality pseudo pairs from any image via a frequency-separated perturbation in the initial-noise space, which alters appearance while preserving pose, coarse shape, and scene layout, requiring no videos, multi-view data, or additional images. We then train a dual U-Net with full-source conditioning and a noise-free reference encoder, enabling direct inter-object alignment, zero-shot inference without per-object finetuning, and lightweight iterative refinement. We further introduce SourceBench, a high-quality benchmark with higher resolution, more categories, and richer interactions. Experiments demonstrate that SourceSwap achieves superior fidelity, stronger scene preservation, and more natural harmony, and it transfers well to edits such as subject-driven refinement and face swapping.

</details>


### [21] [HiDrop: Hierarchical Vision Token Reduction in MLLMs via Late Injection, Concave Pyramid Pruning, and Early Exit](https://arxiv.org/abs/2602.23699)
*Hao Wu,Yingqi Fan,Jinyang Dai,Junlong Tong,Yunpu Ma,Xiaoyu Shen*

Main category: cs.CV

TL;DR: HiDrop通过创新方法优化视觉标记处理，提高MLLM效率。


<details>
  <summary>Details</summary>
Motivation: 处理视觉标记的计算成本高，限制了多模态大型语言模型（MLLM）的广泛应用。

Method: 提出HiDrop框架，通过晚期注入和凹面金字塔剪枝等创新方法来优化视觉标记处理。

Result: HiDrop压缩了约90%的视觉标记，同时匹配原始性能并加速训练1.72倍。

Conclusion: HiDrop在高效MLLM训练和推理方面达到新水平，并为多模态融合的层次结构提供见解。

Abstract: The quadratic computational cost of processing vision tokens in Multimodal Large Language Models (MLLMs) hinders their widespread adoption. While progressive vision token pruning offers a promising solution, current methods misinterpret shallow layer functions and use rigid schedules, which fail to unlock the full efficiency potential. To address these issues, we propose HiDrop, a framework that aligns token pruning with the true hierarchical function of MLLM layers. HiDrop features two key innovations: (1) Late Injection, which bypasses passive shallow layers to introduce visual tokens exactly where active fusion begins; and (2) Concave Pyramid Pruning with an Early Exit mechanism to dynamically adjust pruning rates across middle and deep layers. This process is optimized via an inter-layer similarity measure and a differentiable top-k operator. To ensure practical efficiency, HiDrop further incorporates persistent positional encoding, FlashAttention-compatible token selection, and parallel decoupling of vision computation to eliminate hidden overhead associated with dynamic token reduction. Extensive experiments show that HiDrop compresses about 90% visual tokens while matching the original performance and accelerating training by 1.72 times. Our work not only sets a new state-of-the-art for efficient MLLM training and inference but also provides valuable insights into the hierarchical nature of multimodal fusion. The code is released at https://github.com/EIT-NLP/HiDrop.

</details>


### [22] [EgoGraph: Temporal Knowledge Graph for Egocentric Video Understanding](https://arxiv.org/abs/2602.23709)
*Shitong Sun,Ke Han,Yukai Huang,Weitong Cai,Jifei Song*

Main category: cs.CV

TL;DR: EgoGraph provides a new approach for understanding ultra-long egocentric videos by encoding long-term dependencies and achieving superior performance in long-term video question answering.


<details>
  <summary>Details</summary>
Motivation: Existing approaches in video understanding for ultra-long egocentric videos have limitations in local processing and temporal modeling.

Method: Introducing EgoGraph, a training-free and dynamic knowledge-graph construction framework for encoding long-term dependencies. It employs a novel egocentric schema and a temporal relational modeling strategy.

Result: EgoGraph achieves state-of-the-art performance on long-term video question answering, validating its effectiveness.

Conclusion: EgoGraph is an effective new paradigm for ultra-long egocentric video understanding.

Abstract: Ultra-long egocentric videos spanning multiple days present significant challenges for video understanding. Existing approaches still rely on fragmented local processing and limited temporal modeling, restricting their ability to reason over such extended sequences. To address these limitations, we introduce EgoGraph, a training-free and dynamic knowledge-graph construction framework that explicitly encodes long-term, cross-entity dependencies in egocentric video streams. EgoGraph employs a novel egocentric schema that unifies the extraction and abstraction of core entities, such as people, objects, locations, and events, and structurally reasons about their attributes and interactions, yielding a significantly richer and more coherent semantic representation than traditional clip-based video models. Crucially, we develop a temporal relational modeling strategy that captures temporal dependencies across entities and accumulates stable long-term memory over multiple days, enabling complex temporal reasoning. Extensive experiments on the EgoLifeQA and EgoR1-bench benchmarks demonstrate that EgoGraph achieves state-of-the-art performance on long-term video question answering, validating its effectiveness as a new paradigm for ultra-long egocentric video understanding.

</details>


### [23] [Can Unified Generation and Understanding Models Maintain Semantic Equivalence Across Different Output Modalities?](https://arxiv.org/abs/2602.23711)
*Hongbo Jiang,Jie Li,Yunhang Shen,Pingyang Dai,Xing Sun,Haoyu Cao,Liujuan Cao*

Main category: cs.CV

TL;DR: U-MLLMs在生成视觉答案时表现不佳，主要问题在于跨模态语义对齐的失败。


<details>
  <summary>Details</summary>
Motivation: 评估U-MLLMs在语义等价性方面的表现，即在不同输出模式下表现出一致的推理结果的能力。

Method: 引入VGUBench框架，包括三个诊断任务：文本生成理解、视觉生成理解和视觉渲染控制任务。

Result: U-MLLMs在文本理解和视觉渲染方面表现出色，但在生成视觉答案时表现不佳，且视觉回答性能与基本渲染质量之间相关性极低。

Conclusion: U-MLLMs在跨模态语义对齐方面存在问题，导致在生成视觉答案时表现不佳。

Abstract: Unified Multimodal Large Language Models (U-MLLMs) integrate understanding and generation within a single architecture. However, existing evaluations typically assess these capabilities separately, overlooking semantic equivalence, i.e., the ability to manifest consistent reasoning results regardless of the output modality. In this work, we investigate whether current U-MLLMs satisfy this premise. We observe that while models demonstrate robust textual reasoning, they fail to maintain semantic equivalence when required to render the same results in the image modality. To rigorously diagnose this discrepancy, we introduce VGUBench, a framework to decouple reasoning logic from generation fidelity. VGUBench comprises three diagnostic tasks: (1)Textual Generative Understanding, establishing a baseline for reasoning accuracy in textual response; (2)Visual Generative Understanding, evaluating the ability to generate visual responses that represent the correct answer; and (3)a Visual Rendering control task, which assesses the ability to directly render explicit visual descriptions into images without complex reasoning. Our evaluation reveals a significant disparity: despite strong performance in textual understanding and visual rendering, U-MLLMs exhibit a marked performance collapse when required to generate visual answers to questions. Furthermore, we find a negligible correlation between visual answering performance and basic rendering quality. These results suggest that the failure stems not from insufficient generation fidelity, but from a breakdown in cross-modal semantic alignment. We provide diagnostic insights to address this challenge in future Unified Generation and Understanding Models.

</details>


### [24] [A Difference-in-Difference Approach to Detecting AI-Generated Images](https://arxiv.org/abs/2602.23732)
*Xinyi Qi,Kai Ye,Chengchun Shi,Ying Yang,Hongyi Zhou,Jin Zhu*

Main category: cs.CV

TL;DR: 提出一种新的差异-差异方法，通过计算重建误差的差异来提高AI生成图像检测的准确性。


<details>
  <summary>Details</summary>
Motivation: 针对现有检测器在区分真实图像和AI生成图像方面的局限性，提出一种新的差异-差异方法。

Method: 计算重建误差的差异（二阶差异）以减少方差并提高检测精度。

Result: 实验表明，该方法具有强大的泛化性能，能够在生成AI时代可靠地检测AI生成图像。

Conclusion: 提出的方法能够有效提高AI生成图像检测的准确性，为应对生成AI时代的挑战提供了新的思路。

Abstract: Diffusion models are able to produce AI-generated images that are almost indistinguishable from real ones. This raises concerns about their potential misuse and poses substantial challenges for detecting them. Many existing detectors rely on reconstruction error -- the difference between the input image and its reconstructed version -- as the basis for distinguishing real from fake images. However, these detectors become less effective as modern AI-generated images become increasingly similar to real ones. To address this challenge, we propose a novel difference-in-difference method. Instead of directly using the reconstruction error (a first-order difference), we compute the difference in reconstruction error -- a second-order difference -- for variance reduction and improving detection accuracy. Extensive experiments demonstrate that our method achieves strong generalization performance, enabling reliable detection of AI-generated images in the era of generative AI.

</details>


### [25] [UTPTrack: Towards Simple and Unified Token Pruning for Visual Tracking](https://arxiv.org/abs/2602.23734)
*Hao Wu,Xudong Wang,Jialiang Zhang,Junlong Tong,Xinghao Chen,Junyan Lin,Yunpu Ma,Xiaoyu Shen*

Main category: cs.CV

TL;DR: UTPTrack是一种基于单流Transformer的视觉跟踪器，通过联合剪枝三个组件，在保持高精度的情况下显著降低计算开销。


<details>
  <summary>Details</summary>
Motivation: 解决基于单流Transformer的跟踪器在视觉对象跟踪中计算开销大的问题，以及现有方法在剪枝方面的碎片化问题。

Method: 提出UTPTrack，一个简单且统一的令牌剪枝框架，首次联合压缩搜索区域、动态模板和静态模板三个组件。采用注意力引导的、令牌类型感知的策略来整体建模冗余。

Result: 在10个基准测试中，UTPTrack在剪枝跟踪器的精度-效率权衡方面实现了新的最先进水平，在RGB跟踪中剪枝了65.4%的视觉令牌，在统一跟踪中剪枝了67.5%，同时分别保留了99.7%和100.5%的基线性能。

Conclusion: UTPTrack在RGB和多模态场景下都表现出强大的性能，有望成为未来高效视觉跟踪研究的基础。

Abstract: One-stream Transformer-based trackers achieve advanced performance in visual object tracking but suffer from significant computational overhead that hinders real-time deployment. While token pruning offers a path to efficiency, existing methods are fragmented. They typically prune the search region, dynamic template, and static template in isolation, overlooking critical inter-component dependencies, which yields suboptimal pruning and degraded accuracy. To address this, we introduce UTPTrack, a simple and Unified Token Pruning framework that, for the first time, jointly compresses all three components. UTPTrack employs an attention-guided, token type-aware strategy to holistically model redundancy, a design that seamlessly supports unified tracking across multimodal and language-guided tasks within a single model. Extensive evaluations on 10 benchmarks demonstrate that UTPTrack achieves a new state-of-the-art in the accuracy-efficiency trade-off for pruning-based trackers, pruning 65.4% of vision tokens in RGB-based tracking and 67.5% in unified tracking while preserving 99.7% and 100.5% of baseline performance, respectively. This strong performance across both RGB and multimodal scenarios underlines its potential as a robust foundation for future research in efficient visual tracking. Code will be released at https://github.com/EIT-NLP/UTPTrack.

</details>


### [26] [Learning Accurate Segmentation Purely from Self-Supervision](https://arxiv.org/abs/2602.23759)
*Zuyao You,Zuxuan Wu,Yu-Gang Jiang*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Accurately segmenting objects without any manual annotations remains one of the core challenges in computer vision. In this work, we introduce Selfment, a fully self-supervised framework that segments foreground objects directly from raw images without human labels, pretrained segmentation models, or any post-processing. Selfment first constructs patch-level affinity graphs from self-supervised features and applies NCut to obtain an initial coarse foreground--background separation. We then introduce Iterative Patch Optimization (IPO), a feature-space refinement procedure that progressively enforces spatial coherence and semantic consistency through iterative patch clustering. The refined masks are subsequently used as supervisory signals to train a lightweight segmentation head with contrastive and region-consistency objectives, allowing the model to learn stable and transferable object representations. Despite its simplicity and complete absence of manual supervision, Selfment sets new state-of-the-art (SoTA) results across multiple benchmarks. It achieves substantial improvements on $F_{\max}$ over previous unsupervised saliency detection methods on ECSSD ($+4.0\%$), HKUIS ($+4.6\%$), and PASCAL-S ($+5.7\%$). Moreover, without any additional fine-tuning, Selfment demonstrates remarkable zero-shot generalization to camouflaged object detection tasks (e.g., $0.910$ $S_m$ on CHAMELEON and $0.792$ $F_β^ω$ on CAMO), outperforming all existing unsupervised approaches and even rivaling the SoTA fully supervised methods.

</details>


### [27] [Diffusion Probe: Generated Image Result Prediction Using CNN Probes](https://arxiv.org/abs/2602.23783)
*Benlei Cui,Bukun Huang,Zhizeng Ye,Xuemei Dong,Tuo Chen,Hui Xue,Dingkang Yang,Longtao Huang,Jingqun Tang,Haiwen Hong*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Text-to-image (T2I) diffusion models lack an efficient mechanism for early quality assessment, leading to costly trial-and-error in multi-generation scenarios such as prompt iteration, agent-based generation, and flow-grpo. We reveal a strong correlation between early diffusion cross-attention distributions and final image quality. Based on this finding, we introduce Diffusion Probe, a framework that leverages internal cross-attention maps as predictive signals.
  We design a lightweight predictor that maps statistical properties of early-stage cross-attention extracted from initial denoising steps to the final image's overall quality. This enables accurate forecasting of image quality across diverse evaluation metrics long before full synthesis is complete.
  We validate Diffusion Probe across a wide range of settings. On multiple T2I models, across early denoising windows, resolutions, and quality metrics, it achieves strong correlation (PCC > 0.7) and high classification performance (AUC-ROC > 0.9).
  Its reliability translates into practical gains. By enabling early quality-aware decisions in workflows such as prompt optimization, seed selection, and accelerated RL training, the probe supports more targeted sampling and avoids computation on low-potential generations. This reduces computational overhead while improving final output quality.
  Diffusion Probe is model-agnostic, efficient, and broadly applicable, offering a practical solution for improving T2I generation efficiency through early quality prediction.

</details>


### [28] [Fourier Angle Alignment for Oriented Object Detection in Remote Sensing](https://arxiv.org/abs/2602.23790)
*Changyu Gu,Linwei Chen,Lin Gu,Ying Fu*

Main category: cs.CV

TL;DR: 提出了一种基于傅里叶旋转等变性的遥感旋转目标检测方法，显著提高了检测性能。


<details>
  <summary>Details</summary>
Motivation: 在遥感旋转目标检测中，主流方法存在两个瓶颈：检测颈部的方向不一致性和检测头部的任务冲突。

Method: 利用傅里叶旋转等变性，引入傅里叶角度对齐，通过频谱分析角度信息，并将主要方向对齐到特定方向。然后提出两个即插即用模块：FAAFusion和FAA Head。FAAFusion在检测颈部工作，将高级特征的 主要方向对齐到低级特征并融合它们。FAA Head作为一个新的检测头部，在分类和回归之前预先对齐RoI特征到规范角度并将其添加到原始特征中。

Result: 在DOTA-v1.0、DOTA-v1.5和HRSC2016数据集上的实验表明，该方法可以显著提高先前的工作。特别是在DOTA-v1.0数据集上达到78.72%的mAP，在DOTA-v1.5数据集上达到72.28%的mAP，验证了该方法在遥感目标检测中的有效性。

Conclusion: 该方法在遥感目标检测中取得了显著的性能提升，并实现了新的最先进结果。

Abstract: In remote sensing rotated object detection, mainstream methods suffer from two bottlenecks, directional incoherence at detector neck and task conflict at detecting head. Ulitising fourier rotation equivariance, we introduce Fourier Angle Alignment, which analyses angle information through frequency spectrum and aligns the main direction to a certain orientation. Then we propose two plug and play modules : FAAFusion and FAA Head. FAAFusion works at the detector neck, aligning the main direction of higher-level features to the lower-level features and then fusing them. FAA Head serves as a new detection head, which pre-aligns RoI features to a canonical angle and adds them to the original features before classification and regression. Experiments on DOTA-v1.0, DOTA-v1.5 and HRSC2016 show that our method can greatly improve previous work. Particularly, our method achieves new state-of-the-art results of 78.72% mAP on DOTA-v1.0 and 72.28% mAP on DOTA-v1.5 datasets with single scale training and testing, validating the efficacy of our approach in remote sensing object detection. The code is made publicly available at https://github.com/gcy0423/Fourier-Angle-Alignment .

</details>


### [29] [See, Act, Adapt: Active Perception for Unsupervised Cross-Domain Visual Adaptation via Personalized VLM-Guided Agent](https://arxiv.org/abs/2602.23806)
*Tianci Tang,Tielong Cai,Hongwei Wang,Gaoang Wang*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Pre-trained perception models excel in generic image domains but degrade significantly in novel environments like indoor scenes. The conventional remedy is fine-tuning on downstream data which incurs catastrophic forgetting of prior knowledge and demands costly, scene-specific annotations. We propose a paradigm shift through Sea$^2$ (See, Act, Adapt): rather than adapting the perception modules themselves, we adapt how they are deployed through an intelligent pose-control agent. Sea$^2$ keeps all perception modules frozen, requiring no downstream labels during training, and uses only scalar perceptual feedback to navigate the agent toward informative viewpoints. Specially, we transform a vision-language model (VLM) into a low-level pose controller through a two-stage training pipeline: first fine-tuning it on rule-based exploration trajectories that systematically probe indoor scenes, and then refining the policy via unsupervised reinforcement learning that constructs rewards from the perception module's outputs and confidence. Unlike prior active perception methods that couple exploration with specific models or collect data for retraining them, Sea$^2$ directly leverages off-the-shelf perception models for various tasks without the need for retraining. We conducted experiments on three visual perception tasks, including visual grounding, segmentation and 3D box estimation, with performance improvements of 13.54%, 15.92% and 27.68% respectively on dataset ReplicaCAD.

</details>


### [30] [Action-Geometry Prediction with 3D Geometric Prior for Bimanual Manipulation](https://arxiv.org/abs/2602.23814)
*Chongyang Xu,Haipeng Li,Shen Cheng,Jingyu Hu,Haoqiang Fan,Ziliang Feng,Shuaicheng Liu*

Main category: cs.CV

TL;DR: 提出了一种基于3D几何基础模型的双臂操作框架，在模拟和真实环境中均表现出色。


<details>
  <summary>Details</summary>
Motivation: 为了解决双臂操作需要处理3D几何、预测动作影响以及生成平滑协调运动的问题，同时克服现有方法在空间感知和点云获取方面的局限性。

Method: 提出了一种基于预训练的3D几何基础模型的框架，融合几何感知的潜在表示、2D语义特征和自身体感，使用扩散模型预测未来动作块和未来3D潜在表示，从而实现双臂操作。

Result: 在模拟和真实机器人执行中，该方法在操作成功率、手臂协调和3D空间预测精度方面均优于基于2D和点云的基线，达到最先进水平。

Conclusion: 该方法在双臂操作方面取得了显著成果，为未来研究提供了新的思路。

Abstract: Bimanual manipulation requires policies that can reason about 3D geometry, anticipate how it evolves under action, and generate smooth, coordinated motions. However, existing methods typically rely on 2D features with limited spatial awareness, or require explicit point clouds that are difficult to obtain reliably in real-world settings. At the same time, recent 3D geometric foundation models show that accurate and diverse 3D structure can be reconstructed directly from RGB images in a fast and robust manner. We leverage this opportunity and propose a framework that builds bimanual manipulation directly on a pre-trained 3D geometric foundation model. Our policy fuses geometry-aware latents, 2D semantic features, and proprioception into a unified state representation, and uses diffusion model to jointly predict a future action chunk and a future 3D latent that decodes into a dense pointmap. By explicitly predicting how the 3D scene will evolve together with the action sequence, the policy gains strong spatial understanding and predictive capability using only RGB observations. We evaluate our method both in simulation on the RoboTwin benchmark and in real-world robot executions. Our approach consistently outperforms 2D-based and point-cloud-based baselines, achieving state-of-the-art performance in manipulation success, inter-arm coordination, and 3D spatial prediction accuracy. Code is available at https://github.com/Chongyang-99/GAP.git.

</details>


### [31] [Footprint-Guided Exemplar-Free Continual Histopathology Report Generation](https://arxiv.org/abs/2602.23817)
*Pratibha Kumari,Daniel Reisenbüchler,Afshin Bozorgpour,yousef Sadegheih,Priyankar Choudhary,Dorit Merhof*

Main category: cs.CV

TL;DR: 提出了一种无示例的持续学习框架，用于在临床环境中生成病理报告，有效避免了灾难性遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 为了解决病理报告生成中由于临床部署中器官、机构和报告规范随时间变化而导致的灾难性遗忘问题。

Method: 提出了一种无示例的持续学习框架，该框架在冻结的补丁嵌入空间中构建紧凑的领域足迹：一组代表性的形态标记的小代码簿以及幻灯片级别的共现摘要和轻量级的补丁计数先验。

Result: 在多个公共持续学习基准上评估，该方法优于无示例和有限缓冲重排基线，突出了基于足迹的生成重放作为在不断变化的临床环境中部署的实用解决方案。

Conclusion: 该框架能够有效地避免灾难性遗忘，并在不断变化的临床环境中实现高效的病理报告生成。

Abstract: Rapid progress in vision-language modeling has enabled pathology report generation from gigapixel whole-slide images, but most approaches assume static training with simultaneous access to all data. In clinical deployment, however, new organs, institutions, and reporting conventions emerge over time, and sequential fine-tuning can cause catastrophic forgetting. We introduce an exemplar-free continual learning framework for WSI-to-report generation that avoids storing raw slides or patch exemplars. The core idea is a compact domain footprint built in a frozen patch-embedding space: a small codebook of representative morphology tokens together with slide-level co-occurrence summaries and lightweight patch-count priors. These footprints support generative replay by synthesizing pseudo-WSI representations that reflect domain-specific morphological mixtures, while a teacher snapshot provides pseudo-reports to supervise the updated model without retaining past data. To address shifting reporting conventions, we distill domain-specific linguistic characteristics into a compact style descriptor and use it to steer generation. At inference, the model identifies the most compatible descriptor directly from the slide signal, enabling domain-agnostic setup without requiring explicit domain identifiers. Evaluated across multiple public continual learning benchmarks, our approach outperforms exemplar-free and limited-buffer rehearsal baselines, highlighting footprint-based generative replay as a practical solution for deployment in evolving clinical settings.

</details>


### [32] [Denoising-Enhanced YOLO for Robust SAR Ship Detection](https://arxiv.org/abs/2602.23820)
*Xiaojing Zhao,Shiyang Li,Zena Chu,Ying Zhang,Peinan Hao,Tianzi Yan,Jiajia Chen,Huicong Ning*

Main category: cs.CV

TL;DR: CPN-YOLO：一种基于YOLOv8的船舶检测框架，有效提高检测精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 针对复杂场景中合成孔径雷达图像船舶检测的鲁棒性问题，以及杂波和斑点噪声引起的误报和小目标易被遗漏的问题。

Method: 提出CPN-YOLO，基于YOLOv8进行改进，包括可学习的核大小可变去噪模块、基于PPA注意力机制的特征提取增强策略以及基于归一化Wasserstein距离的高斯相似度损失。

Result: 在HRSID和SSDD数据集上实验结果表明，CPN-YOLO在SSDD数据集上优于YOLOv8基线，达到97.0%的精度、95.1%的召回率和98.9%的mAP，总体性能优于其他深度学习检测器。

Conclusion: CPN-YOLO是一种高效的船舶检测框架，在复杂场景中具有鲁棒性，能够有效检测小目标和避免误报。

Abstract: With the rapid advancement of deep learning, synthetic aperture radar (SAR) imagery has become a key modality for ship detection. However, robust performance remains challenging in complex scenes, where clutter and speckle noise can induce false alarms and small targets are easily missed. To address these issues, we propose CPN-YOLO, a high-precision ship detection framework built upon YOLOv8 with three targeted improvements. First, we introduce a learnable large-kernel denoising module for input pre-processing, producing cleaner representations and more discriminative features across diverse ship types. Second, we design a feature extraction enhancement strategy based on the PPA attention mechanism to strengthen multi-scale modeling and improve sensitivity to small ships. Third, we incorporate a Gaussian similarity loss derived from the normalized Wasserstein distance (NWD) to better measure similarity under complex bounding-box distributions and improve generalization. Extensive experiments on HRSID and SSDD demonstrate the effectiveness of our method. On SSDD, CPN-YOLO surpasses the YOLOv8 baseline, achieving 97.0% precision, 95.1% recall, and 98.9% mAP, and consistently outperforms other representative deep-learning detectors in overall performance.

</details>


### [33] [APPO: Attention-guided Perception Policy Optimization for Video Reasoning](https://arxiv.org/abs/2602.23823)
*Henghui Du,Chang Zhou,Xi Chen,Di Hu*

Main category: cs.CV

TL;DR: APPO算法通过优化关键视频帧的token感知，有效提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 复杂视频推理过度依赖细粒度感知而非专家推理，通过大量观察认识到感知的重要性。

Method: 提出APPO算法，利用token级别的密集奖励来优化模型对关键视频帧的细粒度感知。

Result: APPO在多个视频基准和不同规模模型上优于GRPO和DAPO，提升性能0.5%~4%。

Conclusion: APPO算法有效提升了模型感知能力，为低成本增强模型推理能力提供了一种有前景的方法。

Abstract: Complex video reasoning, actually, relies excessively on fine-grained perception rather than on expert (e.g., Ph.D, Science)-level reasoning. Through extensive empirical observation, we have recognized the critical impact of perception. In particular, when perception ability is almost fixed, enhancing reasoning from Qwen3-8B to OpenAI-o3 yields only 0.7% performance improvement. Conversely, even minimal change in perception model scale (from 7B to 32B) boosts performance by 1.4%, indicating enhancing perception, rather than reasoning, is more critical to improve performance. Therefore, exploring how to enhance perception ability through reasoning without the need for expensive fine-grained annotation information is worthwhile. To achieve this goal, we specially propose APPO, the Attention-guided Perception Policy Optimization algorithm that leverages token-level dense rewards to improve model's fine-grained perception. The core idea behind APPO is to optimize those tokens from different responses that primarily focus on the same crucial video frame (called intra-group perception tokens). Experimental results on diverse video benchmarks and models with different scales (3/7B) demonstrate APPO consistently outperforms GRPO and DAPO (0.5%~4%). We hope our work provides a promising approach to effectively enhance model's perception abilities through reasoning in a low-cost manner, serving diverse scenarios and demands.

</details>


### [34] [NAU-QMUL: Utilizing BERT and CLIP for Multi-modal AI-Generated Image Detection](https://arxiv.org/abs/2602.23863)
*Xiaoyu Guo,Arkaitz Zubiaga*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: With the aim of detecting AI-generated images and identifying the specific models responsible for their generation, we propose a multi-modal multi-task model. The model leverages pre-trained BERT and CLIP Vision encoders for text and image feature extraction, respectively, and employs cross-modal feature fusion with a tailored multi-task loss function. Additionally, a pseudo-labeling-based data augmentation strategy was utilized to expand the training dataset with high-confidence samples. The model achieved fifth place in both Tasks A and B of the `CT2: AI-Generated Image Detection' competition, with F1 scores of 83.16\% and 48.88\%, respectively. These findings highlight the effectiveness of the proposed architecture and its potential for advancing AI-generated content detection in real-world scenarios. The source code for our method is published on https://github.com/xxxxxxxxy/AIGeneratedImageDetection.

</details>


### [35] [Open-Vocabulary Semantic Segmentation in Remote Sensing via Hierarchical Attention Masking and Model Composition](https://arxiv.org/abs/2602.23869)
*Mohammadreza Heidarianbaei,Mareike Dorozynski,Hubert Kanyamahanga,Max Mehltretter,Franz Rottensteiner*

Main category: cs.CV

TL;DR: 提出ReSeg-CLIP，一种无监督遥感数据语义分割新方法，显著提高分割性能。


<details>
  <summary>Details</summary>
Motivation: 针对视觉语言模型在语义分割中存在的问题，如CLIP在遥感数据语义分割中由于自注意力层内部不当交互导致的错误，提出了一种新的无监督语义分割方法。

Method: 引入了利用SAM生成的掩码的分层方案来约束多尺度交互，并提出了一种模型组合方法，通过新的加权方案，使用不同的文本提示来评估表示质量，平均多个RS特定的CLIP变体的参数。

Result: 在三个遥感数据基准上实现了最先进的性能，无需额外训练。

Conclusion: ReSeg-CLIP是一种有效的无监督遥感数据语义分割方法，能够显著提高分割性能。

Abstract: In this paper, we propose ReSeg-CLIP, a new training-free Open-Vocabulary Semantic Segmentation method for remote sensing data. To compensate for the problems of vision language models, such as CLIP in semantic segmentation caused by inappropriate interactions within the self-attention layers, we introduce a hierarchical scheme utilizing masks generated by SAM to constrain the interactions at multiple scales. We also present a model composition approach that averages the parameters of multiple RS-specific CLIP variants, taking advantage of a new weighting scheme that evaluates representational quality using varying text prompts. Our method achieves state-of-the-art results across three RS benchmarks without additional training.

</details>


### [36] [Altitude-Aware Visual Place Recognition in Top-Down View](https://arxiv.org/abs/2602.23872)
*Xingyu Shao,Mengfan He,Chunyu Li,Liangzheng Sun,Ziyang Meng*

Main category: cs.CV

TL;DR: 本研究提出了一种新的空中视觉场所识别方法，通过结合地面特征密度分析和图像分类技术，在大范围高度变化下实现了高精度和鲁棒的定位。


<details>
  <summary>Details</summary>
Motivation: 解决在大范围高度变化下空中视觉场所识别（VPR）的挑战。

Method: 该方法结合了地面特征密度分析和图像分类技术，通过分析图像中的地面特征密度来估计飞行平台的相对高度，并基于此生成标准查询图像，从而在基于分类的视觉场所识别策略中进行定位。

Result: 实验表明，与传统的基于气压计或飞行时间（ToF）传感器的传统方法相比，该方法不需要额外的硬件，适用于各种环境，包括农村和城市地区的小型和中等尺寸空中平台。

Conclusion: 本研究提出了一种鲁棒的视觉场所识别框架，适用于大范围高度变化下的空中平台定位。

Abstract: To address the challenge of aerial visual place recognition (VPR) problem under significant altitude variations, this study proposes an altitude-adaptive VPR approach that integrates ground feature density analysis with image classification techniques. The proposed method estimates airborne platforms' relative altitude by analyzing the density of ground features in images, then applies relative altitude-based cropping to generate canonical query images, which are subsequently used in a classification-based VPR strategy for localization. Extensive experiments across diverse terrains and altitude conditions demonstrate that the proposed approach achieves high accuracy and robustness in both altitude estimation and VPR under significant altitude changes. Compared to conventional methods relying on barometric altimeters or Time-of-Flight (ToF) sensors, this solution requires no additional hardware and offers a plug-and-play solution for downstream applications, {making it suitable for small- and medium-sized airborne platforms operating in diverse environments, including rural and urban areas.} Under significant altitude variations, incorporating our relative altitude estimation module into the VPR retrieval pipeline boosts average R@1 and R@5 by 29.85\% and 60.20\%, respectively, compared with applying VPR retrieval alone. Furthermore, compared to traditional {Monocular Metric Depth Estimation (MMDE) methods}, the proposed method reduces the mean error by 202.1 m, yielding average additional improvements of 31.4\% in R@1 and 44\% in R@5. These results demonstrate that our method establishes a robust, vision-only framework for three-dimensional visual place recognition, offering a practical and scalable solution for accurate airborne platforms localization under large altitude variations and limited sensor availability.

</details>


### [37] [AoE: Always-on Egocentric Human Video Collection for Embodied AI](https://arxiv.org/abs/2602.23893)
*Bowen Yang,Zishuo Li,Yang Sun,Changtao Miao,Yifan Yang,Man Luo,Xiaotong Yan,Feng Jiang,Jinchuan Shi,Yankai Fu,Ning Chen,Junkai Zhao,Pengwei Wang,Guocai Yao,Shanghang Zhang,Hao Chen,Zhe Li,Kai Zhu*

Main category: cs.CV

TL;DR: AoE系统通过利用人类和智能手机，实现低成本、高效且场景无关的交互数据收集，显著提升具身基础模型的真实世界泛化能力。


<details>
  <summary>Details</summary>
Motivation: Embodied foundation models require large-scale, high-quality real-world interaction data for pre-training and scaling.

Method: Propose the Always-on Egocentric (AoE) data collection system, leveraging humans and their smartphones.

Result: AoE enables low-cost, highly efficient, and scene-agnostic real-world interaction data collection.

Conclusion: AoE significantly boosts real-world generalization in embodied foundation models.

Abstract: Embodied foundation models require large-scale, high-quality real-world interaction data for pre-training and scaling. However, existing data collection methods suffer from high infrastructure costs, complex hardware dependencies, and limited interaction scope, making scalable expansion challenging. In fact, humans themselves are ideal physically embodied agents. Therefore, obtaining egocentric real-world interaction data from globally distributed "human agents" offers advantages of low cost and sustainability. To this end, we propose the Always-on Egocentric (AoE) data collection system, which aims to simplify hardware dependencies by leveraging humans themselves and their smartphones, enabling low-cost, highly efficient, and scene-agnostic real-world interaction data collection to address the challenge of data scarcity. Specifically, we first employ an ergonomic neck-mounted smartphone holder to enable low-barrier, large-scale egocentric data collection through a cloud-edge collaborative architecture. Second, we develop a cross-platform mobile APP that leverages on-device compute for real-time processing, while the cloud hosts automated labeling and filtering pipelines that transform raw videos into high-quality training data. Finally, the AoE system supports distributed Ego video data collection by anyone, anytime, and anywhere. We evaluate AoE on data preprocessing quality and downstream tasks, demonstrating that high-quality egocentric data significantly boosts real-world generalization.

</details>


### [38] [Ref-Adv: Exploring MLLM Visual Reasoning in Referring Expression Tasks](https://arxiv.org/abs/2602.23898)
*Qihua Dong,Kuo Yang,Lin Ju,Handong Zhao,Yitian Zhang,Yizhou Wang,Huimin Zeng,Jianglin Lu,Yun Fu*

Main category: cs.CV

TL;DR: Ref-Adv是一个新的指代表达式基准，旨在提高视觉推理和定位能力，揭示了现有模型的局限性。


<details>
  <summary>Details</summary>
Motivation: 为了提高语言与视觉感知之间的联系，并解决现有标准基准在视觉推理和定位方面的不足。

Method: 引入Ref-Adv，一个现代的指代表达式基准，通过将语言上非平凡的指代表达式与唯一识别目标所需的信息配对来抑制捷径。

Result: 在RefCOCO、RefCOCO+和RefCOCOg上表现出色，但在Ref-Adv上的表现明显下降，揭示了模型对捷径的依赖以及视觉推理和定位方面的不足。

Conclusion: Ref-Adv为未来在多模态LLMs中进行视觉推理和定位研究提供了指导。

Abstract: Referring Expression Comprehension (REC) links language to region level visual perception. Standard benchmarks (RefCOCO, RefCOCO+, RefCOCOg) have progressed rapidly with multimodal LLMs but remain weak tests of visual reasoning and grounding: (i) many expressions are very short, leaving little reasoning demand; (ii) images often contain few distractors, making the target easy to find; and (iii) redundant descriptors enable shortcut solutions that bypass genuine text understanding and visual reasoning. We introduce Ref-Adv, a modern REC benchmark that suppresses shortcuts by pairing linguistically nontrivial expressions with only the information necessary to uniquely identify the target. The dataset contains referring expressions on real images, curated with hard distractors and annotated with reasoning facets including negation. We conduct comprehensive ablations (word order perturbations and descriptor deletion sufficiency) to show that solving Ref-Adv requires reasoning beyond simple cues, and we evaluate a broad suite of contemporary multimodal LLMs on Ref-Adv. Despite strong results on RefCOCO, RefCOCO+, and RefCOCOg, models drop markedly on Ref-Adv, revealing reliance on shortcuts and gaps in visual reasoning and grounding. We provide an in depth failure analysis and aim for Ref-Adv to guide future work on visual reasoning and grounding in MLLMs.

</details>


### [39] [SelfOccFlow: Towards end-to-end self-supervised 3D Occupancy Flow prediction](https://arxiv.org/abs/2602.23894)
*Xavier Timoneda,Markus Herb,Fabian Duerr,Daniel Goehring*

Main category: cs.CV

TL;DR: This paper proposes a self-supervised 3D occupancy flow estimation method, achieving promising results without human annotations.


<details>
  <summary>Details</summary>
Motivation: Estimating 3D occupancy and motion at the vehicle's surroundings is essential for autonomous driving.

Method: Proposed a self-supervised method for 3D occupancy flow estimation.

Result: Demonstrated the efficacy of the method on SemanticKITTI, KITTI-MOT, and nuScenes.

Conclusion: The method eliminates the need for human-produced annotations or external flow supervision and shows promising results in 3D occupancy flow estimation.

Abstract: Estimating 3D occupancy and motion at the vehicle's surroundings is essential for autonomous driving, enabling situational awareness in dynamic environments. Existing approaches jointly learn geometry and motion but rely on expensive 3D occupancy and flow annotations, velocity labels from bounding boxes, or pretrained optical flow models. We propose a self-supervised method for 3D occupancy flow estimation that eliminates the need for human-produced annotations or external flow supervision. Our method disentangles the scene into separate static and dynamic signed distance fields and learns motion implicitly through temporal aggregation. Additionally, we introduce a strong self-supervised flow cue derived from features' cosine similarities. We demonstrate the efficacy of our 3D occupancy flow method on SemanticKITTI, KITTI-MOT, and nuScenes.

</details>


### [40] [Experience-Guided Self-Adaptive Cascaded Agents for Breast Cancer Screening and Diagnosis with Reduced Biopsy Referrals](https://arxiv.org/abs/2602.23899)
*Pramit Saha,Mohammad Alsharid,Joshua Strong,J. Alison Noble*

Main category: cs.CV

TL;DR: BUSD-Agent：一种基于经验引导的多智能体框架，有效降低诊断升级和活检转诊，提高筛查和诊断的特异性


<details>
  <summary>Details</summary>
Motivation: 降低诊断升级和不必要的活检转诊

Method: 提出一个名为BUSD-Agent的经验引导的级联多智能体框架，该框架将筛查和诊断建模为两阶段选择性决策过程

Result: 与未进行轨迹条件化的相同架构相比，经验引导的工作流程将BUSD-Agent的诊断升级从84.95%降低到58.72%，将整体活检转诊从59.50%降低到37.08%，同时提高了平均筛查特异性68.48%和诊断特异性6.33%

Conclusion: BUSD-Agent能够有效降低诊断升级和活检转诊，提高筛查和诊断的特异性

Abstract: We propose an experience-guided cascaded multi-agent framework for Breast Ultrasound Screening and Diagnosis, called BUSD-Agent, that aims to reduce diagnostic escalation and unnecessary biopsy referrals. Our framework models screening and diagnosis as a two-stage, selective decision-making process. A lightweight `screening clinic' agent, restricted to classification models as tools, selectively filters out benign and normal cases from further diagnostic escalation when malignancy risk and uncertainty are estimated as low. Cases that have higher risks are escalated to the `diagnostic clinic' agent, which integrates richer perception and radiological description tools to make a secondary decision on biopsy referral. To improve agent performance, past records of pathology-confirmed outcomes along with image embeddings, model predictions, and historical agent actions are stored in a memory bank as structured decision trajectories. For each new case, BUSD-Agent retrieves similar past cases based on image, model response and confidence similarity to condition the agent's current decision policy. This enables retrieval-conditioned in-context adaptation that dynamically adjusts model trust and escalation thresholds from prior experiences without parameter updates. Evaluation across 10 breast ultrasound datasets shows that the proposed experience-guided workflow reduces diagnostic escalation in BUSD-Agent from 84.95% to 58.72% and overall biopsy referrals from 59.50% to 37.08%, compared to the same architecture without trajectory conditioning, while improving average screening specificity by 68.48% and diagnostic specificity by 6.33%.

</details>


### [41] [SegMate: Asymmetric Attention-Based Lightweight Architecture for Efficient Multi-Organ Segmentation](https://arxiv.org/abs/2602.23903)
*Andrei-Alexandru Bunea,Dan-Matei Popovici,Radu Tudor Ionescu*

Main category: cs.CV

TL;DR: SegMate是一种高效且准确的新型医疗图像分割框架，适用于资源受限的临床环境。


<details>
  <summary>Details</summary>
Motivation: 在资源受限的临床环境中，现有的医疗图像分割模型虽然取得了卓越的准确性，但需要大量的计算资源，限制了其部署。

Method: 提出了一种名为SegMate的高效2.5D框架，通过精心整合非对称架构、注意力机制、多尺度特征融合、基于切片的位置条件和多任务优化，在减少计算需求的同时保持了准确性。

Result: 在三个数据集（TotalSegmentator、SegTHOR和AMOS22）上进行的实验表明，与普通模型相比，SegMate将计算（GFLOPs）减少了高达2.5倍，内存占用（VRAM）减少了高达2.1倍，同时通常将性能提升约1%。在TotalSegmentator上，SegMate实现了93.51%的Dice分数，同时只使用了295MB的峰值GPU内存。在SegTHOR和AMOS22上的零样本跨数据集评估显示出强大的泛化能力，分别达到了86.85%和89.35%的Dice分数。

Conclusion: SegMate框架在保证准确性的同时显著降低了计算需求，为资源受限的临床环境提供了有效的解决方案。

Abstract: State-of-the-art models for medical image segmentation achieve excellent accuracy but require substantial computational resources, limiting deployment in resource-constrained clinical settings. We present SegMate, an efficient 2.5D framework that achieves state-of-the-art accuracy, while considerably reducing computational requirements. Our efficient design is the result of meticulously integrating asymmetric architectures, attention mechanisms, multi-scale feature fusion, slice-based positional conditioning, and multi-task optimization. We demonstrate the efficiency-accuracy trade-off of our framework across three modern backbones (EfficientNetV2-M, MambaOut-Tiny, FastViT-T12). We perform experiments on three datasets: TotalSegmentator, SegTHOR and AMOS22. Compared with the vanilla models, SegMate reduces computation (GFLOPs) by up to 2.5x and memory footprint (VRAM) by up to 2.1x, while generally registering performance gains of around 1%. On TotalSegmentator, we achieve a Dice score of 93.51% with only 295MB peak GPU memory. Zero-shot cross-dataset evaluations on SegTHOR and AMOS22 demonstrate strong generalization, with Dice scores of up to 86.85% and 89.35%, respectively. We release our open-source code at https://github.com/andreibunea99/SegMate.

</details>


### [42] [Half-Truths Break Similarity-Based Retrieval](https://arxiv.org/abs/2602.23906)
*Bora Kargi,Arnas Uselis,Seong Joon Oh*

Main category: cs.CV

TL;DR: 提出CS-CLIP，通过组件监督和对照样本，提高CLIP-style双编码器对半真描述的识别能力。


<details>
  <summary>Details</summary>
Motivation: 为了解决CLIP-style双编码器在文本描述中加入错误细节时，相似度得分反而提高的问题。

Method: 提出CS-CLIP（组件监督CLIP），将描述分解为实体和关系单元，为每个单元构建最小编辑的对照样本，并对模型进行微调，使正确单元的得分高于对照样本，同时保持标准双编码器推理。

Result: CS-CLIP将半真率提高到69.3%，并将现有组合基准的平均性能提高了5.7个百分点。

Conclusion: 减少半真错误与更广泛的组合理解收益相一致。

Abstract: When a text description is extended with an additional detail, image-text similarity should drop if that detail is wrong. We show that CLIP-style dual encoders often violate this intuition: appending a plausible but incorrect object or relation to an otherwise correct description can increase the similarity score. We call such cases half-truths. On COCO, CLIP prefers the correct shorter description only 40.6% of the time, and performance drops to 32.9% when the added detail is a relation. We trace this vulnerability to weak supervision on caption parts: contrastive training aligns full sentences but does not explicitly enforce that individual entities and relations are grounded. We propose CS-CLIP (Component-Supervised CLIP), which decomposes captions into entity and relation units, constructs a minimally edited foil for each unit, and fine-tunes the model to score the correct unit above its foil while preserving standard dual-encoder inference. CS-CLIP raises half-truth accuracy to 69.3% and improves average performance on established compositional benchmarks by 5.7 points, suggesting that reducing half-truth errors aligns with broader gains in compositional understanding. Code is publicly available at: https://github.com/kargibora/CS-CLIP

</details>


### [43] [AgenticOCR: Parsing Only What You Need for Efficient Retrieval-Augmented Generation](https://arxiv.org/abs/2602.24134)
*Zhengren Wang,Dongsheng Ma,Huaping Zhong,Jiayu Li,Wentao Zhang,Bin Wang,Conghui He*

Main category: cs.CV

TL;DR: AgenticOCR提高视觉RAG系统性能


<details>
  <summary>Details</summary>
Motivation: 处理复杂视觉文档（如财务报告）的挑战

Method: 引入AgenticOCR，动态解析范式，将OCR从静态全文过程转变为查询驱动的按需提取系统

Result: 提高视觉RAG系统的效率和准确性，在长文档理解方面达到专家级性能

Conclusion: AgenticOCR作为视觉文档RAG堆栈的“第三块基石”，能够有效解耦检索粒度与刚性页面级分块

Abstract: The expansion of retrieval-augmented generation (RAG) into multimodal domains has intensified the challenge for processing complex visual documents, such as financial reports. While page-level chunking and retrieval is a natural starting point, it creates a critical bottleneck: delivering entire pages to the generator introduces excessive extraneous context. This not only overloads the generator's attention mechanism but also dilutes the most salient evidence. Moreover, compressing these information-rich pages into a limited visual token budget further increases the risk of hallucinations. To address this, we introduce AgenticOCR, a dynamic parsing paradigm that transforms optical character recognition (OCR) from a static, full-text process into a query-driven, on-demand extraction system. By autonomously analyzing document layout in a "thinking with images" manner, AgenticOCR identifies and selectively recognizes regions of interest. This approach performs on-demand decompression of visual tokens precisely where needed, effectively decoupling retrieval granularity from rigid page-level chunking. AgenticOCR has the potential to serve as the "third building block" of the visual document RAG stack, operating alongside and enhancing standard Embedding and Reranking modules. Experimental results demonstrate that AgenticOCR improves both the efficiency and accuracy of visual RAG systems, achieving expert-level performance in long document understanding. Code and models are available at https://github.com/OpenDataLab/AgenticOCR.

</details>


### [44] [Leveraging Geometric Prior Uncertainty and Complementary Constraints for High-Fidelity Neural Indoor Surface Reconstruction](https://arxiv.org/abs/2602.23926)
*Qiyu Feng,Jiwei Shan,Shing Shin Cheng,Hesheng Wang*

Main category: cs.CV

TL;DR: GPU-SDF：一种用于室内表面重建的神经隐式框架，提高了细小结构的重建质量


<details>
  <summary>Details</summary>
Motivation: 解决由于不可靠或噪声的几何先验而难以恢复细小结构等细节的问题

Method: 提出GPU-SDF，一个利用几何先验不确定性和互补约束的神经隐式框架

Result: 实验表明GPU-SDF提高了细小结构的重建质量，并且可以作为现有框架的即插即用增强

Conclusion: GPU-SDF是一种有效的室内表面重建方法，能够提高细小结构的重建质量

Abstract: Neural implicit surface reconstruction with signed distance function has made significant progress, but recovering fine details such as thin structures and complex geometries remains challenging due to unreliable or noisy geometric priors. Existing approaches rely on implicit uncertainty that arises during optimization to filter these priors, which is indirect and inefficient, and masking supervision in high-uncertainty regions further leads to under-constrained optimization. To address these issues, we propose GPU-SDF, a neural implicit framework for indoor surface reconstruction that leverages geometric prior uncertainty and complementary constraints. We introduce a self-supervised module that explicitly estimates prior uncertainty without auxiliary networks. Based on this estimation, we design an uncertainty-guided loss that modulates prior influence rather than discarding it, thereby retaining weak but informative cues. To address regions with high prior uncertainty, GPU-SDF further incorporates two complementary constraints: an edge distance field that strengthens boundary supervision and a multi-view consistency regularization that enforces geometric coherence. Extensive experiments confirm that GPU-SDF improves the reconstruction of fine details and serves as a plug-and-play enhancement for existing frameworks. Source code will be available at https://github.com/IRMVLab/GPU-SDF

</details>


### [45] [PointCoT: A Multi-modal Benchmark for Explicit 3D Geometric Reasoning](https://arxiv.org/abs/2602.23945)
*Dongxu Zhang,Yiding Sun,Pengcheng Li,Yumou Liu,Hongqiang Lin,Haoran Xu,Xiaoxuan Mu,Liang Lin,Wenbiao Yan,Ning Yang,Chaowei Fang,Juanjuan Zhao,Jihua Zhu,Conghui He,Cheng Tan*

Main category: cs.CV

TL;DR: PointCoT是一种新型框架，通过显式的思维链（CoT）推理增强MLLMs的3D点云理解能力，在复杂推理任务上实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: While Multimodal Large Language Models (MLLMs) demonstrate proficiency in 2D scenes, extending their perceptual intelligence to 3D point cloud understanding remains a significant challenge.

Method: We present PointCoT, a novel framework that empowers MLLMs with explicit Chain-of-Thought (CoT) reasoning for 3D data. We advocate for a \textit{Look, Think, then Answer} paradigm. In this approach, the model is supervised to generate geometry-grounded rationales before predicting final answers. To facilitate this, we construct Point-Reason-Instruct, a large-scale benchmark comprising $\sim$86k instruction-tuning samples with hierarchical CoT annotations. By leveraging a dual-stream multi-modal architecture, our method synergizes semantic appearance with geometric truth.

Result: Extensive experiments demonstrate that PointCoT achieves state-of-the-art performance on complex reasoning tasks.

Conclusion: PointCoT is a novel framework that enhances MLLMs' 3D point cloud understanding through explicit Chain-of-Thought (CoT) reasoning, achieving state-of-the-art performance on complex reasoning tasks.

Abstract: While Multimodal Large Language Models (MLLMs) demonstrate proficiency in 2D scenes, extending their perceptual intelligence to 3D point cloud understanding remains a significant challenge. Current approaches focus primarily on aligning 3D features with pre-trained models. However, they typically treat geometric reasoning as an implicit mapping process. These methods bypass intermediate logical steps and consequently suffer from geometric hallucinations. They confidently generate plausible responses that fail to ground in precise structural details. To bridge this gap, we present PointCoT, a novel framework that empowers MLLMs with explicit Chain-of-Thought (CoT) reasoning for 3D data. We advocate for a \textit{Look, Think, then Answer} paradigm. In this approach, the model is supervised to generate geometry-grounded rationales before predicting final answers. To facilitate this, we construct Point-Reason-Instruct, a large-scale benchmark comprising $\sim$86k instruction-tuning samples with hierarchical CoT annotations. By leveraging a dual-stream multi-modal architecture, our method synergizes semantic appearance with geometric truth. Extensive experiments demonstrate that PointCoT achieves state-of-the-art performance on complex reasoning tasks.

</details>


### [46] [CC-VQA: Conflict- and Correlation-Aware Method for Mitigating Knowledge Conflict in Knowledge-Based Visual Question Answering](https://arxiv.org/abs/2602.23952)
*Yuyang Hong,Jiaqi Gu,Yujin Lou,Lubin Fan,Qi Yang,Ying Wang,Kun Ding,Yue Wu,Shiming Xiang,Jieping Ye*

Main category: cs.CV

TL;DR: CC-VQA是KB-VQA的一个创新方法，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有知识冲突缓解方法忽略视觉信息在冲突中的关键作用，并遭受冗余检索上下文的影响。

Method: 提出了一种新的训练免费、冲突和相关性感知的方法CC-VQA，包括视觉中心化上下文冲突推理和相关性引导的编码与解码。

Result: 在E-VQA、InfoSeek和OK-VQA基准测试中，CC-VQA取得了最先进的性能，绝对准确率提高了3.3%至6.4%。

Conclusion: CC-VQA在KB-VQA任务中取得了最先进的性能，与现有方法相比，绝对准确率提高了3.3%至6.4%.

Abstract: Knowledge-based visual question answering (KB-VQA) demonstrates significant potential for handling knowledge-intensive tasks. However, conflicts arise between static parametric knowledge in vision language models (VLMs) and dynamically retrieved information due to the static model knowledge from pre-training. The outputs either ignore retrieved contexts or exhibit inconsistent integration with parametric knowledge, posing substantial challenges for KB-VQA. Current knowledge conflict mitigation methods primarily adapted from language-based approaches, focusing on context-level conflicts through engineered prompting strategies or context-aware decoding mechanisms. However, these methods neglect the critical role of visual information in conflicts and suffer from redundant retrieved contexts, which impair accurate conflict identification and effective mitigation. To address these limitations, we propose \textbf{CC-VQA}: a novel training-free, conflict- and correlation-aware method for KB-VQA. Our method comprises two core components: (1) Vision-Centric Contextual Conflict Reasoning, which performs visual-semantic conflict analysis across internal and external knowledge contexts; and (2) Correlation-Guided Encoding and Decoding, featuring positional encoding compression for low-correlation statements and adaptive decoding using correlation-weighted conflict scoring. Extensive evaluations on E-VQA, InfoSeek, and OK-VQA benchmarks demonstrate that CC-VQA achieves state-of-the-art performance, yielding absolute accuracy improvements of 3.3\% to 6.4\% compared to existing methods. Code is available at https://github.com/cqu-student/CC-VQA.

</details>


### [47] [GDA-YOLO11: Amodal Instance Segmentation for Occlusion-Robust Robotic Fruit Harvesting](https://arxiv.org/abs/2602.23953)
*Caner Beldek,Emre Sariyildiz,Son Lam Phung,Gursel Alici*

Main category: cs.CV

TL;DR: 提出了一种新模型，有效提高了机器人水果收获的遮挡处理能力。


<details>
  <summary>Details</summary>
Motivation: 减少农业收获中的遮挡问题导致的损失。

Method: 提出了一种基于新模型GDA-YOLO11的收获框架，并在受遮挡影响的数据集上进行评估。

Result: GDA-YOLO11在精度、mAP@50和mAP@50:95方面均优于YOLO11n，并实现了高成功率。

Conclusion: GDA-YOLO11显著提高了遮挡鲁棒分割，并简化了感知到行动的集成，为更可靠的农业自主系统铺平了道路。

Abstract: Occlusion remains a critical challenge in robotic fruit harvesting, as undetected or inaccurately localised fruits often results in substantial crop losses. To mitigate this issue, we propose a harvesting framework using a new amodal segmentation model, GDA-YOLO11, which incorporates architectural improvements and an updated asymmetric mask loss. The proposed model is trained on a modified version of a public citrus dataset and evaluated on both the base dataset and occlusion-sensitive subsets with varying occlusion levels. Within the framework, full fruit masks, including invisible regions, are inferred by GDA-YOLO11, and picking points are subsequently estimated using the Euclidean distance transform. These points are then projected into 3D coordinates for robotic harvesting execution. Experiments were conducted using real citrus fruits in a controlled environment simulating occlusion scenarios. Notably, to the best of our knowledge, this study provides the first practical demonstration of amodal instance segmentation in robotic fruit harvesting. GDA-YOLO11 achieves a precision of 0.844, recall of 0.846, mAP@50 of 0.914, and mAP@50:95 of 0.636, outperforming YOLO11n by 5.1%, 1.3%, and 1.0% in precision, mAP@50, and mAP@50:95, respectively. The framework attains harvesting success rates of 92.59%, 85.18%, 48.14%, and 22.22% at zero to high occlusion levels, improving success by 3.5% under medium and high occlusion. These findings demonstrate that GDA-YOLO11 enhances occlusion robust segmentation and streamlines perception-to-action integration, paving the way for more reliable autonomous systems in agriculture.

</details>


### [48] [SwitchCraft: Training-Free Multi-Event Video Generation with Attention Controls](https://arxiv.org/abs/2602.23956)
*Qianxun Xu,Chenxi Song,Yujun Cai,Chi Zhang*

Main category: cs.CV

TL;DR: SwitchCraft通过EAQS和ABSS改进了多事件视频生成。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到视频扩散模型在处理多事件提示时，缺乏显式的时间基础，导致场景混合或崩溃，破坏了预期的叙事。

Method: 提出了一种名为SwitchCraft的训练免费框架，用于多事件视频生成。引入了Event-Aligned Query Steering (EAQS)和Auto-Balance Strength Solver (ABSS)。

Result: 实验表明，与现有基线相比，SwitchCraft在提示对齐、事件清晰度和场景一致性方面有显著改进。

Conclusion: SwitchCraft为多事件视频生成提供了一种简单而有效的解决方案。

Abstract: Recent advances in text-to-video diffusion models have enabled high-fidelity and temporally coherent videos synthesis. However, current models are predominantly optimized for single-event generation. When handling multi-event prompts, without explicit temporal grounding, such models often produce blended or collapsed scenes that break the intended narrative. To address this limitation, we present SwitchCraft, a training-free framework for multi-event video generation. Our key insight is that uniform prompt injection across time ignores the correspondence between events and frames. To this end, we introduce Event-Aligned Query Steering (EAQS), which steers frame-level attention to align with relevant event prompts. Furthermore, we propose Auto-Balance Strength Solver (ABSS), which adaptively balances steering strength to preserve temporal consistency and visual fidelity. Extensive experiments demonstrate that SwitchCraft substantially improves prompt alignment, event clarity, and scene consistency compared with existing baselines, offering a simple yet effective solution for multi-event video generation.

</details>


### [49] [Thinking with Images as Continuous Actions: Numerical Visual Chain-of-Thought](https://arxiv.org/abs/2602.23959)
*Kesen Zhao,Beier Zhu,Junbao Zhou,Xingyu Zhu,Zhongqi Yue,Hanwang Zhang*

Main category: cs.CV

TL;DR: NV-CoT通过连续数值坐标提高MLLM图像推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在图像区域定位上存在模态不匹配和语义碎片化的问题，且固定粒度的补丁限制了精确的区域选择，通常需要非平凡的架构修改。

Method: 提出了一种名为Numerical Visual Chain-of-Thought (NV-CoT)的框架，该框架使MLLM能够使用连续的数值坐标对图像进行推理。NV-CoT将MLLM的动作空间从离散词汇标记扩展到连续欧几里得空间，允许模型仅通过最小的架构修改直接生成边界框坐标作为动作。该框架支持监督微调和强化学习。

Result: 在三个基准测试中，NV-CoT与八个代表性的视觉推理基线进行了广泛实验，结果表明NV-CoT显著提高了定位精度和最终答案的准确性，同时加速了训练收敛速度，验证了连续动作视觉推理在MLLM中的有效性。

Conclusion: NV-CoT通过使用连续数值坐标，提高了MLLM对图像进行推理的精确性和效率。

Abstract: Recent multimodal large language models (MLLMs) increasingly rely on visual chain-of-thought to perform region-grounded reasoning over images. However, existing approaches ground regions via either textified coordinates-causing modality mismatch and semantic fragmentation or fixed-granularity patches that both limit precise region selection and often require non-trivial architectural changes. In this paper, we propose Numerical Visual Chain-of-Thought (NV-CoT), a framework that enables MLLMs to reason over images using continuous numerical coordinates. NV-CoT expands the MLLM action space from discrete vocabulary tokens to a continuous Euclidean space, allowing models to directly generate bounding-box coordinates as actions with only minimal architectural modification. The framework supports both supervised fine-tuning and reinforcement learning. In particular, we replace categorical token policies with a Gaussian (or Laplace) policy over coordinates and introduce stochasticity via reparameterized sampling, making NV-CoT fully compatible with GRPO-style policy optimization. Extensive experiments on three benchmarks against eight representative visual reasoning baselines demonstrate that NV-CoT significantly improves localization precision and final answer accuracy, while also accelerating training convergence, validating the effectiveness of continuous-action visual reasoning in MLLMs. The code is available in https://github.com/kesenzhao/NV-CoT.

</details>


### [50] [SpikeTrack: A Spike-driven Framework for Efficient Visual Tracking](https://arxiv.org/abs/2602.23963)
*Qiuyang Zhang,Jiujun Cheng,Qichao Mao,Cong Liu,Yu Fang,Yuhong Li,Mengying Ge,Shangce Gao*

Main category: cs.CV

TL;DR: SpikeTrack：一种既准确又节能的SNN RGB跟踪框架。


<details>
  <summary>Details</summary>
Motivation: 针对现有SNN视觉跟踪框架的效率与准确率之间的权衡问题，提出了一种名为SpikeTrack的新框架。

Method: SpikeTrack采用新颖的非对称设计，利用非对称时间步扩展和单向信息流，同时利用神经元的空间时间动态特性并减少计算量。

Result: SpikeTrack在LaSOT数据集上超过了TransT，同时能耗仅为其1/26，实现了RGB跟踪的高准确性和低能耗。

Conclusion: SpikeTrack是第一个实现RGB跟踪既准确又节能的SNN框架。

Abstract: Spiking Neural Networks (SNNs) promise energy-efficient vision, but applying them to RGB visual tracking remains difficult: Existing SNN tracking frameworks either do not fully align with spike-driven computation or do not fully leverage neurons' spatiotemporal dynamics, leading to a trade-off between efficiency and accuracy. To address this, we introduce SpikeTrack, a spike-driven framework for energy-efficient RGB object tracking. SpikeTrack employs a novel asymmetric design that uses asymmetric timestep expansion and unidirectional information flow, harnessing spatiotemporal dynamics while cutting computation. To ensure effective unidirectional information transfer between branches, we design a memory-retrieval module inspired by neural inference mechanisms. This module recurrently queries a compact memory initialized by the template to retrieve target cues and sharpen target perception over time. Extensive experiments demonstrate that SpikeTrack achieves the state-of-the-art among SNN-based trackers and remains competitive with advanced ANN trackers. Notably, it surpasses TransT on LaSOT dataset while consuming only 1/26 of its energy. To our knowledge, SpikeTrack is the first spike-driven framework to make RGB tracking both accurate and energy efficient. The code and models are available at https://github.com/faicaiwawa/SpikeTrack.

</details>


### [51] [Venus: Benchmarking and Empowering Multimodal Large Language Models for Aesthetic Guidance and Cropping](https://arxiv.org/abs/2602.23980)
*Tianxiang Du,Hulingxiao He,Yuxin Peng*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The widespread use of smartphones has made photography ubiquitous, yet a clear gap remains between ordinary users and professional photographers, who can identify aesthetic issues and provide actionable shooting guidance during capture. We define this capability as aesthetic guidance (AG) -- an essential but largely underexplored domain in computational aesthetics. Existing multimodal large language models (MLLMs) primarily offer overly positive feedback, failing to identify issues or provide actionable guidance. Without AG capability, they cannot effectively identify distracting regions or optimize compositional balance, thus also struggling in aesthetic cropping, which aims to refine photo composition through reframing after capture. To address this, we introduce AesGuide, the first large-scale AG dataset and benchmark with 10,748 photos annotated with aesthetic scores, analyses, and guidance. Building upon it, we propose Venus, a two-stage framework that first empowers MLLMs with AG capability through progressively complex aesthetic questions and then activates their aesthetic cropping power via CoT-based rationales. Extensive experiments show that Venus substantially improves AG capability and achieves state-of-the-art (SOTA) performance in aesthetic cropping, enabling interpretable and interactive aesthetic refinement across both stages of photo creation. Code is available at https://github.com/PKU-ICST-MIPL/Venus_CVPR2026.

</details>


### [52] [Accelerating Masked Image Generation by Learning Latent Controlled Dynamics](https://arxiv.org/abs/2602.23996)
*Kaiwen Zhu,Quansheng Zeng,Yuandong Pu,Shuo Cao,Xiaohui Li,Yi Xin,Qi Qin,Jiayang Li,Yu Qiao,Jinjin Gu,Yihao Liu*

Main category: cs.CV

TL;DR: 提出 MIGM-Shortcut 模型，显著提升掩码图像生成效率


<details>
  <summary>Details</summary>
Motivation: 提高掩码图像生成模型的效率

Method: 提出了一种轻量级的模型，结合了之前特征和采样令牌，并回归特征演化的平均速度场

Result: 在 Lumina-DiMOO 上实现了超过 4 倍的加速，同时保持质量，显著推动了掩码图像生成的帕累托前沿

Conclusion: MIGM-Shortcut 模型有效地提高了掩码图像生成模型的效率

Abstract: Masked Image Generation Models (MIGMs) have achieved great success, yet their efficiency is hampered by the multiple steps of bi-directional attention. In fact, there exists notable redundancy in their computation: when sampling discrete tokens, the rich semantics contained in the continuous features are lost. Some existing works attempt to cache the features to approximate future features. However, they exhibit considerable approximation error under aggressive acceleration rates. We attribute this to their limited expressivity and the failure to account for sampling information. To fill this gap, we propose to learn a lightweight model that incorporates both previous features and sampled tokens, and regresses the average velocity field of feature evolution. The model has moderate complexity that suffices to capture the subtle dynamics while keeping lightweight compared to the original base model. We apply our method, MIGM-Shortcut, to two representative MIGM architectures and tasks. In particular, on the state-of-the-art Lumina-DiMOO, it achieves over 4x acceleration of text-to-image generation while maintaining quality, significantly pushing the Pareto frontier of masked image generation. The code and model weights are available at https://github.com/Kaiwen-Zhu/MIGM-Shortcut.

</details>


### [53] [Ordinal Diffusion Models for Color Fundus Images](https://arxiv.org/abs/2602.24013)
*Gustav Schmidt,Philipp Berens,Sarah Müller*

Main category: cs.CV

TL;DR: 提出了一种新的序数潜在扩散模型，用于生成彩色眼底图像，提高了糖尿病视网膜病变图像生成的性能。


<details>
  <summary>Details</summary>
Motivation: 改善临床相关任务性能，通过为深度学习模型提供补充训练数据。

Method: 提出了一种序数潜在扩散模型，该模型将糖尿病视网膜病变（DR）严重程度的有序结构显式地纳入生成过程。

Result: 与标准条件扩散模型相比，该模型在五个DR阶段中的四个阶段上减少了Fréchet inception距离，并将二次加权κ值从0.79提高到0.87。

Conclusion: 序数潜在扩散模型在生成彩色眼底图像方面表现出色，能够捕捉从有序、粗略的类别标签中学习到的疾病进展的连续谱。

Abstract: It has been suggested that generative image models such as diffusion models can improve performance on clinically relevant tasks by offering deep learning models supplementary training data. However, most conditional diffusion models treat disease stages as independent classes, ignoring the continuous nature of disease progression. This mismatch is problematic in medical imaging because continuous pathological processes are typically only observed through coarse, discrete but ordered labels as in ophthalmology for diabetic retinopathy (DR). We propose an ordinal latent diffusion model for generating color fundus images that explicitly incorporates the ordered structure of DR severity into the generation process. Instead of categorical conditioning, we used a scalar disease representation, enabling a smooth transition between adjacent stages. We evaluated our approach using visual realism metrics and classification-based clinical consistency analysis on the EyePACS dataset. Compared to a standard conditional diffusion model, our model reduced the Fréchet inception distance for four of the five DR stages and increased the quadratic weighted $κ$ from 0.79 to 0.87. Furthermore, interpolation experiments showed that the model captured a continuous spectrum of disease progression learned from ordered, coarse class labels.

</details>


### [54] [Interpretable Debiasing of Vision-Language Models for Social Fairness](https://arxiv.org/abs/2602.24014)
*Na Min An,Yoonna Jang,Yusuke Hirota,Ryo Hachiuma,Isabelle Augenstein,Hyunjung Shim*

Main category: cs.CV

TL;DR: 提出了一种新的框架来减轻VLMs的社会偏见，同时保持其语义知识


<details>
  <summary>Details</summary>
Motivation: 对VLMs黑盒推理过程的潜在社会偏见表示担忧

Method: 提出DeBiasLens框架，通过稀疏自动编码器定位社会属性神经元

Result: 有效减轻VLMs的社会偏见，而不损害其语义知识

Conclusion: 为未来审计工具奠定基础，优先考虑AI系统中的社会公平性

Abstract: The rapid advancement of Vision-Language models (VLMs) has raised growing concerns that their black-box reasoning processes could lead to unintended forms of social bias. Current debiasing approaches focus on mitigating surface-level bias signals through post-hoc learning or test-time algorithms, while leaving the internal dynamics of the model largely unexplored. In this work, we introduce an interpretable, model-agnostic bias mitigation framework, DeBiasLens, that localizes social attribute neurons in VLMs through sparse autoencoders (SAEs) applied to multimodal encoders. Building upon the disentanglement ability of SAEs, we train them on facial image or caption datasets without corresponding social attribute labels to uncover neurons highly responsive to specific demographics, including those that are underrepresented. By selectively deactivating the social neurons most strongly tied to bias for each group, we effectively mitigate socially biased behaviors of VLMs without degrading their semantic knowledge. Our research lays the groundwork for future auditing tools, prioritizing social fairness in emerging real-world AI systems.

</details>


### [55] [SR3R: Rethinking Super-Resolution 3D Reconstruction With Feed-Forward Gaussian Splatting](https://arxiv.org/abs/2602.24020)
*Xiang Feng,Xiangbo Wang,Tieshi Zhong,Chengkai Wang,Yiting Zhao,Tianxiang Xu,Zhenzhong Kuang,Feiwei Qin,Xuefei Yin,Yanming Zhu*

Main category: cs.CV

TL;DR: 提出了一种新的3DSR方法，通过直接前馈映射提高重建保真度和泛化能力，实验结果表明优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有3D超分辨率方法依赖于密集的LR输入和场景优化，限制了从预训练的2D超分辨率模型继承的高频先验，从而严重限制了重建保真度、场景泛化能力和实时可用性。

Method: 提出将3DSR重新定义为从稀疏LR视图到HR 3DGS表示的直接前馈映射，使模型能够从大规模、多场景数据中自主学习3D特定的几何和外观的高频信息。引入SR3R框架，直接从稀疏LR视图预测HR 3DGS表示。还引入高斯偏移学习和特征细化来提高重建保真度。

Result: 实验结果表明，SR3R优于现有的3DSR方法，实现了强大的零样本泛化能力，甚至在未见过的场景上优于SOTA场景优化方法。

Conclusion: 该方法有效提高了3DSR的重建保真度和泛化能力，为3D超分辨率提供了新的思路。

Abstract: 3D super-resolution (3DSR) aims to reconstruct high-resolution (HR) 3D scenes from low-resolution (LR) multi-view images. Existing methods rely on dense LR inputs and per-scene optimization, which restricts the high-frequency priors for constructing HR 3D Gaussian Splatting (3DGS) to those inherited from pretrained 2D super-resolution (2DSR) models. This severely limits reconstruction fidelity, cross-scene generalization, and real-time usability. We propose to reformulate 3DSR as a direct feed-forward mapping from sparse LR views to HR 3DGS representations, enabling the model to autonomously learn 3D-specific high-frequency geometry and appearance from large-scale, multi-scene data. This fundamentally changes how 3DSR acquires high-frequency knowledge and enables robust generalization to unseen scenes. Specifically, we introduce SR3R, a feed-forward framework that directly predicts HR 3DGS representations from sparse LR views via the learned mapping network. To further enhance reconstruction fidelity, we introduce Gaussian offset learning and feature refinement, which stabilize reconstruction and sharpen high-frequency details. SR3R is plug-and-play and can be paired with any feed-forward 3DGS reconstruction backbone: the backbone provides an LR 3DGS scaffold, and SR3R upscales it to an HR 3DGS. Extensive experiments across three 3D benchmarks demonstrate that SR3R surpasses state-of-the-art (SOTA) 3DSR methods and achieves strong zero-shot generalization, even outperforming SOTA per-scene optimization methods on unseen scenes.

</details>


### [56] [Steering and Rectifying Latent Representation Manifolds in Frozen Multi-modal LLMs for Video Anomaly Detection](https://arxiv.org/abs/2602.24021)
*Zhaolin Cai,Fan Li,Huiyu Duan,Lijun He,Guangtao Zhai*

Main category: cs.CV

TL;DR: SteerVAD：通过主动引导和校正内部表示提升基于MLLM的视频异常检测性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统视频异常检测方法在标注数据和训练成本方面的问题，以及近期一些方法在性能上的局限性，本文提出了一种新的干预框架SteerVAD。

Method: SteerVAD通过主动引导和校正内部表示来提升基于多模态大型语言模型（MLLM）的视频异常检测（VAD）性能。首先利用无梯度表示可分性分析（RSA）识别出对VAD最有判别力的潜在异常专家（LAEs），然后通过分层元控制器（HMC）生成动态校正信号，直接对LAE表示流形进行有针对性的各向异性缩放，增强异常相关维度并抑制固有偏差。

Result: 在主流基准数据集上的实验表明，SteerVAD在无需微调的方法中实现了最先进的性能，仅需1%的训练数据。

Conclusion: SteerVAD为视频异常检测提供了一种强大的新方向。

Abstract: Video anomaly detection (VAD) aims to identify abnormal events in videos. Traditional VAD methods generally suffer from the high costs of labeled data and full training, thus some recent works have explored leveraging frozen multi-modal large language models (MLLMs) in a tuning-free manner to perform VAD. However, their performance is limited as they directly inherit pre-training biases and cannot adapt internal representations to specific video contexts, leading to difficulties in handling subtle or ambiguous anomalies. To address these limitations, we propose a novel intervention framework, termed SteerVAD, which advances MLLM-based VAD by shifting from passively reading to actively steering and rectifying internal representations. Our approach first leverages the gradient-free representational separability analysis (RSA) to identify top attention heads as latent anomaly experts (LAEs) which are most discriminative for VAD. Then a hierarchical meta-controller (HMC) generates dynamic rectification signals by jointly conditioning on global context and these LAE outputs. The signals execute targeted, anisotropic scaling directly upon the LAE representation manifolds, amplifying anomaly-relevant dimensions while suppressing inherent biases. Extensive experiments on mainstream benchmarks demonstrate our method achieves state-of-the-art performance among tuning-free approaches requiring only 1% of training data, establishing it as a powerful new direction for video anomaly detection. The code will be released upon the publication.

</details>


### [57] [GuardAlign: Test-time Safety Alignment in Multimodal Large Language Models](https://arxiv.org/abs/2602.24027)
*Xingyu Zhu,Beier Zhu,Junfeng Fang,Shuo Wang,Yin Zhang,Xiang Wang,Xiangnan He*

Main category: cs.CV

TL;DR: GuardAlign是一种新的训练免费防御框架，用于提高LVLMs的安全性，同时保持其效用。


<details>
  <summary>Details</summary>
Motivation: 为了解决大视觉语言模型（LVLMs）在视觉语言推理任务中的安全问题，提出了一种名为GuardAlign的训练免费防御框架。

Method: GuardAlign框架结合了两种策略：OT增强安全检测和跨模态注意力校准。

Result: 在六个代表性的MLLMs上进行了广泛的评估，GuardAlign在SPA-VL上降低了39%的不安全响应率，同时保持了效用，将VQAv2的评分从78.51%提高到79.21%。

Conclusion: GuardAlign在提高LVLMs安全性的同时，保持了模型的效用。

Abstract: Large vision-language models (LVLMs) have achieved remarkable progress in vision-language reasoning tasks, yet ensuring their safety remains a critical challenge. Recent input-side defenses detect unsafe images with CLIP and prepend safety prefixes to prompts, but they still suffer from inaccurate detection in complex scenes and unstable safety signals during decoding. To address these issues, we propose GuardAlign, a training-free defense framework that integrates two strategies. First, OT-enhanced safety detection leverages optimal transport to measure distribution distances between image patches and unsafe semantics, enabling accurate identification of malicious regions without additional computational cost. Second, cross-modal attentive calibration strengthens the influence of safety prefixes by adaptively reallocating attention across layers, ensuring that safety signals remain consistently activated throughout generation. Extensive evaluations on six representative MLLMs demonstrate that GuardAlign reduces unsafe response rates by up to 39% on SPA-VL, while preserving utility, achieving an improvement on VQAv2 from 78.51% to 79.21%.

</details>


### [58] [Look Carefully: Adaptive Visual Reinforcements in Multimodal Large Language Models for Hallucination Mitigation](https://arxiv.org/abs/2602.24041)
*Xingyu Zhu,Kesen Zhao,Liang Yi,Shuo Wang,Zhicai Wang,Beier Zhu,Hanwang Zhang*

Main category: cs.CV

TL;DR: Adaptive Visual Reinforcement (AIR) 通过无监督方法显著减少了 MLLMs 中的幻觉。


<details>
  <summary>Details</summary>
Motivation: 为了解决MLLMs在视觉语言推理中易出现幻觉的问题，现有的缓解策略要么需要昂贵的训练监督，要么在推理时引入额外的延迟。

Method: 提出了一种名为Adaptive Visual Reinforcement (AIR)的无监督框架，包括基于原型 token 减少和OT引导的 patch 增强。

Result: 实验表明，AIR显著减少了幻觉，同时保留了通用能力，成为构建可靠MLLMs的有效解决方案。

Conclusion: Adaptive Visual Reinforcement (AIR) 是一种有效的无监督框架，可以显著减少 MLLMs 中的幻觉。

Abstract: Multimodal large language models (MLLMs) have achieved remarkable progress in vision-language reasoning, yet they remain vulnerable to hallucination, where generated content deviates from visual evidence. Existing mitigation strategies either require costly supervision during training or introduce additional latency at inference time. Recent vision enhancement methods attempt to address this issue by reinforcing visual tokens during decoding, but they typically inject all tokens indiscriminately, which causes interference from background regions and distracts the model from critical cues. To overcome this challenge, we propose Adaptive Visual Reinforcement (AIR), a training-free framework for MLLMs. AIR consists of two components. Prototype-based token reduction condenses the large pool of visual tokens into a compact subset to suppress redundancy. OT-guided patch reinforcement quantifies the alignment between hidden states and patch embeddings to selectively integrate the most consistent patches into feed-forward layers. As a result, AIR enhances the model's reliance on salient visual information and effectively mitigates hallucination. Extensive experiments across representative MLLMs demonstrate that AIR substantially reduces hallucination while preserving general capabilities, establishing it as an effective solution for building reliable MLLMs.

</details>


### [59] [Spatio-Temporal Garment Reconstruction Using Diffusion Mapping via Pattern Coordinates](https://arxiv.org/abs/2602.24043)
*Yingxuan You,Ren Li,Corentin Dumery,Cong Cao,Hao Li,Pascal Fua*

Main category: cs.CV

TL;DR: 提出了一种从单张图像和视频中重建3D着装人类的统一框架，实现了高保真重建，并支持下游应用。


<details>
  <summary>Details</summary>
Motivation: 从单张图像和视频中重建3D着装人类是虚拟试穿、头像创建和混合现实等应用中的基本问题。尽管在人体恢复方面取得了重大进展，但准确重建服装几何形状，特别是宽松服装的几何形状，仍然是一个挑战。

Method: 提出了一种统一的框架，结合隐式缝合图案（ISP）和生成扩散模型，在2D UV空间中学习表达式的服装形状先验。利用这些先验，引入了一种映射模型，在图像像素、UV图案坐标和3D几何之间建立对应关系，从而实现从单张图像中准确和详细地重建服装。此外，通过引入时空扩散方案和测试时引导，进一步扩展到动态重建，以强制执行长期时间一致性。还开发了基于解析投影的约束，以保持可见区域的图像对齐几何形状，同时随着时间的推移在遮挡区域强制执行一致的完成。

Result: 虽然仅在合成模拟的布料数据上训练，但该方法在真实世界图像上泛化良好，并且在紧身和宽松服装上均优于现有方法。重建的服装保留了精细的几何细节，并表现出逼真的动态运动，支持下游应用，如纹理编辑、服装重定向和动画。

Conclusion: 该方法为高保真3D服装重建提供了一种有效的解决方案，可以应用于虚拟试穿、头像创建和混合现实等领域。

Abstract: Reconstructing 3D clothed humans from monocular images and videos is a fundamental problem with applications in virtual try-on, avatar creation, and mixed reality. Despite significant progress in human body recovery, accurately reconstructing garment geometry, particularly for loose-fitting clothing, remains an open challenge. We propose a unified framework for high-fidelity 3D garment reconstruction from both single images and video sequences. Our approach combines Implicit Sewing Patterns (ISP) with a generative diffusion model to learn expressive garment shape priors in 2D UV space. Leveraging these priors, we introduce a mapping model that establishes correspondences between image pixels, UV pattern coordinates, and 3D geometry, enabling accurate and detailed garment reconstruction from single images. We further extend this formulation to dynamic reconstruction by introducing a spatio-temporal diffusion scheme with test-time guidance to enforce long-range temporal consistency. We also develop analytic projection-based constraints that preserve image-aligned geometry in visible regions while enforcing coherent completion in occluded areas over time. Although trained exclusively on synthetically simulated cloth data, our method generalizes well to real-world imagery and consistently outperforms existing approaches on both tight- and loose-fitting garments. The reconstructed garments preserve fine geometric detail while exhibiting realistic dynamic motion, supporting downstream applications such as texture editing, garment retargeting, and animation.

</details>


### [60] [Quant Experts: Token-aware Adaptive Error Reconstruction with Mixture of Experts for Large Vision-Language Models Quantization](https://arxiv.org/abs/2602.24059)
*Chenwei Jia,Baoting Li,Xuchong Zhang,Mingzhuo Wei,Bochen Lin,Hongbin Sun*

Main category: cs.CV

TL;DR: 提出了Quant Experts（QE），一种针对VLMs的token感知自适应误差补偿方法，显著提高了量化模型的性能。


<details>
  <summary>Details</summary>
Motivation: 为了减轻视觉语言模型（VLMs）的计算和内存开销，提出了后训练量化（PTQ）技术。

Method: 提出了名为Quant Experts（QE）的token感知自适应误差补偿方法，用于VLMs量化。QE将重要通道分为token独立和token相关两组。对于前者，为大多数token设计了一个共享专家，使用低秩适配器补偿全局量化误差。对于后者，设计了包括多个路由低秩适配器的路由专家，以补偿与特定token相关的局部量化误差。

Result: QE在多种量化设置和模型规模下，从2B到70B参数，持续提高任务准确性，同时保持与全精度模型相当的性能。

Conclusion: QE是一种有效的VLMs量化方法，可以显著提高量化模型的性能。

Abstract: Post-Training Quantization (PTQ) has emerged as an effective technique for alleviating the substantial computational and memory overheads of Vision-Language Models (VLMs) by compressing both weights and activations without retraining the full model. Existing PTQ methods primarily rely on static identification and global compensation of sensitive or outlier channels, yet they often overlook the distributional differences of these important channels across inputs, leading to unsatisfactory quantization. In this work, we observe that the distributions and occurrence frequencies of important channels vary significantly both across modalities and among tokens, even within the same modality. Accordingly, we propose \textbf{Quant Experts (QE)}, a token-aware adaptive error compensation with mixture-of-experts for VLMs quantization. QE divides the important channels into token-independent and token-dependent groups. For the former, a shared expert is designed for most tokens to compensate for global quantization error using a low-rank adapter. For the latter, routed experts including multiple routed low-rank adapters are elaborated to compensate for local quantization error related to specific tokens. Extensive experiments demonstrate that QE consistently enhances task accuracy across various quantization settings and model scales, ranging from 2B to 70B parameters, while maintaining performance comparable to full-precision models.

</details>


### [61] [EvalMVX: A Unified Benchmarking for Neural 3D Reconstruction under Diverse Multiview Setups](https://arxiv.org/abs/2602.24065)
*Zaiyan Yang,Jieji Ren,Xiangyi Wang,zonglin li,Xu Cao,Heng Guo,Zhanyu Ma,Boxin Shi*

Main category: cs.CV

TL;DR: 提出EvalMVX数据集，评估多视图3D重建方法，为未来研究提供启示。


<details>
  <summary>Details</summary>
Motivation: 为了确定不同MVX（MVS、MVSfP和MVPS）技术的适用范围，并评估多视图3D重建方法。

Method: 提出EvalMVX，一个包含25个物体的真实世界数据集，每个物体在20个不同视角和17种光照条件下，使用偏振相机捕获，并包含对齐的地面真实3D网格，以促进MVX方法的定量基准测试。

Result: 评估了13种MVX方法，记录了表现最佳的方法，并确定了在不同几何细节和反射类型下的开放性问题。

Conclusion: EvalMVX和基准测试结果可以启发未来多视图3D重建研究。

Abstract: Recent advancements in neural surface reconstruction have significantly enhanced 3D reconstruction. However, current real world datasets mainly focus on benchmarking multiview stereo (MVS) based on RGB inputs. Multiview photometric stereo (MVPS) and multiview shape from polarization (MVSfP), though indispensable on high-fidelity surface reconstruction and sparse inputs, have not been quantitatively assessed together with MVS. To determine the working range of different MVX (MVS, MVSfP, and MVPS) techniques, we propose EvalMVX, a real-world dataset containing $25$ objects, each captured with a polarized camera under $20$ varying views and $17$ light conditions including OLAT and natural illumination, leading to $8,500$ images. Each object includes aligned ground-truth 3D mesh, facilitating quantitative benchmarking of MVX methods simultaneously. Based on our EvalMVX, we evaluate $13$ MVX methods published in recent years, record the best-performing methods, and identify open problems under diverse geometric details and reflectance types. We hope EvalMVX and the benchmarking results can inspire future research on multiview 3D reconstruction.

</details>


### [62] [FocusTrack: One-Stage Focus-and-Suppress Framework for 3D Point Cloud Object Tracking](https://arxiv.org/abs/2602.24133)
*Sifan Zhou,Jiahao Nie,Ziyu Zhao,Yichao Cao,Xiaobo Lu*

Main category: cs.CV

TL;DR: FocusTrack通过IMM和关注-抑制注意力实现高效的一阶段3D点云对象跟踪。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有基于运动的两阶段方法存在的局限性，如误差累积和计算瓶颈。

Method: 提出FocusTrack，一个新颖的一阶段跟踪框架，通过两个核心创新：帧间运动建模（IMM）和关注-抑制注意力。

Result: 在KITTI、nuScenes和Waymo等3D跟踪基准上实现新SOTA性能，同时以105 FPS的速度运行。

Conclusion: FocusTrack在保持高性能的同时，提高了速度和效率。

Abstract: In 3D point cloud object tracking, the motion-centric methods have emerged as a promising avenue due to its superior performance in modeling inter-frame motion. However, existing two-stage motion-based approaches suffer from fundamental limitations: (1) error accumulation due to decoupled optimization caused by explicit foreground segmentation prior to motion estimation, and (2) computational bottlenecks from sequential processing. To address these challenges, we propose FocusTrack, a novel one-stage paradigms tracking framework that unifies motion-semantics co-modeling through two core innovations: Inter-frame Motion Modeling (IMM) and Focus-and-Suppress Attention. The IMM module employs a temp-oral-difference siamese encoder to capture global motion patterns between adjacent frames. The Focus-and-Suppress attention that enhance the foreground semantics via motion-salient feature gating and suppress the background noise based on the temporal-aware motion context from IMM without explicit segmentation. Based on above two designs, FocusTrack enables end-to-end training with compact one-stage pipeline. Extensive experiments on prominent 3D tracking benchmarks, such as KITTI, nuScenes, and Waymo, demonstrate that the FocusTrack achieves new SOTA performance while running at a high speed with 105 FPS.

</details>


### [63] [Prune Wisely, Reconstruct Sharply: Compact 3D Gaussian Splatting via Adaptive Pruning and Difference-of-Gaussian Primitives](https://arxiv.org/abs/2602.24136)
*Haoran Wang,Guoxi Huang,Fan Zhang,David Bull,Nantheera Anantrasirichai*

Main category: cs.CV

TL;DR: 提出了一种高效的3D场景表示方法，显著提高渲染质量并降低冗余。


<details>
  <summary>Details</summary>
Motivation: 为了提高3D场景表示的效率，降低冗余和提高渲染质量。

Method: 提出了一种高效的重建感知剪枝策略和3D差异高斯原始数据。

Result: 显著提高了模型的紧凑性，在保持视觉质量相似甚至更好的同时，将高斯数量减少了90%。

Conclusion: 该方法对于3D场景表示具有重大意义，能够实现高效和高质量的实时渲染。

Abstract: Recent significant advances in 3D scene representation have been driven by 3D Gaussian Splatting (3DGS), which has enabled real-time rendering with photorealistic quality. 3DGS often requires a large number of primitives to achieve high fidelity, leading to redundant representations and high resource consumption, thereby limiting its scalability for complex or large-scale scenes. Consequently, effective pruning strategies and more expressive primitives that can reduce redundancy while preserving visual quality are crucial for practical deployment. We propose an efficient, integrated reconstruction-aware pruning strategy that adaptively determines pruning timing and refining intervals based on reconstruction quality, thus reducing model size while enhancing rendering quality. Moreover, we introduce a 3D Difference-of-Gaussians primitive that jointly models both positive and negative densities in a single primitive, improving the expressiveness of Gaussians under compact configurations. Our method significantly improves model compactness, achieving up to 90\% reduction in Gaussian-count while delivering visual quality that is similar to, or in some cases better than, that produced by state-of-the-art methods. Code will be made publicly available.

</details>


### [64] [Multimodal Optimal Transport for Unsupervised Temporal Segmentation in Surgical Robotics](https://arxiv.org/abs/2602.24138)
*Omar Mohamed,Edoardo Fazzari,Ayah Al-Naji,Hamdan Alhadhrami,Khalfan Hableel,Saif Alkindi,Cesare Stefanini*

Main category: cs.CV

TL;DR: 提出了一种新的无监督方法TASOT，通过文本信息增强动作分割，有效降低手术视频分析成本


<details>
  <summary>Details</summary>
Motivation: 降低手术视频分析中的计算和数据收集成本

Method: 提出Text-Augmented Action Segmentation Optimal Transport (TASOT)方法，将文本信息融入ASOT，将时间动作分割作为多模态最优传输问题处理

Result: 在多个手术数据集上观察到比现有零样本方法更一致的实质性改进

Conclusion: 通过利用标准视觉和文本表示中的信息，可以实现精细的手术理解，无需复杂的预训练流程

Abstract: Recognizing surgical phases and steps from video is a fundamental problem in computer-assisted interventions. Recent approaches increasingly rely on large-scale pre-training on thousands of labeled surgical videos, followed by zero-shot transfer to specific procedures. While effective, this strategy incurs substantial computational and data collection costs. In this work, we question whether such heavy pre-training is truly necessary. We propose Text-Augmented Action Segmentation Optimal Transport (TASOT), an unsupervised method for surgical phase and step recognition that extends Action Segmentation Optimal Transport (ASOT) by incorporating textual information generated directly from the videos. TASOT formulates temporal action segmentation as a multimodal optimal transport problem, where the matching cost is defined as a weighted combination of visual and text-based costs. The visual term captures frame-level appearance similarity, while the text term provides complementary semantic cues, and both are jointly regularized through a temporally consistent unbalanced Gromov-Wasserstein formulation. This design enables effective alignment between video frames and surgical actions without surgical-specific pretraining or external web-scale supervision. We evaluate TASOT on multiple benchmark surgical datasets and observe consistent and substantial improvements over existing zero-shot methods, including StrasBypass70 (+23.7), BernBypass70 (+4.5), Cholec80 (+16.5), and AutoLaparo (+19.6). These results demonstrate that fine-grained surgical understanding can be achieved by exploiting information already present in standard visual and textual representations, without resorting to increasingly complex pre-training pipelines. The code will be available at https://github.com/omar8ahmed9/TASOT.

</details>


### [65] [Fixed Anchors Are Not Enough: Dynamic Retrieval and Persistent Homology for Dataset Distillation](https://arxiv.org/abs/2602.24144)
*Muquan Li,Hang Gou,Yingyi Ma,Rongzheng Wang,Ke Qin,Tao He*

Main category: cs.CV

TL;DR: RETA通过动态检索连接和持久拓扑对齐，提高了解耦数据集蒸馏的性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决当前残差匹配管道依赖于静态真实补丁的问题，导致拟合复杂度差距和拉向锚点效应，从而降低类内多样性和泛化能力。

Method: 提出了一种名为RETA的检索和拓扑对齐框架，包括动态检索连接（DRC）和持久拓扑对齐（PTA）。DRC通过在教师特征空间中最小化拟合复杂度分数从预建池中选择真实补丁，并通过残差连接注入所选补丁以紧化特征拟合并控制注入的复杂度。PTA使用持久同伦正则化合成，构建相互k-NN特征图，计算组件和环的持久图像，并惩罚真实和合成集之间的拓扑差异，以减轻拉向锚点效应。

Result: 在CIFAR-100、Tiny-ImageNet、ImageNet-1K和多个ImageNet子集上，RETA在可比的时间和内存下，始终优于各种基线，特别是在ImageNet-1K上，使用ResNet-18在每类50个图像的情况下，达到了64.3%的top-1准确率，比最佳先前方法高出3.1%。

Conclusion: RETA框架有效提高了解耦数据集蒸馏的性能，特别是在降低拟合复杂度差距和拉向锚点效应方面。

Abstract: Decoupled dataset distillation (DD) compresses large corpora into a few synthetic images by matching a frozen teacher's statistics. However, current residual-matching pipelines rely on static real patches, creating a fit-complexity gap and a pull-to-anchor effect that reduce intra-class diversity and hurt generalization. To address these issues, we introduce RETA -- a Retrieval and Topology Alignment framework for decoupled DD. First, Dynamic Retrieval Connection (DRC) selects a real patch from a prebuilt pool by minimizing a fit-complexity score in teacher feature space; the chosen patch is injected via a residual connection to tighten feature fit while controlling injected complexity. Second, Persistent Topology Alignment (PTA) regularizes synthesis with persistent homology: we build a mutual k-NN feature graph, compute persistence images of components and loops, and penalize topology discrepancies between real and synthetic sets, mitigating pull-to-anchor effect. Across CIFAR-100, Tiny-ImageNet, ImageNet-1K, and multiple ImageNet subsets, RETA consistently outperforms various baselines under comparable time and memory, especially reaching 64.3% top-1 accuracy on ImageNet-1K with ResNet-18 at 50 images per class, +3.1% over the best prior.

</details>


### [66] [HumanOrbit: 3D Human Reconstruction as 360° Orbit Generation](https://arxiv.org/abs/2602.24148)
*Keito Suzuki,Kunyao Chen,Lei Wang,Bang Du,Runfa Blark Li,Peng Liu,Ning Bi,Truong Nguyen*

Main category: cs.CV

TL;DR: 提出了一种名为HumanOrbit的视频扩散模型，用于生成360度环绕一个人的多视图视频，实验证明其效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了生成360度环绕一个人的视频，现有方法通常采用基于图像的扩散模型进行多视图合成，但结果在不同视图和原始身份之间不一致。受此启发，我们提出了一种名为HumanOrbit的视频扩散模型，用于多视图人像生成。

Method: HumanOrbit是一种视频扩散模型，能够合成连续的相机旋转，产生几何上一致的 novel 视图，同时保留人的外观和身份。

Result: 实验结果表明，HumanOrbit在多视图图像生成方面有效，重建的3D模型在完整性和保真度方面优于现有基线。

Conclusion: HumanOrbit为多视图图像生成提供了一种新的方法，能够生成具有高质量外观和身份一致性的3D模型。

Abstract: We present a method for generating a full 360° orbit video around a person from a single input image. Existing methods typically adapt image-based diffusion models for multi-view synthesis, but yield inconsistent results across views and with the original identity. In contrast, recent video diffusion models have demonstrated their ability in generating photorealistic results that align well with the given prompts. Inspired by these results, we propose HumanOrbit, a video diffusion model for multi-view human image generation. Our approach enables the model to synthesize continuous camera rotations around the subject, producing geometrically consistent novel views while preserving the appearance and identity of the person. Using the generated multi-view frames, we further propose a reconstruction pipeline that recovers a textured mesh of the subject. Experimental results validate the effectiveness of HumanOrbit for multi-view image generation and that the reconstructed 3D models exhibit superior completeness and fidelity compared to those from state-of-the-art baselines.

</details>


### [67] [Manifold-Preserving Superpixel Hierarchies and Embeddings for the Exploration of High-Dimensional Images](https://arxiv.org/abs/2602.24160)
*Alexander Vieth,Boudewijn Lelieveldt,Elmar Eisemann,Anna Vilanova,Thomas Höllt*

Main category: cs.CV

TL;DR: 提出了一种新的图像引导的层次结构，用于更有效地探索高维图像中的感兴趣区域。


<details>
  <summary>Details</summary>
Motivation: 现有的层次降维方法在构建层次结构时仅考虑属性信息，忽略了图像中像素的空间布局。这阻碍了在图像空间中对感兴趣区域的探索，因为在图像空间中的感兴趣区域与其在层次结构中关联的属性抽象之间没有一致性。

Method: 提出了一种新的图像引导的层次结构，在构建层次结构时考虑了高维属性流形。

Result: 这种方法使得可以在图像和属性空间中一致地探索高维图像，并在两个用例中与经典基于层次嵌入的图像探索方法进行了比较，以展示其有效性。

Conclusion: 提出的方法可以有效地在图像和属性空间中探索高维图像，提高了对感兴趣区域的探索能力。

Abstract: High-dimensional images, or images with a high-dimensional attribute vector per pixel, are commonly explored with coordinated views of a low-dimensional embedding of the attribute space and a conventional image representation. Nowadays, such images can easily contain several million pixels. For such large datasets, hierarchical embedding techniques are better suited to represent the high-dimensional attribute space than flat dimensionality reduction methods. However, available hierarchical dimensionality reduction methods construct the hierarchy purely based on the attribute information and ignore the spatial layout of pixels in the images. This impedes the exploration of regions of interest in the image space, since there is no congruence between a region of interest in image space and the associated attribute abstractions in the hierarchy. In this paper, we present a superpixel hierarchy for high-dimensional images that takes the high-dimensional attribute manifold into account during construction. Through this, our method enables consistent exploration of high-dimensional images in both image and attribute space. We show the effectiveness of this new image-guided hierarchy in the context of embedding exploration by comparing it with classical hierarchical embedding-based image exploration in two use cases.

</details>


### [68] [GeoDiff4D: Geometry-Aware Diffusion for 4D Head Avatar Reconstruction](https://arxiv.org/abs/2602.24161)
*Chao Xu,Xiaochen Zhao,Xiang Deng,Jingxiang Sun,Zhuo Su,Donglin Di,Yebin Liu*

Main category: cs.CV

TL;DR: 提出了一种基于几何感知扩散的新框架，用于从单张肖像图像中重建逼真且可动的4D头像。


<details>
  <summary>Details</summary>
Motivation: 重建从单张肖像图像中获取逼真且可动4D头像在计算机视觉中是一个基本挑战。

Method: 提出了一种利用几何感知扩散学习强大几何先验的框架，以实现高保真头像重建。该方法联合生成肖像图像和相应的表面法线，同时使用无姿态表达式编码器捕获隐式表达式表示。

Result: 实验表明，该方法在视觉质量、表情保真度和跨身份泛化方面显著优于现有方法，同时支持实时渲染。

Conclusion: 该方法为高保真头像重建提供了一种新的解决方案，具有显著的性能优势。

Abstract: Reconstructing photorealistic and animatable 4D head avatars from a single portrait image remains a fundamental challenge in computer vision. While diffusion models have enabled remarkable progress in image and video generation for avatar reconstruction, existing methods primarily rely on 2D priors and struggle to achieve consistent 3D geometry. We propose a novel framework that leverages geometry-aware diffusion to learn strong geometry priors for high-fidelity head avatar reconstruction. Our approach jointly synthesizes portrait images and corresponding surface normals, while a pose-free expression encoder captures implicit expression representations. Both synthesized images and expression latents are incorporated into 3D Gaussian-based avatars, enabling photorealistic rendering with accurate geometry. Extensive experiments demonstrate that our method substantially outperforms state-of-the-art approaches in visual quality, expression fidelity, and cross-identity generalization, while supporting real-time rendering.

</details>


### [69] [A Mixed Diet Makes DINO An Omnivorous Vision Encoder](https://arxiv.org/abs/2602.24181)
*Rishabh Kabra,Maks Ovsjanikov,Drew A. Hudson,Ye Xia,Skanda Koppula,Andre Araujo,Joao Carreira,Niloy J. Mitra*

Main category: cs.CV

TL;DR: Omnivorous Vision Encoder通过学习模态无关的特征空间，解决了预训练视觉编码器在不同模态之间特征表示对齐不良的问题，实现了鲁棒的跨模态理解。


<details>
  <summary>Details</summary>
Motivation: 预训练视觉编码器在单模态任务上表现出色，但其特征表示在不同模态之间对齐不良。

Method: 提出了一种名为Omnivorous Vision Encoder的新型框架，该框架学习一个模态无关的特征空间。使用双重目标进行训练：首先，最大化同一场景不同模态之间的特征对齐；其次，蒸馏目标将学习到的表示锚定到DINOv2等完全冻结的教师模型的输出。

Result: 学生编码器能够产生一致、强大的嵌入，无论输入模态（RGB、深度、分割等）如何。这种方法实现了鲁棒的跨模态理解，同时保留了原始基础模型的判别语义。

Conclusion: Omnivorous Vision Encoder通过学习模态无关的特征空间，解决了预训练视觉编码器在不同模态之间特征表示对齐不良的问题，实现了鲁棒的跨模态理解。

Abstract: Pre-trained vision encoders like DINOv2 have demonstrated exceptional performance on unimodal tasks. However, we observe that their feature representations are poorly aligned across different modalities. For instance, the feature embedding for an RGB image and its corresponding depth map of the same scene exhibit a cosine similarity that is nearly identical to that of two random, unrelated images. To address this, we propose the Omnivorous Vision Encoder, a novel framework that learns a modality-agnostic feature space. We train the encoder with a dual objective: first, to maximize the feature alignment between different modalities of the same scene; and second, a distillation objective that anchors the learned representations to the output of a fully frozen teacher such as DINOv2. The resulting student encoder becomes "omnivorous" by producing a consistent, powerful embedding for a given scene, regardless of the input modality (RGB, Depth, Segmentation, etc.). This approach enables robust cross-modal understanding while retaining the discriminative semantics of the original foundation model.

</details>


### [70] [A multimodal slice discovery framework for systematic failure detection and explanation in medical image classification](https://arxiv.org/abs/2602.24183)
*Yixuan Liu,Kanwal K. Bhatia,Ahmed E. Fetit*

Main category: cs.CV

TL;DR: 本研究提出了一种针对医学图像分类器的多模态审计框架，有效提高了故障发现和解释生成的能力。


<details>
  <summary>Details</summary>
Motivation: 尽管基于机器学习的医学图像分类器取得了进展，但其在实际环境中的安全性和可靠性仍然是主要问题。现有的审计方法主要依赖于单模态特征或基于元数据的子组分析，这些方法在可解释性方面有限，并且往往无法捕捉隐藏的系统故障。

Method: 我们引入了第一个自动审计框架，该框架将切片发现方法扩展到多模态表示，专门用于医学应用。

Result: 在MIMIC-CXR-JPG数据集上进行的综合实验表明，该框架在故障发现和解释生成方面都具有强大的能力。结果还表明，多模态信息通常允许对分类器进行更全面和有效的审计，而超越仅图像输入的单模态变体在资源受限的场合具有强大的潜力。

Conclusion: 多模态信息在医学图像分类器的审计中具有重要作用，有助于提高系统的安全性和可靠性。

Abstract: Despite advances in machine learning-based medical image classifiers, the safety and reliability of these systems remain major concerns in practical settings. Existing auditing approaches mainly rely on unimodal features or metadata-based subgroup analyses, which are limited in interpretability and often fail to capture hidden systematic failures. To address these limitations, we introduce the first automated auditing framework that extends slice discovery methods to multimodal representations specifically for medical applications. Comprehensive experiments were conducted under common failure scenarios using the MIMIC-CXR-JPG dataset, demonstrating the framework's strong capability in both failure discovery and explanation generation. Our results also show that multimodal information generally allows more comprehensive and effective auditing of classifiers, while unimodal variants beyond image-only inputs exhibit strong potential in scenarios where resources are constrained.

</details>


### [71] [SenCache: Accelerating Diffusion Model Inference via Sensitivity-Aware Caching](https://arxiv.org/abs/2602.24208)
*Yasaman Haghighi,Alexandre Alahi*

Main category: cs.CV

TL;DR: SenCache通过敏感度感知的缓存策略，提高了扩散模型的推理速度和视觉质量。


<details>
  <summary>Details</summary>
Motivation: 为了解决扩散模型在视频生成中的推理成本问题，研究者们开始探索加速扩散推理的方法。

Method: 提出了一种基于敏感度感知的缓存框架，通过分析模型输出对去噪输入扰动的敏感性来优化缓存策略。

Result: 实验结果表明，SenCache在类似的计算预算下，比现有的缓存方法具有更好的视觉质量。

Conclusion: SenCache通过敏感度感知的缓存策略，有效地提高了扩散模型的推理速度，同时保持了高质量的输出。

Abstract: Diffusion models achieve state-of-the-art video generation quality, but their inference remains expensive due to the large number of sequential denoising steps. This has motivated a growing line of research on accelerating diffusion inference. Among training-free acceleration methods, caching reduces computation by reusing previously computed model outputs across timesteps. Existing caching methods rely on heuristic criteria to choose cache/reuse timesteps and require extensive tuning. We address this limitation with a principled sensitivity-aware caching framework. Specifically, we formalize the caching error through an analysis of the model output sensitivity to perturbations in the denoising inputs, i.e., the noisy latent and the timestep, and show that this sensitivity is a key predictor of caching error. Based on this analysis, we propose Sensitivity-Aware Caching (SenCache), a dynamic caching policy that adaptively selects caching timesteps on a per-sample basis. Our framework provides a theoretical basis for adaptive caching, explains why prior empirical heuristics can be partially effective, and extends them to a dynamic, sample-specific approach. Experiments on Wan 2.1, CogVideoX, and LTX-Video show that SenCache achieves better visual quality than existing caching methods under similar computational budgets.

</details>


### [72] [MuViT: Multi-Resolution Vision Transformers for Learning Across Scales in Microscopy](https://arxiv.org/abs/2602.24222)
*Albert Dominguez Mantes,Gioele La Manno,Martin Weigert*

Main category: cs.CV

TL;DR: MuViT通过融合多分辨率信息，在显微镜分析中实现了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 许多分析任务需要结合多个空间尺度的结构，但大多数视觉模型在单一分辨率下运行或从单一视角提取多尺度特征，限制了它们利用显微镜数据的内在多分辨率性质的能力。

Method: 提出MuViT，这是一种Transformer架构，旨在融合来自同一底层图像的真实多分辨率观察结果。MuViT将所有补丁嵌入到共享的世界坐标系中，并将旋转位置嵌入扩展到这些坐标，使注意力能够在单个编码器中整合广域上下文与高分辨率细节。

Result: 在合成基准、肾脏组织病理学和高分辨率小鼠脑显微镜中，MuViT在ViT和CNN基线之上提供了持续改进。多分辨率MAE预训练进一步产生了尺度一致的表示，增强了下游任务。

Conclusion: 这些结果表明，显式世界坐标建模为利用大规模显微镜分析中的多分辨率信息提供了一种简单而强大的机制。

Abstract: Modern microscopy routinely produces gigapixel images that contain structures across multiple spatial scales, from fine cellular morphology to broader tissue organization. Many analysis tasks require combining these scales, yet most vision models operate at a single resolution or derive multi-scale features from one view, limiting their ability to exploit the inherently multi-resolution nature of microscopy data. We introduce MuViT, a transformer architecture built to fuse true multi-resolution observations from the same underlying image. MuViT embeds all patches into a shared world-coordinate system and extends rotary positional embeddings to these coordinates, enabling attention to integrate wide-field context with high-resolution detail within a single encoder. Across synthetic benchmarks, kidney histopathology, and high-resolution mouse-brain microscopy, MuViT delivers consistent improvements over strong ViT and CNN baselines. Multi-resolution MAE pretraining further produces scale-consistent representations that enhance downstream tasks. These results demonstrate that explicit world-coordinate modelling provides a simple yet powerful mechanism for leveraging multi-resolution information in large-scale microscopy analysis.

</details>


### [73] [Enhancing Spatial Understanding in Image Generation via Reward Modeling](https://arxiv.org/abs/2602.24233)
*Zhenyu Tang,Chaoran Feng,Yufan Deng,Jie Wu,Xiaojie Li,Rui Wang,Yunpeng Chen,Daquan Zhou*

Main category: cs.CV

TL;DR: 提出了一种新的奖励模型，显著提升了文本到图像生成中空间关系的理解。


<details>
  <summary>Details</summary>
Motivation: 近年来文本到图像生成技术取得了很大进展，但同时也对提示的复杂性提出了更高的要求，尤其是在编码复杂空间关系方面。为了解决这一挑战，我们引入了一种新的方法来加强当前图像生成模型的空间理解。

Method: 首先构建了包含超过80k个偏好对的SpatialReward-Dataset，基于此数据集，建立了SpatialScore奖励模型，用于评估文本到图像生成中空间关系的准确性。通过大量实验，证明了该奖励模型在空间理解方面带来了显著且一致的提升。

Result: SpatialScore奖励模型在空间评估方面甚至超过了领先的专有模型，有效促进了复杂空间生成的在线强化学习。

Conclusion: 该研究通过引入新的奖励模型，提高了文本到图像生成中空间关系的理解，为复杂空间生成提供了有效的解决方案。

Abstract: Recent progress in text-to-image generation has greatly advanced visual fidelity and creativity, but it has also imposed higher demands on prompt complexity-particularly in encoding intricate spatial relationships. In such cases, achieving satisfactory results often requires multiple sampling attempts. To address this challenge, we introduce a novel method that strengthens the spatial understanding of current image generation models. We first construct the SpatialReward-Dataset with over 80k preference pairs. Building on this dataset, we build SpatialScore, a reward model designed to evaluate the accuracy of spatial relationships in text-to-image generation, achieving performance that even surpasses leading proprietary models on spatial evaluation. We further demonstrate that this reward model effectively enables online reinforcement learning for the complex spatial generation. Extensive experiments across multiple benchmarks show that our specialized reward model yields significant and consistent gains in spatial understanding for image generation.

</details>


### [74] [Joint Geometric and Trajectory Consistency Learning for One-Step Real-World Super-Resolution](https://arxiv.org/abs/2602.24240)
*Chengyan Deng,Zhangquan Chen,Li Yu,Kai Zhang,Xue Zhou,Wang Zhang*

Main category: cs.CV

TL;DR: GTASR是一种高效的Real-ISR超分辨率方法。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有超分辨率方法的计算成本高和一致性漂移问题。

Method: GTASR（几何轨迹对齐超分辨率）是一种一致性训练范式，包括轨迹对齐策略和双重参考结构校正机制。

Result: GTASR在性能上优于基线模型，同时具有较低的延迟。

Conclusion: GTASR在Real-ISR中实现了优异的性能，同时保持了较低的延迟。

Abstract: Diffusion-based Real-World Image Super-Resolution (Real-ISR) achieves impressive perceptual quality but suffers from high computational costs due to iterative sampling. While recent distillation approaches leveraging large-scale Text-to-Image (T2I) priors have enabled one-step generation, they are typically hindered by prohibitive parameter counts and the inherent capability bounds imposed by teacher models. As a lightweight alternative, Consistency Models offer efficient inference but struggle with two critical limitations: the accumulation of consistency drift inherent to transitive training, and a phenomenon we term "Geometric Decoupling" - where the generative trajectory achieves pixel-wise alignment yet fails to preserve structural coherence. To address these challenges, we propose GTASR (Geometric Trajectory Alignment Super-Resolution), a simple yet effective consistency training paradigm for Real-ISR. Specifically, we introduce a Trajectory Alignment (TA) strategy to rectify the tangent vector field via full-path projection, and a Dual-Reference Structural Rectification (DRSR) mechanism to enforce strict structural constraints. Extensive experiments verify that GTASR delivers superior performance over representative baselines while maintaining minimal latency. The code and model will be released at https://github.com/Blazedengcy/GTASR.

</details>


### [75] [Hierarchical Action Learning for Weakly-Supervised Action Segmentation](https://arxiv.org/abs/2602.24275)
*Junxian Huang,Ruichu Cai,Hao Zhu,Juntao Fang,Boyan Xu,Weilin Chen,Zijian Li,Shenghua Gao*

Main category: cs.CV

TL;DR: HAL模型通过层次推理实现弱监督动作分割，在实验中表现出色。


<details>
  <summary>Details</summary>
Motivation: 人类通过关键过渡感知动作，而机器则倾向于过度分割，这突出了在视频理解中实现层次推理的困难。

Method: 提出了一种名为HAL的层次动作学习模型，该模型引入了层次因果数据生成过程，并使用层次金字塔转换器来捕获视觉特征和潜在变量。

Result: 实验结果表明，HAL模型在弱监督动作分割任务上显著优于现有方法，证明了其实际应用的有效性。

Conclusion: HAL模型能够有效地实现层次动作学习，为弱监督动作分割提供了一种新的解决方案。

Abstract: Humans perceive actions through key transitions that structure actions across multiple abstraction levels, whereas machines, relying on visual features, tend to over-segment. This highlights the difficulty of enabling hierarchical reasoning in video understanding. Interestingly, we observe that lower-level visual and high-level action latent variables evolve at different rates, with low-level visual variables changing rapidly, while high-level action variables evolve more slowly, making them easier to identify. Building on this insight, we propose the Hierarchical Action Learning (\textbf{HAL}) model for weakly-supervised action segmentation. Our approach introduces a hierarchical causal data generation process, where high-level latent action governs the dynamics of low-level visual features. To model these varying timescales effectively, we introduce deterministic processes to align these latent variables over time. The \textbf{HAL} model employs a hierarchical pyramid transformer to capture both visual features and latent variables, and a sparse transition constraint is applied to enforce the slower dynamics of high-level action variables. This mechanism enhances the identification of these latent variables over time. Under mild assumptions, we prove that these latent action variables are strictly identifiable. Experimental results on several benchmarks show that the \textbf{HAL} model significantly outperforms existing methods for weakly-supervised action segmentation, confirming its practical effectiveness in real-world applications.

</details>


### [76] [Mode Seeking meets Mean Seeking for Fast Long Video Generation](https://arxiv.org/abs/2602.24289)
*Shengqu Cai,Weili Nie,Chao Liu,Julius Berner,Lvmin Zhang,Nanye Ma,Hansheng Chen,Maneesh Agrawala,Leonidas Guibas,Gordon Wetzstein,Arash Vahdat*

Main category: cs.CV

TL;DR: 提出了一种基于解耦扩散变换器的新方法，能够有效解决视频生成从秒到分钟的扩展问题，实现快速生成长视频。


<details>
  <summary>Details</summary>
Motivation: 视频生成从秒到分钟的扩展面临瓶颈，因为虽然短视频数据丰富且高保真，但连贯的长视频数据稀缺且限于狭窄领域。

Method: 提出了一种新的训练范式，将模式寻求与平均寻求相结合，通过解耦扩散变换器实现局部保真度与长期一致性的解耦。利用全局Flow Matching头在长视频上进行监督学习以捕获叙事结构，同时采用局部Distribution Matching头通过模式寻求的逆KL散度将滑动窗口与冻结的短视频教师对齐。

Result: 该方法通过联合改善局部清晰度、运动和长距离一致性，有效地缩小了保真度-视域差距。

Conclusion: 提出的方法能够有效解决视频生成从秒到分钟的扩展问题，实现了快速生成长视频。

Abstract: Scaling video generation from seconds to minutes faces a critical bottleneck: while short-video data is abundant and high-fidelity, coherent long-form data is scarce and limited to narrow domains. To address this, we propose a training paradigm where Mode Seeking meets Mean Seeking, decoupling local fidelity from long-term coherence based on a unified representation via a Decoupled Diffusion Transformer. Our approach utilizes a global Flow Matching head trained via supervised learning on long videos to capture narrative structure, while simultaneously employing a local Distribution Matching head that aligns sliding windows to a frozen short-video teacher via a mode-seeking reverse-KL divergence. This strategy enables the synthesis of minute-scale videos that learns long-range coherence and motions from limited long videos via supervised flow matching, while inheriting local realism by aligning every sliding-window segment of the student to a frozen short-video teacher, resulting in a few-step fast long video generator. Evaluations show that our method effectively closes the fidelity-horizon gap by jointly improving local sharpness, motion and long-range consistency. Project website: https://primecai.github.io/mmm/.

</details>


### [77] [UFO-4D: Unposed Feedforward 4D Reconstruction from Two Images](https://arxiv.org/abs/2602.24290)
*Junhwa Hur,Charles Herrmann,Songyou Peng,Philipp Henzler,Zeyu Ma,Todd Zickler,Deqing Sun*

Main category: cs.CV

TL;DR: UFO-4D：一种从未定位图像中重建密集4D表示的统一馈前框架。


<details>
  <summary>Details</summary>
Motivation: 从未定位的图像中重建密集的4D结构仍然是一个关键挑战，现有方法依赖于缓慢的测试时优化或碎片化的、特定于任务的馈前模型。

Method: UFO-4D，一个统一的馈前框架，可以从一对未定位的图像中重建密集的、显式的4D表示。它直接估计动态3D高斯Splat，从而实现3D几何、3D运动和相机姿态的联合和一致估计。

Result: 这种方法能够实现自监督图像合成损失，同时紧密耦合外观、深度和运动。由于所有模态共享相同的几何原语，因此监督一个本质上可以正则化和改进其他模态。这种协同作用克服了数据稀缺性，使得UFO-4D在联合几何、运动和相机姿态估计方面比以往的工作提高了3倍。此外，该表示还允许在新的视图和时间上进行高保真的4D插值。

Conclusion: UFO-4D通过直接估计动态3D高斯Splat，实现了从一对未定位图像到密集4D表示的高效重建，在几何、运动和相机姿态估计方面取得了显著成果。

Abstract: Dense 4D reconstruction from unposed images remains a critical challenge, with current methods relying on slow test-time optimization or fragmented, task-specific feedforward models. We introduce UFO-4D, a unified feedforward framework to reconstruct a dense, explicit 4D representation from just a pair of unposed images. UFO-4D directly estimates dynamic 3D Gaussian Splats, enabling the joint and consistent estimation of 3D geometry, 3D motion, and camera pose in a feedforward manner. Our core insight is that differentiably rendering multiple signals from a single Dynamic 3D Gaussian representation offers major training advantages. This approach enables a self-supervised image synthesis loss while tightly coupling appearance, depth, and motion. Since all modalities share the same geometric primitives, supervising one inherently regularizes and improves the others. This synergy overcomes data scarcity, allowing UFO-4D to outperform prior work by up to 3 times in joint geometry, motion, and camera pose estimation. Our representation also enables high-fidelity 4D interpolation across novel views and time. Please visit our project page for visual results: https://ufo-4d.github.io/

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [78] [Task-Lens: Cross-Task Utility Based Speech Dataset Profiling for Low-Resource Indian Languages](https://arxiv.org/abs/2602.23388)
*Swati Sharma,Divya V. Sharma,Anubha Gupta*

Main category: cs.CL

TL;DR: Task-Lens enhances the use of Indian speech datasets for NLP, addressing data scarcity and promoting inclusivity.


<details>
  <summary>Details</summary>
Motivation: The rising demand for inclusive speech technologies and the need for multilingual datasets for NLP research.

Method: Cross-task profiling of existing Indian speech datasets, proposing Task-Lens, a cross-task survey.

Result: Identified untapped metadata in many Indian speech datasets, enabling broader applicability of existing datasets and prioritizing dataset creation for underserved tasks and languages.

Conclusion: Task-Lens helps alleviate data scarcity in low-resource languages and promotes inclusive speech technologies.

Abstract: The rising demand for inclusive speech technologies amplifies the need for multilingual datasets for Natural Language Processing (NLP) research. However, limited awareness of existing task-specific resources in low-resource languages hinders research. This challenge is especially acute in linguistically diverse countries, such as India. Cross-task profiling of existing Indian speech datasets can alleviate the data scarcity challenge. This involves investigating the utility of datasets across multiple downstream tasks rather than focusing on a single task. Prior surveys typically catalogue datasets for a single task, leaving comprehensive cross-task profiling as an open opportunity. Therefore, we propose Task-Lens, a cross-task survey that assesses the readiness of 50 Indian speech datasets spanning 26 languages for nine downstream speech tasks. First, we analyze which datasets contain metadata and properties suitable for specific tasks. Next, we propose task-aligned enhancements to unlock datasets to their full downstream potential. Finally, we identify tasks and Indian languages that are critically underserved by current resources. Our findings reveal that many Indian speech datasets contain untapped metadata that can support multiple downstream tasks. By uncovering cross-task linkages and gaps, Task-Lens enables researchers to explore the broader applicability of existing datasets and to prioritize dataset creation for underserved tasks and languages.

</details>


### [79] [Truncated Step-Level Sampling with Process Rewards for Retrieval-Augmented Reasoning](https://arxiv.org/abs/2602.23440)
*Chris Samarinas,Haw-Shiuan Chang,Hamed Zamani*

Main category: cs.CL

TL;DR: SLATE improves reinforcement learning for language models by reducing variance and outperforming baselines.


<details>
  <summary>Details</summary>
Motivation: Training large language models to reason with search engines via reinforcement learning faces a credit assignment problem due to sparse outcome rewards.

Method: Proposing SLATE, a framework with truncated step-level sampling and dense LLM-as-judge rewards.

Result: SLATE reduces the variance of advantage estimates and outperforms baselines on QA benchmarks.

Conclusion: SLATE is an effective framework for training language models to reason with search engines.

Abstract: Training large language models to reason with search engines via reinforcement learning is hindered by a fundamental credit assignment problem: existing methods such as Search-R1 provide only a sparse outcome reward after an entire multi-step trajectory, making it infeasible to attribute success or failure to individual reasoning and retrieval decisions. Process-reward methods like StepSearch alleviate this by introducing step-level supervision, but rely on heuristic rewards such as TF-IDF overlap with gold documents, and still sample k complete trajectories per example, retaining high gradient variance. We propose SLATE, a framework built on two complementary ideas: (1) truncated step-level sampling, which generates k trajectories that share a common prefix and differ only at the next step, and (2) dense LLM-as-judge rewards, which replace heuristic scoring with a capable LLM evaluator that assesses the quality of each reasoning step, search query, and answer, providing richer and more reliable supervision. We theoretically prove that under the same dense reward structure, truncated sampling reduces the variance of advantage estimates by up to a factor of T compared to full-trajectory sampling for T-step trajectories, yielding lower-variance, better-targeted policy gradients. Experiments on seven QA benchmarks confirm that SLATE consistently outperforms both sparse-reward and process-reward baselines, with the largest gains on harder multi-hop tasks and smaller models.

</details>


### [80] [CiteAudit: You Cited It, But Did You Read It? A Benchmark for Verifying Scientific References in the LLM Era](https://arxiv.org/abs/2602.23452)
*Zhengqing Yuan,Kaiwen Shi,Zheyuan Zhang,Lichao Sun,Nitesh V. Chawla,Yanfang Ye*

Main category: cs.CL

TL;DR: 本研究提出了第一个用于检测科学写作中幻觉引用的综合基准和检测框架，实验表明该方法优于现有方法，有助于提高科学引用的可信度。


<details>
  <summary>Details</summary>
Motivation: 科学研究中准确引用对于归属和完整性至关重要，但大型语言模型（LLMs）引入了新的风险：虚构的参考文献看似可信，但实际上并不对应任何真实出版物。这种幻觉引用已在主要机器学习会议的提交和已接受的论文中观察到，暴露了同行评审的漏洞。同时，快速增长的参考文献列表使手动验证不切实际，现有的自动化工具对嘈杂和异构的引用格式仍然脆弱，并且缺乏标准化的评估。

Method: 我们提出了第一个用于科学写作中幻觉引用的综合基准和检测框架。我们的多智能体验证管道将引用检查分解为索赔提取、证据检索、段落匹配、推理和校准判断，以评估所引用的来源是否真正支持其主张。我们构建了一个跨领域的大型人类验证数据集，并定义了统一的标准来衡量引用的忠实度和证据的一致性。

Result: 实验表明，我们框架在准确性和可解释性方面都显著优于先前的方法。这项工作为LLM时代提供了第一个可扩展的审计引用的基础设施，并为提高科学引用的可信度提供了实用工具。

Conclusion: 本研究为LLM时代提供了可扩展的引用审计基础设施，并有助于提高科学引用的可信度。

Abstract: Scientific research relies on accurate citation for attribution and integrity, yet large language models (LLMs) introduce a new risk: fabricated references that appear plausible but correspond to no real publications. Such hallucinated citations have already been observed in submissions and accepted papers at major machine learning venues, exposing vulnerabilities in peer review. Meanwhile, rapidly growing reference lists make manual verification impractical, and existing automated tools remain fragile to noisy and heterogeneous citation formats and lack standardized evaluation. We present the first comprehensive benchmark and detection framework for hallucinated citations in scientific writing. Our multi-agent verification pipeline decomposes citation checking into claim extraction, evidence retrieval, passage matching, reasoning, and calibrated judgment to assess whether a cited source truly supports its claim. We construct a large-scale human-validated dataset across domains and define unified metrics for citation faithfulness and evidence alignment. Experiments with state-of-the-art LLMs reveal substantial citation errors and show that our framework significantly outperforms prior methods in both accuracy and interpretability. This work provides the first scalable infrastructure for auditing citations in the LLM era and practical tools to improve the trustworthiness of scientific references.

</details>


### [81] [FHIRPath-QA: Executable Question Answering over FHIR Electronic Health Records](https://arxiv.org/abs/2602.23479)
*Michael Frew,Nishit Bheda,Bryan Tripp*

Main category: cs.CL

TL;DR: 提出了FHIRPath-QA，一种基于FHIRPath的问答范式，以提高EHR中针对患者特定问题的问答的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有电子健康记录（EHR）接口可能无法支持精确、可靠的针对患者特定问题的答案的问题，以及大型语言模型（LLM）在临床问答（QA）中的计算效率低、易产生幻觉、难以在实际EHR中部署等问题。

Method: 提出了一种基于FHIRPath的问答范式，将推理从自由文本生成转移到FHIRPath查询合成，显著减少了LLM的使用。在MIMIC-IV on FHIR Demo上构建了数据集，其中包含超过14k个自然语言问题和经过验证的FHIRPath查询和答案。

Result: 实验结果表明，最先进的LLM在处理患者语言的歧义方面存在困难，在FHIRPath查询合成中的表现也较差。然而，它们从监督微调中受益很大。

Conclusion: 文本到FHIRPath合成有潜力成为安全、高效、互操作的健康应用的实际基础，我们的数据集和基准为该主题的未来研究提供了起点。

Abstract: Though patients are increasingly granted digital access to their electronic health records (EHRs), existing interfaces may not support precise, trustworthy answers to patient-specific questions. Large language models (LLM) show promise in clinical question answering (QA), but retrieval-based approaches are computationally inefficient, prone to hallucination, and difficult to deploy over real-life EHRs. In this work, we introduce FHIRPath-QA, the first open dataset and benchmark for patient-specific QA that includes open-standard FHIRPath queries over real-world clinical data. We propose a text-to-FHIRPath QA paradigm that shifts reasoning from free-text generation to FHIRPath query synthesis, significantly reducing LLM usage. Built on MIMIC-IV on FHIR Demo, the dataset pairs over 14k natural language questions in patient and clinician phrasing with validated FHIRPath queries and answers. Further, we demonstrate that state-of-the-art LLMs struggle to deal with ambiguity in patient language and perform poorly in FHIRPath query synthesis. However, they benefit strongly from supervised fine-tuning. Our results highlight that text-to-FHIRPath synthesis has the potential to serve as a practical foundation for safe, efficient, and interoperable consumer health applications, and our dataset and benchmark serve as a starting point for future research on the topic. The full dataset and generation code is available at: https://github.com/mooshifrew/fhirpath-qa.

</details>


### [82] [Humans and LLMs Diverge on Probabilistic Inferences](https://arxiv.org/abs/2602.23546)
*Gaurav Kamath,Sreenath Madathil,Sebastian Schuster,Marie-Catherine de Marneffe,Siva Reddy*

Main category: cs.CL

TL;DR: 研究人类推理和LLMs在概率推理上的差异，发现LLMs无法产生类似人类的分布，强调了评估推理的必要性。


<details>
  <summary>Details</summary>
Motivation: 探索人类推理在有限信息下的概率结论，以及推理LLMs在此类开放性、非确定性推理上的表现。

Method: 构建了一个包含210个手工制作的概率推理数据集，并让25-30名人类参与者对推理的可能性进行标注。

Result: 人类回答具有分级和多样性，揭示了数据集中推理的概率判断。与八种最先进的推理LLMs的响应进行比较，发现模型无法产生类似人类的分布。

Conclusion: 人类和LLMs在推理方面存在持续差异，强调了在确定性设置之外评估推理的必要性。

Abstract: Human reasoning often involves working over limited information to arrive at probabilistic conclusions. In its simplest form, this involves making an inference that is not strictly entailed by a premise, but rather only likely given the premise. While reasoning LLMs have demonstrated strong performance on logical and mathematical tasks, their behavior on such open-ended, non-deterministic inferences remains largely unexplored. We introduce ProbCOPA, a dataset of 210 handcrafted probabilistic inferences in English, each annotated for inference likelihood by 25--30 human participants. We find that human responses are graded and varied, revealing probabilistic judgments of the inferences in our dataset. Comparing these judgments with responses from eight state-of-the-art reasoning LLMs, we show that models consistently fail to produce human-like distributions. Finally, analyzing LLM reasoning chains, we find evidence of a common reasoning pattern used to evaluate such inferences. Our findings reveal persistent differences between humans and LLMs, and underscore the need to evaluate reasoning beyond deterministic settings.

</details>


### [83] [Multi-Agent Causal Reasoning for Suicide Ideation Detection Through Online Conversations](https://arxiv.org/abs/2602.23577)
*Jun Li,Xiangmeng Wang,Haoyang Li,Yifei Yan,Shijie Zhang,Hong Va Leong,Ling Feng,Nancy Xiaonan Yu,Qing Li*

Main category: cs.CL

TL;DR: MACR is an effective framework for identifying suicide risk in social media.


<details>
  <summary>Details</summary>
Motivation: Existing approaches for early risk detection on social media platforms have limitations.

Method: Proposing a Multi-Agent Causal Reasoning (MACR) framework.

Result: MACR effectively identifies suicide risk.

Conclusion: MACR alleviates hidden biases and enriches contextual information of user interactions.

Abstract: Suicide remains a pressing global public health concern. While social media platforms offer opportunities for early risk detection through online conversation trees, existing approaches face two major limitations: (1) They rely on predefined rules (e.g., quotes or relies) to log conversations that capture only a narrow spectrum of user interactions, and (2) They overlook hidden influences such as user conformity and suicide copycat behavior, which can significantly affect suicidal expression and propagation in online communities. To address these limitations, we propose a Multi-Agent Causal Reasoning (MACR) framework that collaboratively employs a Reasoning Agent to scale user interactions and a Bias-aware Decision-Making Agent to mitigate harmful biases arising from hidden influences. The Reasoning Agent integrates cognitive appraisal theory to generate counterfactual user reactions to posts, thereby scaling user interactions. It analyses these reactions through structured dimensions, i.e., cognitive, emotional, and behavioral patterns, with a dedicated sub-agent responsible for each dimension. The Bias-aware Decision-Making Agent mitigates hidden biases through a front-door adjustment strategy, leveraging the counterfactual user reactions produced by the Reasoning Agent. Through the collaboration of reasoning and bias-aware decision making, the proposed MACR framework not only alleviates hidden biases, but also enriches contextual information of user interactions with counterfactual knowledge. Extensive experiments on real-world conversational datasets demonstrate the effectiveness and robustness of MACR in identifying suicide risk.

</details>


### [84] [BRIDGE the Gap: Mitigating Bias Amplification in Automated Scoring of English Language Learners via Inter-group Data Augmentation](https://arxiv.org/abs/2602.23580)
*Yun Wang,Xuansheng Wu,Jingyuan Huang,Lei Liu,Xiaoming Zhai,Ninghao Liu*

Main category: cs.CL

TL;DR: 提出BRIDGE框架，以减轻教育评估自动化评分系统中的偏差放大问题，通过合成高质量的英语学习者样本来提高公平性。


<details>
  <summary>Details</summary>
Motivation: 为了减轻教育评估中自动化评分系统存在的偏差放大风险，特别是对于英语学习者（ELLs）等代表性不足的群体。

Method: 提出了一种名为BRIDGE的偏差降低跨组数据生成框架，该框架通过将大量非英语学习者的高质量内容“粘贴”到真实的英语学习者的语言模式中来生成高质量的英语学习者样本。

Result: 实验表明，BRIDGE在减少对高分英语学习者的预测偏差的同时，保持了整体评分性能。

Conclusion: BRIDGE是一种有效减轻教育评估中自动化评分系统偏差放大的方法，为大规模评估中的公平评分提供了成本效益高的解决方案。

Abstract: In the field of educational assessment, automated scoring systems increasingly rely on deep learning and large language models (LLMs). However, these systems face significant risks of bias amplification, where model prediction gaps between student groups become larger than those observed in training data. This issue is especially severe for underrepresented groups such as English Language Learners (ELLs), as models may inherit and further magnify existing disparities in the data. We identify that this issue is closely tied to representation bias: the scarcity of minority (high-scoring ELL) samples makes models trained with empirical risk minimization favor majority (non-ELL) linguistic patterns. Consequently, models tend to under-predict ELL students who even demonstrate comparable domain knowledge but use different linguistic patterns, thereby undermining the fairness of automated scoring outcomes. To mitigate this, we propose BRIDGE, a Bias-Reducing Inter-group Data GEneration framework designed for low-resource assessment settings. Instead of relying on the limited minority samples, BRIDGE synthesizes high-scoring ELL samples by "pasting" construct-relevant (i.e., rubric-aligned knowledge and evidence) content from abundant high-scoring non-ELL samples into authentic ELL linguistic patterns. We further introduce a discriminator model to ensure the quality of synthetic samples. Experiments on California Science Test (CAST) datasets demonstrate that BRIDGE effectively reduces prediction bias for high-scoring ELL students while maintaining overall scoring performance. Notably, our method achieves fairness gains comparable to using additional real human data, offering a cost-effective solution for ensuring equitable scoring in large-scale assessments.

</details>


### [85] [LFQA-HP-1M: A Large-Scale Human Preference Dataset for Long-Form Question Answering](https://arxiv.org/abs/2602.23603)
*Rafid Ishrak Jahan,Fahmid Shahriar Iqbal,Sagnik Ray Choudhury*

Main category: cs.CL

TL;DR: 提出大型LFQA数据集和评估框架，用于更准确地评估长文本问答。


<details>
  <summary>Details</summary>
Motivation: 长文本问答（LFQA）需要评估多句解释性回答的细微差别，但现有指标往往无法反映人类判断。

Method: 提出LFQA-HP-1M，一个包含130万人类成对偏好标注的大规模数据集，并制定九个评价标准。

Result: 简单线性模型在这些特征的基础上表现与最先进的LLM评估器相当。

Conclusion: 该研究提供了一项大型公共LFQA偏好数据集和基于评价标准的透明可靠评估框架。

Abstract: Long-form question answering (LFQA) demands nuanced evaluation of multi-sentence explanatory responses, yet existing metrics often fail to reflect human judgment. We present LFQA-HP-1M, a large-scale dataset comprising 1.3M human pairwise preference annotations for LFQA. We propose nine rubrics for answer quality evaluation, and show that simple linear models based on these features perform comparably to state-of-the-art LLM evaluators. We further examine transitivity consistency, positional bias, and verbosity biases in LLM evaluators and demonstrate their vulnerability to adversarial perturbations. Overall, this work provides one of the largest public LFQA preference datasets and a rubric-driven framework for transparent and reliable evaluation.

</details>


### [86] [LLM-Driven Multi-Turn Task-Oriented Dialogue Synthesis for Realistic Reasoning](https://arxiv.org/abs/2602.23610)
*Yu Zhu,Kai Yang*

Main category: cs.CL

TL;DR: 提出了一种基于LLM的框架，以解决现有推理基准测试的不足，并通过实验证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试无法充分反映真实场景的复杂性，限制了其在评估和提升大型语言模型（LLMs）推理能力方面的有效性。

Method: 提出一个LLM驱动的框架，通过三层次优化增强对话质量，生成基于真实推理场景的多轮、任务导向对话。

Result: 实验结果表明，基于合成数据的推理任务引入了非平凡的推理挑战，并为提高LLMs的推理能力提供了有意义的支持。

Conclusion: 该框架为评估和提升LLMs的现实逻辑推理能力提供了有价值的基准数据集。

Abstract: The reasoning capability of large language models (LLMs), defined as their ability to analyze, infer, and make decisions based on input information, is essential for building intelligent task-oriented dialogue systems. However, existing benchmarks do not sufficiently reflect the complexity of real-world scenarios, which limits their effectiveness in evaluating and enhancing LLM reasoning in practical contexts. Many current reasoning datasets are overly simplistic and abstract, often disconnected from realistic task flows, domain constraints, and operational rules, making it difficult to effectively evaluate LLMs' logical reasoning ability. In addition, data contamination from pretraining corpora undermines the reliability of evaluation results, and traditional crowdsourcing methods for dataset construction are labor-intensive and difficult to scale. To address these challenges, we propose a LLM-driven framework for synthesizing multi-turn, task-oriented dialogues grounded in realistic reasoning scenarios, leveraging trilevel optimization to enhance dialogue quality. Our method generates dialogues grounded in authentic task scenarios, enriched with real-world information, and exhibiting strong contextual coherence. Corresponding reasoning tasks are carefully designed around these dialogues and iteratively refined to continuously improve the tasks' quality and challenge. The resulting dataset serves as a valuable benchmark for assessing and advancing the realistic logical reasoning capabilities of LLMs. Experimental results show that our synthetic data-based reasoning tasks introduce non-trivial reasoning challenges and provide meaningful support for improving the reasoning capabilities of LLMs.

</details>


### [87] [TRIZ-RAGNER: A Retrieval-Augmented Large Language Model for TRIZ-Aware Named Entity Recognition in Patent-Based Contradiction Mining](https://arxiv.org/abs/2602.23656)
*Zitong Xu,Yuqing Wu,Yue Zhao*

Main category: cs.CL

TL;DR: TRIZ-RAGNER在专利矛盾挖掘中表现出色，提高了提取的准确性和一致性。


<details>
  <summary>Details</summary>
Motivation: 专利分析和系统创新中的TRIZ-based矛盾挖掘是一个基本任务，因为它能够识别推动创新问题解决的技术参数的改进和恶化。然而，现有方法在很大程度上依赖于基于规则的系统或传统的机器学习模型，这些方法在处理复杂的专利语言时难以应对语义歧义、领域依赖和有限的泛化能力。最近，大型语言模型（LLMs）在语义理解能力方面表现出色，但它们在直接应用于TRIZ参数提取时仍存在挑战，因为它们存在幻觉和缺乏对结构化TRIZ知识的充分理解。

Method: 提出TRIZ-RAGNER，一个检索增强的大型语言模型框架，用于基于专利的TRIZ意识命名实体识别。将矛盾挖掘重新定义为语义级别的命名实体识别任务，并集成密集检索、交叉编码重排序和结构化LLM提示，以从专利句子中提取改进和恶化的参数。通过将领域特定的TRIZ知识注入LLM推理过程，该框架有效地减少了语义噪声并提高了提取一致性。

Result: 在PaTRIZ数据集上的实验表明，TRIZ-RAGNER在TRIZ矛盾对识别方面始终优于传统的序列标注模型和基于LLM的基线。该框架在TRIZ矛盾对识别中实现了85.6%的精确率、82.9%的召回率和84.2%的F1分数。与使用提示增强的GPT的最强基线相比，TRIZ-RAGNER的F1分数提高了7.3个百分点，证实了检索增强的TRIZ知识定位对于稳健和准确的基于专利的矛盾挖掘的有效性。

Conclusion: TRIZ-RAGNER在专利矛盾挖掘中表现出色，提高了提取的准确性和一致性。

Abstract: TRIZ-based contradiction mining is a fundamental task in patent analysis and systematic innovation, as it enables the identification of improving and worsening technical parameters that drive inventive problem solving. However, existing approaches largely rely on rule-based systems or traditional machine learning models, which struggle with semantic ambiguity, domain dependency, and limited generalization when processing complex patent language. Recently, large language models (LLMs) have shown strong semantic understanding capabilities, yet their direct application to TRIZ parameter extraction remains challenging due to hallucination and insufficient grounding in structured TRIZ knowledge. To address these limitations, this paper proposes TRIZ-RAGNER, a retrieval-augmented large language model framework for TRIZ-aware named entity recognition in patent-based contradiction mining. TRIZ-RAGNER reformulates contradiction mining as a semantic-level NER task and integrates dense retrieval over a TRIZ knowledge base, cross-encoder reranking for context refinement, and structured LLM prompting to extract improving and worsening parameters from patent sentences. By injecting domain-specific TRIZ knowledge into the LLM reasoning process, the proposed framework effectively reduces semantic noise and improves extraction consistency. Experiments on the PaTRIZ dataset demonstrate that TRIZ-RAGNER consistently outperforms traditional sequence labeling models and LLM-based baselines. The proposed framework achieves a precision of 85.6%, a recall of 82.9%, and an F1-score of 84.2% in TRIZ contradiction pair identification. Compared with the strongest baseline using prompt-enhanced GPT, TRIZ-RAGNER yields an absolute F1-score improvement of 7.3 percentage points, confirming the effectiveness of retrieval-augmented TRIZ knowledge grounding for robust and accurate patent-based contradiction mining.

</details>


### [88] [Structured Prompt Optimization for Few-Shot Text Classification via Semantic Alignment in Latent Space](https://arxiv.org/abs/2602.23753)
*Jiasen Zheng,Zijun Zhou,Huajun Zhang,Junjiang Lin,Jingyun Jia,Qi Wang*

Main category: cs.CL

TL;DR: 该方法通过结构化提示优化框架提高少样本文本分类性能


<details>
  <summary>Details</summary>
Motivation: 解决语义纠缠、标签结构不明确和特征表示不足等问题

Method: 基于结构化提示的优化框架，使用预训练语言模型进行编码和语义表示，结合结构化提示和文本特征，构建结构化标签嵌入矩阵和跨空间对齐机制，应用提示正交约束和联合优化目标

Result: 显著提高分类准确率、精确率、召回率和AUC，具有良好的跨任务适用性

Conclusion: 提出的方法在少样本文本分类中有效缓解了语义冲突和标签模糊性问题，具有良好的性能和稳定性

Abstract: This study addresses the issues of semantic entanglement, unclear label structure, and insufficient feature representation in few-shot text classification, and proposes an optimization framework based on structured prompts to enhance semantic understanding and task adaptation under low-resource conditions. The framework first uses a pretrained language model to encode the input text and obtain basic semantic representations. It then introduces structured prompts composed of multi-dimensional semantic factors and integrates them with text features through a learnable combination mechanism, which forms task-related representations with clear boundaries in the latent space. To further strengthen the consistency between text representations and label semantics, the method constructs a structured label embedding matrix and employs a cross-space alignment mechanism to ensure stable matching between textual features and label attributes. In addition, the model applies prompt orthogonality constraints and a joint optimization objective to maintain independence across different semantic factors in the prompts, allowing the structured prompts to provide transparent and controllable guidance for classification decisions. Three types of sensitivity experiments, including learning rate sensitivity, prompt length sensitivity, and data scale sensitivity, are designed to evaluate the stability and robustness of the framework under different conditions. Experimental results show that the proposed structured prompt optimization framework effectively alleviates semantic conflicts and label ambiguity in few-shot text classification. It significantly improves performance on accuracy, precision, recall, and AUC, and demonstrates strong cross-task applicability.

</details>


### [89] [Divide and Conquer: Accelerating Diffusion-Based Large Language Models via Adaptive Parallel Decoding](https://arxiv.org/abs/2602.23792)
*Xiangzhong Luo,Yilin An,Zhicheng Yu,Weichen Liu,Xu Yang*

Main category: cs.CL

TL;DR: DiCo：一种自适应并行解码方法，显著提高dLLMs的推理速度和生成质量。


<details>
  <summary>Details</summary>
Motivation: 为了解决扩散型大型语言模型（dLLMs）在并行解码方面的实际性能与理论性能之间的差距问题。

Method: 提出了一种名为DiCo的自适应并行解码方法，采用三阶段划分-征服范式来释放dLLMs的内在并行性。

Result: 实验表明，DiCo可以在保持具有竞争力的生成质量的同时实现显著的推理加速。

Conclusion: DiCo是一种有效的自适应并行解码方法，可以显著提高dLLMs的推理速度并保持高质量的生成。

Abstract: Diffusion-based large language models (dLLMs) have shown promising performance across various reasoning tasks, establishing themselves as an alternative to autoregressive large language models (LLMs). Unlike autoregressive LLMs that generate one token per step based on all previous tokens, dLLMs theoretically enable parallel generation of multiple tokens at each decoding step. However, recent dLLMs still favor one-token-per-step generation in practice, as directly decoding multiple masked tokens often leads to degraded generation quality and stability. This reveals a substantial gap between the theoretical parallelism and practical performance of dLLMs. To bridge this gap, we introduce an adaptive parallel decoding approach, namely DiCo, which features a three-phase divide-and-conquer paradigm to unleash the inherent parallelism of dLLMs. During the Divide phase, DiCo first explores the input masked sequence and identifies masked tokens as seed tokens, which are then expanded to construct a set of local clusters. During the Conquer phase, DiCo performs parallel decoding across different local clusters constructed in the Divide phase. The divide-and-conquer process repeatedly alternates between the Divide and Conquer phases until convergence. During the Finalize phase, DiCo decodes the remaining few masked tokens using an effective fine-grained compound decoding scheme to finalize the generation. Extensive experiments demonstrate that DiCo can achieve significant inference speedups while maintaining competitive generation quality.

</details>


### [90] [GLUScope: A Tool for Analyzing GLU Neurons in Transformer Language Models](https://arxiv.org/abs/2602.23826)
*Sebastian Gerstner,Hinrich Schütze*

Main category: cs.CL

TL;DR: GLUScope是一个开源工具，用于分析Transformer-based语言模型中的神经元，提高了模型的可解释性。


<details>
  <summary>Details</summary>
Motivation: 为了提高Transformer-based语言模型的可解释性，研究人员需要一个工具来分析其中的神经元。

Method: 开发了GLUScope，一个开源工具，用于分析Transformer-based语言模型中的神经元。该工具考虑了门控激活函数，如SwiGLU。

Result: GLUScope工具能够显示每个神经元的四种不同符号组合的文本示例，并指出每种组合出现的频率。它有助于发现新的见解。

Conclusion: GLUScope工具有助于提高Transformer-based语言模型的可解释性，为研究人员提供了一种新的分析神经元的方法。

Abstract: We present GLUScope, an open-source tool for analyzing neurons in Transformer-based language models, intended for interpretability researchers. We focus on more recent models than previous tools do; specifically we consider gated activation functions such as SwiGLU. This introduces a new challenge: understanding positive activations is not enough. Instead, both the gate and the in activation of a neuron can be positive or negative, leading to four different possible sign combinations that in some cases have quite different functionalities. Accordingly, for any neuron, our tool shows text examples for each of the four sign combinations, and indicates how often each combination occurs. We describe examples of how our tool can lead to novel insights. A demo is available at https: //sjgerstner.github.io/gluscope.

</details>


### [91] [The Astonishing Ability of Large Language Models to Parse Jabberwockified Language](https://arxiv.org/abs/2602.23928)
*Gary Lupyan,Senyi Yang*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We show that large language models (LLMs) have an astonishing ability to recover meaning from severely degraded English texts. Texts in which content words have been randomly substituted by nonsense strings, e.g., "At the ghybe of the swuint, we are haiveed to Wourge Phrear-gwurr, who sproles into an ghitch flount with his crurp", can be translated to conventional English that is, in many cases, close to the original text, e.g., "At the start of the story, we meet a man, Chow, who moves into an apartment building with his wife." These results show that structural cues (e.g., morphosyntax, closed-class words) constrain lexical meaning to a much larger degree than imagined. Although the abilities of LLMs to make sense of "Jabberwockified" English are clearly superhuman, they are highly relevant to understanding linguistic structure and suggest that efficient language processing either in biological or artificial systems likely benefits from very tight integration between syntax, lexical semantics, and general world knowledge.

</details>


### [92] [Benchmarking BERT-based Models for Sentence-level Topic Classification in Nepali Language](https://arxiv.org/abs/2602.23940)
*Nischal Karki,Bipesh Subedi,Prakash Poudyal,Rupak Raj Ghimire,Bal Krishna Bal*

Main category: cs.CL

TL;DR: Evaluates BERT variants for Nepali topic classification, with Indic models and NepBERTa showing strong performance.


<details>
  <summary>Details</summary>
Motivation: Nepali, a low-resource language, has been relatively underexplored in NLP.

Method: Benchmarking multilingual, Indic, Hindi, and Nepali BERT variants.

Result: Indic models, particularly MuRIL-large, achieved the highest F1-score of 90.60%. NepBERTa also performed competitively with an F1-score of 88.26%.

Conclusion: Establishes a robust baseline for future document-level classification and broader Nepali NLP applications.

Abstract: Transformer-based models such as BERT have significantly advanced Natural Language Processing (NLP) across many languages. However, Nepali, a low-resource language written in Devanagari script, remains relatively underexplored. This study benchmarks multilingual, Indic, Hindi, and Nepali BERT variants to evaluate their effectiveness in Nepali topic classification. Ten pre-trained models, including mBERT, XLM-R, MuRIL, DevBERT, HindiBERT, IndicBERT, and NepBERTa, were fine-tuned and tested on the balanced Nepali dataset containing 25,006 sentences across five conceptual domains and the performance was evaluated using accuracy, weighted precision, recall, F1-score, and AUROC metrics. The results reveal that Indic models, particularly MuRIL-large, achieved the highest F1-score of 90.60%, outperforming multilingual and monolingual models. NepBERTa also performed competitively with an F1-score of 88.26%. Overall, these findings establish a robust baseline for future document-level classification and broader Nepali NLP applications.

</details>


### [93] [EDDA-Coordinata: An Annotated Dataset of Historical Geographic Coordinates](https://arxiv.org/abs/2602.23941)
*Ludovic Moncla,Pierre Nugues,Thierry Joliveau,Katherine McDonough*

Main category: cs.CL

TL;DR: 本文提出了一种从历史文本中自动恢复地理坐标的方法，并在多个数据集上进行了验证。


<details>
  <summary>Details</summary>
Motivation: 自动从历史文本中恢复地理坐标是一项复杂的任务，因为它们以各种方式表达，精度各异。

Method: 创建金标准数据集，训练模型，发布推断和归一化的坐标数据，对新文本进行实验。

Result: 在ARTFL和ENCCRE数字化版本的Encyclopedie中，对15,278个地理条目进行了检查，其中4,798个包含坐标，10,480个具有描述性但非数值参考。

Conclusion: 本文提出的金标准数据集在训练数据方面具有实用性，我们的两步方法具有跨语言、跨领域的泛化能力。

Abstract: This paper introduces a dataset of enriched geographic coordinates retrieved from Diderot and d'Alembert's eighteenth-century Encyclopedie. Automatically recovering geographic coordinates from historical texts is a complex task, as they are expressed in a variety of ways and with varying levels of precision. To improve retrieval of coordinates from similar digitized early modern texts, we have created a gold standard dataset, trained models, published the resulting inferred and normalized coordinate data, and experimented applying these models to new texts. From 74,000 total articles in each of the digitized versions of the Encyclopedie from ARTFL and ENCCRE, we examined 15,278 geographical entries, manually identifying 4,798 containing coordinates, and 10,480 with descriptive but non-numerical references. Leveraging our gold standard annotations, we trained transformer-based models to retrieve and normalize coordinates. The pipeline presented here combines a classifier to identify coordinate-bearing entries and a second model for retrieval, tested across encoder-decoder and decoder architectures. Cross-validation yielded an 86% EM score. On an out-of-domain eighteenth-century Trevoux dictionary (also in French), our fine-tuned model had a 61% EM score, while for the nineteenth-century, 7th edition of the Encyclopaedia Britannica in English, the EM was 77%. These findings highlight the gold standard dataset's usefulness as training data, and our two-step method's cross-lingual, cross-domain generalizability.

</details>


### [94] [MemEmo: Evaluating Emotion in Memory Systems of Agents](https://arxiv.org/abs/2602.23944)
*Peng Liu,Zhen Tao,Jihao Zhao,Ding Chen,Yansong Zhang,Cuiping Li,Zhiyu Li,Hong Chen*

Main category: cs.CL

TL;DR: Proposed a benchmark for evaluating memory systems in handling emotional information; found deficiencies and suggested future research.


<details>
  <summary>Details</summary>
Motivation: Memory systems face the challenge of context loss in Large Language Model during prolonged interactions.

Method: Proposed an emotion-enhanced memory evaluation benchmark and developed the HLME dataset.

Result: None of the evaluated systems achieve robust performance across all three tasks.

Conclusion: Findings provide an objective perspective on the current deficiencies of memory systems in processing emotional memories and suggest a new trajectory for future research and system optimization.

Abstract: Memory systems address the challenge of context loss in Large Language Model during prolonged interactions. However, compared to human cognition, the efficacy of these systems in processing emotion-related information remains inconclusive. To address this gap, we propose an emotion-enhanced memory evaluation benchmark to assess the performance of mainstream and state-of-the-art memory systems in handling affective information. We developed the \textbf{H}uman-\textbf{L}ike \textbf{M}emory \textbf{E}motion (\textbf{HLME}) dataset, which evaluates memory systems across three dimensions: emotional information extraction, emotional memory updating, and emotional memory question answering. Experimental results indicate that none of the evaluated systems achieve robust performance across all three tasks. Our findings provide an objective perspective on the current deficiencies of memory systems in processing emotional memories and suggest a new trajectory for future research and system optimization.

</details>


### [95] [The GRADIEND Python Package: An End-to-End System for Gradient-Based Feature Learning](https://arxiv.org/abs/2602.23993)
*Jonathan Drechsel,Steffen Herbold*

Main category: cs.CL

TL;DR: GRADIEND是一个开源Python包，用于从语言模型中学习特征方向，支持全面工作流程和特征比较


<details>
  <summary>Details</summary>
Motivation: 学习语言模型中的特征方向

Method: GRADIEND方法

Result: 开源Python包gradiend，提供统一工作流程，支持特征相关数据创建、训练、评估、可视化、模型重写和特征比较

Conclusion: GRADIEND在英语代词范式和大规模特征比较中表现良好

Abstract: We present gradiend, an open-source Python package that operationalizes the GRADIEND method for learning feature directions from factual-counterfactual MLM and CLM gradients in language models. The package provides a unified workflow for feature-related data creation, training, evaluation, visualization, persistent model rewriting via controlled weight updates, and multi-feature comparison. We demonstrate GRADIEND on an English pronoun paradigm and on a large-scale feature comparison that reproduces prior use cases.

</details>


### [96] [Dialect and Gender Bias in YouTube's Spanish Captioning System](https://arxiv.org/abs/2602.24002)
*Iris Dania Jimenez,Christoph Kern*

Main category: cs.CL

TL;DR: 研究指出YouTube的西班牙语字幕系统可能存在偏见，需要针对不同方言进行校准。


<details>
  <summary>Details</summary>
Motivation: YouTube仅提供一种自动生成西班牙语字幕的选项，引发了对该字幕系统是否对某些西班牙方言存在偏见的问题。

Method: 通过分析YouTube自动字幕系统在不同西班牙方言上的表现，研究了潜在的偏见。通过比较不同地区女性和男性说话者的字幕质量，确定了可归因于特定方言的系统差异。

Result: 研究提供了进一步证据，表明数字平台上的算法技术需要针对用户群体的多样性和需求进行调整。

Conclusion: YouTube的自动字幕系统可能存在针对某些西班牙方言的偏见，这表明算法技术在数字平台上的部署需要考虑到用户群体的多样性。

Abstract: Spanish is the official language of twenty-one countries and is spoken by over 441 million people. Naturally, there are many variations in how Spanish is spoken across these countries. Media platforms such as YouTube rely on automatic speech recognition systems to make their content accessible to different groups of users. However, YouTube offers only one option for automatically generating captions in Spanish. This raises the question: could this captioning system be biased against certain Spanish dialects? This study examines the potential biases in YouTube's automatic captioning system by analyzing its performance across various Spanish dialects. By comparing the quality of captions for female and male speakers from different regions, we identify systematic disparities which can be attributed to specific dialects. Our study provides further evidence that algorithmic technologies deployed on digital platforms need to be calibrated to the diverse needs and experiences of their user populations.

</details>


### [97] [Task Complexity Matters: An Empirical Study of Reasoning in LLMs for Sentiment Analysis](https://arxiv.org/abs/2602.24060)
*Donghao Huang,Zhaoxia Wang*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Large language models (LLMs) with reasoning capabilities have fueled a compelling narrative that reasoning universally improves performance across language tasks. We test this claim through a comprehensive evaluation of 504 configurations across seven model families--including adaptive, conditional, and reinforcement learning-based reasoning architectures--on sentiment analysis datasets of varying granularity (binary, five-class, and 27-class emotion). Our findings reveal that reasoning effectiveness is strongly task-dependent, challenging prevailing assumptions: (1) Reasoning shows task-complexity dependence--binary classification degrades up to -19.9 F1 percentage points (pp), while 27-class emotion recognition gains up to +16.0pp; (2) Distilled reasoning variants underperform base models by 3-18 pp on simpler tasks, though few-shot prompting enables partial recovery; (3) Few-shot learning improves over zero-shot in most cases regardless of model type, with gains varying by architecture and task complexity; (4) Pareto frontier analysis shows base models dominate efficiency-performance trade-offs, with reasoning justified only for complex emotion recognition despite 2.1x-54x computational overhead. We complement these quantitative findings with qualitative error analysis revealing that reasoning degrades simpler tasks through systematic over-deliberation, offering mechanistic insight beyond the high-level overthinking hypothesis.

</details>


### [98] [Preference Packing: Efficient Preference Optimization for Large Language Models](https://arxiv.org/abs/2602.24082)
*Jaekyung Cho*

Main category: cs.CL

TL;DR: 提出偏好打包方法，提高资源效率，实现至少37%的训练时间减少，与现有技术结合使用可加速3.22倍。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）规模的不断扩大，资源高效的训练优化技术变得越来越重要。

Method: 提出了一种名为偏好打包的方法，用于提高使用具有不同响应的数据（如奖励模型或直接偏好优化（DPO））进行训练的技术中的资源效率。

Result: 在文本数据集和包含图像的数据集上进行了实验，实现了至少37%的训练时间减少。

Conclusion: 该方法可以与现有的优化技术（如批量排序）结合使用，从而实现3.22倍的加速。

Abstract: Resource-efficient training optimization techniques are becoming increasingly important as the size of large language models (LLMs) continues to grow. In particular, batch packing is commonly used in pre-training and supervised fine-tuning to achieve resource-efficient training. We propose preference packing, a method to enhance resource efficiency in training techniques that use data with different responses for the same input prompt, such as reward models or Direct Preference Optimization (DPO). Preference packing improves resource efficiency by reducing the attention operations for duplicate input prompts and decreasing KV cache memory usage. We conducted experiments on text-only datasets and image-included datasets and achieved at least 37% reduction in training time. Notably, this method can be applied alongside existing optimization techniques such as batch sorting, resulting in a 3.22x speedup.

</details>


### [99] [ARGUS: Seeing the Influence of Narrative Features on Persuasion in Argumentative Texts](https://arxiv.org/abs/2602.24109)
*Sara Nabhani,Federico Pianzola,Khalid Al-Khatib,Malvina Nissim*

Main category: cs.CL

TL;DR: ARGUS框架通过识别故事和叙事特征，有效地研究了叙事对在线论证说服的影响。


<details>
  <summary>Details</summary>
Motivation: 虽然故事通常被视为说服的有力工具，但它们在在线非结构化论证中的具体作用仍不明确。

Method: 我们提出了ARGUS框架，这是一个用于研究叙述对论证性话语中说服影响的研究框架。该框架引入了一个新的ChangeMyView语料库，该语料库针对故事存在和六个关键叙事特征进行了注释，并整合了两个已建立的理论框架的见解，这两个框架捕捉了文本叙事特征及其对接受者的影响。利用基于编码器的分类器和零样本大型语言模型（LLMs），ARGUS识别故事和叙事特征，并大规模应用它们来检验不同的叙事维度如何影响在线论证中的说服成功。

Result: ARGUS框架可以识别故事和叙事特征，并大规模应用它们来检验不同的叙事维度如何影响在线论证中的说服成功。

Conclusion: 叙事在在线非结构化论证中起着重要作用，ARGUS框架可以有效地识别和利用这些特征。

Abstract: Can narratives make arguments more persuasive? And to this end, which narrative features matter most? Although stories are often seen as powerful tools for persuasion, their specific role in online, unstructured argumentation remains underexplored. To address this gap, we present ARGUS, a framework for studying the impact of narration on persuasion in argumentative discourse. ARGUS introduces a new ChangeMyView corpus annotated for story presence and six key narrative features, integrating insights from two established theoretical frameworks that capture both textual narrative features and their effects on recipients. Leveraging both encoder-based classifiers and zero-shot large language models (LLMs), ARGUS identifies stories and narrative features and applies them at scale to examine how different narrative dimensions influence persuasion success in online argumentation.

</details>


### [100] [Terminology Rarity Predicts Catastrophic Failure in LLM Translation of Low-Resource Ancient Languages: Evidence from Ancient Greek](https://arxiv.org/abs/2602.24119)
*James L. Zainaldin,Cameron Pattison,Manuela Marai,Jacob Wu,Mark J. Schiefsky*

Main category: cs.CL

TL;DR: 本研究评估了LLM在古希腊技术散文机器翻译中的表现，发现其在某些方面接近专家水平，但存在术语翻译挑战，对古典学术研究和低资源古老语言的自动化评估有重要意义


<details>
  <summary>Details</summary>
Motivation: 对古希腊技术散文进行机器翻译的系统性、无参考的人评研究

Method: 评估了三个商业LLM（Claude，Gemini，ChatGPT）对20段古希腊医家加伦的两篇作品的翻译，包括使用标准自动化评估指标和专家人工评估

Result: LLM在已翻译的说明性文本上取得了高翻译质量，但在未翻译的药理学文本上质量较低，术语的稀有度是翻译失败的关键预测因素

Conclusion: LLM在古典学术研究和低资源古老语言的自动化评估管道设计中具有潜在应用价值

Abstract: This study presents the first systematic, reference-free human evaluation of large language model (LLM) machine translation (MT) for Ancient Greek (AG) technical prose. We evaluate translations by three commercial LLMs (Claude, Gemini, ChatGPT) of twenty paragraph-length passages from two works by the Greek physician Galen of Pergamum (ca. 129-216 CE): On Mixtures, which has two published English translations, and On the Composition of Drugs according to Kinds, which has never been fully translated into English. We assess translation quality using both standard automated evaluation metrics (BLEU, chrF++, METEOR, ROUGE-L, BERTScore, COMET, BLEURT) and expert human evaluation via a modified Multidimensional Quality Metrics (MQM) framework applied to all 60 translations by a team of domain specialists. On the previously translated expository text, LLMs achieved high translation quality (mean MQM score 95.2/100), with performance approaching expert level. On the untranslated pharmacological text, aggregate quality was lower (79.9/100) but with high variance driven by two passages presenting extreme terminological density; excluding these, scores converged to within 4 points of the translated text. Terminology rarity, operationalized via corpus frequency in the literary Diorisis Ancient Greek Corpus, emerged as a strong predictor of translation failure (r = -.97 for passage-level quality on the untranslated text). Automated metrics showed moderate correlation with human judgment overall on the text with a wide quality spread (Composition), but no metric discriminated among high-quality translations. We discuss implications for the use of LLMs in Classical scholarship and for the design of automated evaluation pipelines for low-resource ancient languages.

</details>


### [101] [Task-Centric Acceleration of Small-Language Models](https://arxiv.org/abs/2602.24174)
*Dor Tsur,Sharon Adar,Ran Levy*

Main category: cs.CL

TL;DR: TASC方法通过两种策略提高了SLMs的推理效率。


<details>
  <summary>Details</summary>
Motivation: 小语言模型（SLMs）在特定任务应用中成为大型语言模型的替代方案，但在高容量、低延迟环境中效率至关重要。

Method: 提出TASC，一个包含两个用例的框架：TASC-ft和TASC-spec。TASC-ft通过迭代丰富标记器词汇表并使用扩展词汇微调模型。TASC-spec是一个轻量级、无训练的推测解码方法，从任务的输出语料库构建n-gram草案模型。

Result: 在多个低输出可变性生成任务中，两种方法都提高了推理效率，同时保持任务性能。

Conclusion: TASC方法在保持任务性能的同时，显著提高了SLMs的推理效率。

Abstract: Small language models (SLMs) have emerged as efficient alternatives to large language models for task-specific applications. However, they are often employed in high-volume, low-latency settings, where efficiency is crucial. We propose TASC, Task-Adaptive Sequence Compression, a framework for SLM acceleration comprising two use-cases: When performing SLM fine-tuning, we propose TASC-ft, which iteratively enriches the tokenizer vocabulary with high-frequency output n-grams and then fine-tunes the model to utilize the expanded vocabulary. Next, we propose an inference-time method, termed TASC-spec. TASC-spec is a lightweight, training-free speculative decoding method that constructs an n-gram draft model from the task's output corpus, mixing task and context n-gram information.TASC-spec avoids any additional training, while bypassing draft-target vocabulary alignment constraints. We demonstrate the effectiveness of both methods across multiple low output-variability generation tasks. Our methods show consistent improvements in inference efficiency while maintaining task performance.

</details>


### [102] [MT-PingEval: Evaluating Multi-Turn Collaboration with Private Information Games](https://arxiv.org/abs/2602.24188)
*Jacob Eisenstein,Fantine Huot,Adam Fisch,Jonathan Berant,Mirella Lapata*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We present a scalable methodology for evaluating language models in multi-turn interactions, using a suite of collaborative games that require effective communication about private information. This enables an interactive scaling analysis, in which a fixed token budget is divided over a variable number of turns. We find that in many cases, language models are unable to use interactive collaboration to improve over the non-interactive baseline scenario in which one agent attempts to summarize its information and the other agent immediately acts -- despite substantial headroom. This suggests that state-of-the-art models still suffer from significant weaknesses in planning and executing multi-turn collaborative conversations. We analyze the linguistic features of these dialogues, assessing the roles of sycophancy, information density, and discourse coherence. While there is no single linguistic explanation for the collaborative weaknesses of contemporary language models, we note that humans achieve comparable task success at superior token efficiency by producing dialogues that are more coherent than those produced by most language models. The proactive management of private information is a defining feature of real-world communication, and we hope that MT-PingEval will drive further work towards improving this capability.

</details>


### [103] [Controllable Reasoning Models Are Private Thinkers](https://arxiv.org/abs/2602.24210)
*Haritz Puerto,Haonan Li,Xudong Han,Timothy Baldwin,Iryna Gurevych*

Main category: cs.CL

TL;DR: 通过改进推理模型的指令遵循行为，可以显著提高隐私保护能力，为未来隐私感知智能体的开发提供了有希望的方向。


<details>
  <summary>Details</summary>
Motivation: AI agents powered by reasoning models require access to sensitive user data, which can result in the unintended leakage of private information.

Method: Proposing training models to follow instructions in reasoning traces, introducing a generation strategy that decouples reasoning and answer generation using separate LoRA adapters, and evaluating on six models across two benchmarks.

Result: Significant improvements in instruction-following performance and privacy benchmarks, but with a trade-off in task utility.

Conclusion: Improving instruction-following behavior in reasoning models can significantly enhance privacy, suggesting a promising direction for the development of future privacy-aware agents.

Abstract: AI agents powered by reasoning models require access to sensitive user data. However, their reasoning traces are difficult to control, which can result in the unintended leakage of private information to external parties. We propose training models to follow instructions not only in the final answer, but also in reasoning traces, potentially under different constraints. We hypothesize that improving their instruction following abilities in the reasoning traces can improve their privacy-preservation skills. To demonstrate this, we fine-tune models on a new instruction-following dataset with explicit restrictions on reasoning traces. We further introduce a generation strategy that decouples reasoning and answer generation using separate LoRA adapters. We evaluate our approach on six models from two model families, ranging from 1.7B to 14B parameters, across two instruction-following benchmarks and two privacy benchmarks. Our method yields substantial improvements, achieving gains of up to 20.9 points in instruction-following performance and up to 51.9 percentage points on privacy benchmarks. These improvements, however, can come at the cost of task utility, due to the trade-off between reasoning performance and instruction-following abilities. Overall, our results show that improving instruction-following behavior in reasoning models can significantly enhance privacy, suggesting a promising direction for the development of future privacy-aware agents. Our code and data are available at https://github.com/UKPLab/arxiv2026-controllable-reasoning-models

</details>


### [104] [Do LLMs Benefit From Their Own Words?](https://arxiv.org/abs/2602.24287)
*Jenny Y. Huang,Leshem Choshen,Ramon Astudillo,Tamara Broderick,Jacob Andreas*

Main category: cs.CL

TL;DR: 研究结果表明，大型语言模型在多轮交互中不需要依赖于自身先前响应，选择性省略助手历史可以改善性能


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型在多轮交互中是否从依赖于自身先前响应中受益

Method: 使用野外多轮对话，比较标准（完整上下文）提示与仅用户响应提示方法，在三个开放推理模型和一个最先进的模型上进行分析

Result: 发现移除先前助手响应不会影响大部分轮次的响应质量，省略助手历史可以减少累积上下文长度高达10倍，设计了一种上下文过滤方法，选择性地省略助手上下文，结果表明选择性省略助手历史可以提高响应质量，同时减少内存消耗

Conclusion: 大型语言模型在多轮交互中不需要依赖于自身先前响应，选择性省略助手历史可以提高响应质量，同时减少内存消耗

Abstract: Multi-turn interactions with large language models typically retain the assistant's own past responses in the conversation history. In this work, we revisit this design choice by asking whether large language models benefit from conditioning on their own prior responses. Using in-the-wild, multi-turn conversations, we compare standard (full-context) prompting with a user-turn-only prompting approach that omits all previous assistant responses, across three open reasoning models and one state-of-the-art model. To our surprise, we find that removing prior assistant responses does not affect response quality on a large fraction of turns. Omitting assistant-side history can reduce cumulative context lengths by up to 10x. To explain this result, we find that multi-turn conversations consist of a substantial proportion (36.4%) of self-contained prompts, and that many follow-up prompts provide sufficient instruction to be answered using only the current user turn and prior user turns. When analyzing cases where user-turn-only prompting substantially outperforms full context, we identify instances of context pollution, in which models over-condition on their previous responses, introducing errors, hallucinations, or stylistic artifacts that propagate across turns. Motivated by these findings, we design a context-filtering approach that selectively omits assistant-side context. Our findings suggest that selectively omitting assistant history can improve response quality while reducing memory consumption.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [105] [Uncovering Physical Drivers of Dark Matter Halo Structures with Auxiliary-Variable-Guided Generative Models](https://arxiv.org/abs/2602.23518)
*Arkaprabha Ganguli,Anirban Samaddar,Florian Kéruzoré,Nesar Ramachandra,Julie Bessac,Sandeep Madireddy,Emil Constantinescu*

Main category: stat.ML

TL;DR: 提出了一种新的方法来解耦暗物质晕的tSZ图表示，并将其转化为宇宙结构诊断工具。


<details>
  <summary>Details</summary>
Motivation: Deep generative models压缩高维数据，但通常会在潜在空间中纠缠不同的物理因素。

Method: 提出了一种辅助变量引导框架，将暗物质晕的热Sunyaev-Zel'dovich（tSZ）图表示进行解耦。引入了晕质量和浓度作为辅助变量，并应用轻量级对齐惩罚来鼓励潜在维度反映这些物理量。为了生成清晰和逼真的样本，扩展了潜在条件流匹配（LCFM），一种最先进的生成模型，以在潜在空间中强制实现解耦。

Result: Disentangled Latent-CFM（DL-CFM）模型恢复了已建立的质心-浓度尺度关系，并识别出潜在空间中的异常值，这些异常值可能与异常的晕形成历史相对应。通过将潜在坐标与可解释的天体物理属性联系起来，我们的方法将潜在空间转化为宇宙结构诊断工具。

Conclusion: 这项工作表明，辅助引导在保持生成灵活性的同时，产生了具有物理意义的解耦嵌入，为揭示复杂天体数据集中的独立因素提供了一条通用的途径。

Abstract: Deep generative models (DGMs) compress high-dimensional data but often entangle distinct physical factors in their latent spaces. We present an auxiliary-variable-guided framework for disentangling representations of thermal Sunyaev-Zel'dovich (tSZ) maps of dark matter halos. We introduce halo mass and concentration as auxiliary variables and apply a lightweight alignment penalty to encourage latent dimensions to reflect these physical quantities. To generate sharp and realistic samples, we extend latent conditional flow matching (LCFM), a state-of-the-art generative model, to enforce disentanglement in the latent space. Our Disentangled Latent-CFM (DL-CFM) model recovers the established mass-concentration scaling relation and identifies latent space outliers that may correspond to unusual halo formation histories. By linking latent coordinates to interpretable astrophysical properties, our method transforms the latent space into a diagnostic tool for cosmological structure. This work demonstrates that auxiliary guidance preserves generative flexibility while yielding physically meaningful, disentangled embeddings, providing a generalizable pathway for uncovering independent factors in complex astronomical datasets.

</details>


### [106] [Partition Function Estimation under Bounded f-Divergence](https://arxiv.org/abs/2602.23535)
*Adam Block,Abhishek Shetty*

Main category: stat.ML

TL;DR: 研究估计配分函数的统计复杂性，引入新工具，推广先前分析，提供最小假设理论。


<details>
  <summary>Details</summary>
Motivation: 研究在给定目标分布的未规范化密度比和提议分布的样本访问的情况下，估计配分函数的统计复杂性。

Method: 提供了一种基于信息论的一般性描述，该描述仅依赖于提议分布和目标分布之间的关系。

Result: 引入了综合覆盖配置文件，量化了目标质量在密度比大的区域中的程度。

Conclusion: 统一并推广了先前关于重要性采样、拒绝采样和重尾均值估计的分析，为配分函数估计提供了一个最小假设理论。

Abstract: We study the statistical complexity of estimating partition functions given sample access to a proposal distribution and an unnormalized density ratio for a target distribution. While partition function estimation is a classical problem, existing guarantees typically rely on structural assumptions about the domain or model geometry. We instead provide a general, information-theoretic characterization that depends only on the relationship between the proposal and target distributions. Our analysis introduces the integrated coverage profile, a functional that quantifies how much target mass lies in regions where the density ratio is large. We show that integrated coverage tightly characterizes the sample complexity of multiplicative partition function estimation and provide matching lower bounds. We further express these bounds in terms of $f$-divergences, yielding sharp phase transitions depending on the growth rate of f and recovering classical results as a special case while extending to heavy-tailed regimes. Matching lower bounds establish tightness in all regimes. As applications, we derive improved finite-sample guarantees for importance sampling and self-normalized importance sampling, and we show a strict separation between the complexity of approximate sampling and counting under the same divergence constraints. Our results unify and generalize prior analyses of importance sampling, rejection sampling, and heavy-tailed mean estimation, providing a minimal-assumption theory of partition function estimation. Along the way we introduce new technical tools including new connections between coverage and $f$-divergences as well as a generalization of the classical Paley-Zygmund inequality.

</details>


### [107] [Moment Matters: Mean and Variance Causal Graph Discovery from Heteroscedastic Observational Data](https://arxiv.org/abs/2602.23602)
*Yoichi Chikahara*

Main category: stat.ML

TL;DR: 提出了一种基于统计矩的因果发现框架，用于从异方差数据中识别均值和方差结构，实验结果表明其性能优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 阐明异方差性产生的原因对于科学知识发现和决策制定至关重要。

Method: 提出一种贝叶斯，基于统计矩的因果发现框架，从观察到的异方差数据中推断出分别的均值和方差因果图。

Result: 实验结果表明，该方法可以准确恢复均值和方差结构，并优于最先进的基线。

Conclusion: 该方法在异方差模型中具有较好的性能，能够有效识别均值和方差结构，为科学知识发现和决策制定提供支持。

Abstract: Heteroscedasticity -- where the variance of a variable changes with other variables -- is pervasive in real data, and elucidating why it arises from the perspective of statistical moments is crucial in scientific knowledge discovery and decision-making. However, standard causal discovery does not reveal which causes act on the mean versus the variance, as it returns a single moment-agnostic graph, limiting interpretability and downstream intervention design. We propose a Bayesian, moment-driven causal discovery framework that infers separate \textit{mean} and \textit{variance} causal graphs from observational heteroscedastic data. We first derive the identification results by establishing sufficient conditions under which these two graphs are separately identifiable. Building on this theory, we develop a variational inference method that learns a posterior distribution over both graphs, enabling principled uncertainty quantification of structural features (e.g., edges, paths, and subgraphs). To address the challenges of parameter optimization in heteroscedastic models with two graph structures, we take a curvature-aware optimization approach and develop a prior incorporation technique that leverages domain knowledge on node orderings, improving sample efficiency. Experiments on synthetic, semi-synthetic, and real data show that our approach accurately recovers mean and variance structures and outperforms state-of-the-art baselines.

</details>


### [108] [Fairness under Graph Uncertainty: Achieving Interventional Fairness with Partially Known Causal Graphs over Clusters of Variables](https://arxiv.org/abs/2602.23611)
*Yoichi Chikahara*

Main category: stat.ML

TL;DR: 提出了一种基于变量簇因果图的新框架，通过优化干预分布间的最大偏差来实现干预公平，在公平性和准确性之间取得了更好的平衡。


<details>
  <summary>Details</summary>
Motivation: 算法决策对个人需要准确且对敏感属性如性别和种族公平的预测。因果公平概念与法律要求一致，但许多方法假设对底层因果图的详细知识。

Method: 提出了一种学习框架，该框架通过利用变量簇上的因果图来实现干预公平，从而降低对底层因果图的详细知识的需求。

Result: 通过识别来自簇因果图的可能的调整簇集，该框架通过减少这些集之间干预分布之间的最大偏差来训练预测模型。开发了计算高效的质心核最大均值差异（MMD）。实验表明，该框架在公平性和准确性之间取得了比现有方法更好的平衡。

Conclusion: 该框架在有限因果图知识的情况下，在公平性和准确性之间取得了更好的平衡。

Abstract: Algorithmic decisions about individuals require predictions that are not only accurate but also fair with respect to sensitive attributes such as gender and race. Causal notions of fairness align with legal requirements, yet many methods assume access to detailed knowledge of the underlying causal graph, which is a demanding assumption in practice. We propose a learning framework that achieves interventional fairness by leveraging a causal graph over \textit{clusters of variables}, which is substantially easier to estimate than a variable-level graph. With possible \textit{adjustment cluster sets} identified from such a cluster causal graph, our framework trains a prediction model by reducing the worst-case discrepancy between interventional distributions across these sets. To this end, we develop a computationally efficient barycenter kernel maximum mean discrepancy (MMD) that scales favorably with the number of sensitive attribute values. Extensive experiments show that our framework strikes a better balance between fairness and accuracy than existing approaches, highlighting its effectiveness under limited causal graph knowledge.

</details>


### [109] [General Bayesian Policy Learning](https://arxiv.org/abs/2602.23672)
*Masahiro Kato*

Main category: stat.ML

TL;DR: 提出了通用贝叶斯框架进行策略学习，提供理论保证。


<details>
  <summary>Details</summary>
Motivation: 提出通用贝叶斯框架以进行策略学习。

Method: 基于损失函数的贝叶斯更新。

Result: 最大化经验福利与最小化结果差异的缩放平方误差等价。

Conclusion: 提出了一个适用于策略学习的通用贝叶斯框架，并提供了理论保证。

Abstract: This study proposes the General Bayes framework for policy learning. We consider decision problems in which a decision-maker chooses an action from an action set to maximize its expected welfare. Typical examples include treatment choice and portfolio selection. In such problems, the statistical target is a decision rule, and the prediction of each outcome $Y(a)$ is not necessarily of primary interest. We formulate this policy learning problem by loss-based Bayesian updating. Our main technical device is a squared-loss surrogate for welfare maximization. We show that maximizing empirical welfare over a policy class is equivalent to minimizing a scaled squared error in the outcome difference, up to a quadratic regularization controlled by a tuning parameter $ζ>0$. This rewriting yields a General Bayes posterior over decision rules that admits a Gaussian pseudo-likelihood interpretation. We clarify two Bayesian interpretations of the resulting generalized posterior, a working Gaussian view and a decision-theoretic loss-based view. As one implementation example, we introduce neural networks with tanh-squashed outputs. Finally, we provide theoretical guarantees in a PAC-Bayes style.

</details>


### [110] [A Variational Estimator for $L_p$ Calibration Errors](https://arxiv.org/abs/2602.24230)
*Eugène Berta,Sacha Braun,David Holzmüller,Francis Bach,Michael I. Jordan*

Main category: stat.ML

TL;DR: 本文提出了一种新的方法来估计校准误差，可以更准确地评估预测概率与观察到的类别频率的一致性。


<details>
  <summary>Details</summary>
Motivation: Calibration是确保预测概率与观察到的类别频率一致的问题，对于机器学习系统的可靠预测是一个基本要求。

Method: 提出了一种扩展最近变分框架的方法，用于估计校准误差，并将其应用于$L_p$散度诱导的广泛类别的校准误差。

Result: 该方法可以区分过度自信和不足自信，并且与变分方法不同，避免了高估。

Conclusion: 该方法在评估校准误差方面具有广泛的应用前景。

Abstract: Calibration$\unicode{x2014}$the problem of ensuring that predicted probabilities align with observed class frequencies$\unicode{x2014}$is a basic desideratum for reliable prediction with machine learning systems. Calibration error is traditionally assessed via a divergence function, using the expected divergence between predictions and empirical frequencies. Accurately estimating this quantity is challenging, especially in the multiclass setting. Here, we show how to extend a recent variational framework for estimating calibration errors beyond divergences induced induced by proper losses, to cover a broad class of calibration errors induced by $L_p$ divergences. Our method can separate over- and under-confidence and, unlike non-variational approaches, avoids overestimation. We provide extensive experiments and integrate our code in the open-source package probmetrics (https://github.com/dholzmueller/probmetrics) for evaluating calibration errors.

</details>


### [111] [Active Bipartite Ranking with Smooth Posterior Distributions](https://arxiv.org/abs/2602.24263)
*James Cheshire,Stephan Clémençon*

Main category: stat.ML

TL;DR: 本文提出了一种新的算法，用于在更通用的主动设置中解决双分图排名问题，实验结果表明其性能优于其他方法。


<details>
  <summary>Details</summary>
Motivation: 在许多应用中，双分图排名是一个统计学习方法问题，在被动环境中被广泛研究。本文在比文献中先前考虑的离散设置中更通用的主动设置中研究了这个问题。

Method: 提出了一种新的算法，称为平滑排名，用于连续设置，旨在最小化估计排名规则与最优排名之间的ROC曲线距离。

Result: 平滑排名在固定置信水平ε>0和概率δ∈(0,1)下是PAC(ε,δ)的。此外，还提供了平滑排名的期望采样时间的上界和任何PAC(ε,δ)算法的期望采样时间的下界。数值结果表明，所提出的算法的性能优于其他方法。

Conclusion: 本文提出了一种新的算法，用于在更通用的主动设置中解决双分图排名问题，并在理论和实验上证明了其有效性。

Abstract: In this article, bipartite ranking, a statistical learning problem involved in many applications and widely studied in the passive context, is approached in a much more general \textit{active setting} than the discrete one previously considered in the literature. While the latter assumes that the conditional distribution is piece wise constant, the framework we develop permits in contrast to deal with continuous conditional distributions, provided that they fulfill a Hölder smoothness constraint. We first show that a naive approach based on discretisation at a uniform level, fixed \textit{a priori} and consisting in applying next the active strategy designed for the discrete setting generally fails. Instead, we propose a novel algorithm, referred to as smooth-rank and designed for the continuous setting, which aims to minimise the distance between the ROC curve of the estimated ranking rule and the optimal one w.r.t. the $\sup$ norm. We show that, for a fixed confidence level $ε>0$ and probability $δ\in (0,1)$, smooth-rank is PAC$(ε,δ)$. In addition, we provide a problem dependent upper bound on the expected sampling time of smooth-rank and establish a problem dependent lower bound on the expected sampling time of any PAC$(ε,δ)$ algorithm. Beyond the theoretical analysis carried out, numerical results are presented, providing solid empirical evidence of the performance of the algorithm proposed, which compares favorably with alternative approaches.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [112] [Learning to Generate Secure Code via Token-Level Rewards](https://arxiv.org/abs/2602.23407)
*Jiazheng Quan,Xiaodong Li,Bin Wang,Guo An,Like Liu,Degen Huang,Lin Liu,Chengbin Hou*

Main category: cs.CR

TL;DR: Vul2Safe和SRCode通过改进代码生成和强化学习，有效降低了安全漏洞。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有方法在代码生成中存在的两个关键限制：高质量安全数据的稀缺性和粗粒度的强化学习奖励信号。

Method: 提出Vul2Safe，一个利用LLM自我反思从现实世界漏洞中构建高置信度修复对的新安全代码生成框架，并进一步生成多样化的隐式提示来构建PrimeVul+数据集。同时，引入SRCode，一个新颖的培训框架，它首次在代码安全性强化学习中使用token级别的奖励，使模型能够在训练过程中持续关注并强化关键细粒度安全模式。

Result: PrimeVul+和SRCode在多个基准测试中显著降低了生成代码中的安全漏洞，同时提高了整体代码质量。

Conclusion: Vul2Safe和SRCode框架能够有效减少代码生成中的安全漏洞，并提高代码质量。

Abstract: Large language models (LLMs) have demonstrated strong capabilities in code generation, yet they remain prone to producing security vulnerabilities. Existing approaches commonly suffer from two key limitations: the scarcity of high-quality security data and coarse-grained reinforcement learning reward signals. To address these challenges, we propose Vul2Safe, a new secure code generation framework that leverages LLM self-reflection to construct high-confidence repair pairs from real-world vulnerabilities, and further generates diverse implicit prompts to build the PrimeVul+ dataset. Meanwhile, we introduce SRCode, a novel training framework that pioneers the use of token-level rewards in reinforcement learning for code security, which enables the model to continuously attend to and reinforce critical fine-grained security patterns during training. Compared with traditional instance-level reward schemes, our approach allows for more precise optimization of local security implementations. Extensive experiments show that PrimeVul+ and SRCode substantially reduce security vulnerabilities in generated code while improving overall code quality across multiple benchmarks.

</details>


### [113] [A Software-Defined Testbed for Quantifying Deauthentication Resilience in Modern Wi-Fi Networks](https://arxiv.org/abs/2602.23513)
*Alex Carbajal,Asma Jodeiri Akbarfam*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Wi-Fi deauthentication attacks remain a practical denial-of-service (DoS) threat by exploiting unprotected management frames to disrupt client connectivity. In this work, we introduce a software-defined testbed to measure Wi-Fi resilience to deauthentication attacks. We experimentally evaluate five wireless security configurations: open networks, WPA1, WPA2 without Protected Management Frames (PMF), WPA2 with PMF, and WPA3. Using controlled experiments, we measure client disconnection rates, packet injection volume, and time-to-disruption under each configuration. Packet-level behavior is analyzed using standard wireless auditing tools. Open networks, WPA1, and WPA2 without PMF proved entirely vulnerable to deauthentication, while no successful attacks were observed for WPA2 with PMF or WPA3 under tested conditions. These findings confirm the effectiveness of management-frame protection and highlight the continued risk posed by legacy or misconfigured wireless deployments.

</details>


### [114] [Lap2: Revisiting Laplace DP-SGD for High Dimensions via Majorization Theory](https://arxiv.org/abs/2602.23516)
*Meisam Mohammady,Qin Yang,Nicholas Stout,Ayesha Samreen,Han Wang,Christopher J Quinn,Yuan Hong*

Main category: cs.CR

TL;DR: Lap2显著提高了Laplace DP-SGD的性能，实现了隐私保护与模型性能的平衡。


<details>
  <summary>Details</summary>
Motivation: DP-SGD在深度学习中确保隐私的关键技术，但Laplace机制由于L1范数剪裁而未被充分利用。

Method: 提出Lap2，一种允许L2剪裁的Laplace DP-SGD新解决方案。通过计算坐标-wise 瞬时界限和运用主化理论构造整个模型的上界，利用Schur-凸性聚合这些界限。

Result: 显著提高了Laplace DP-SGD的性能，在强隐私约束下，与高斯DP-SGD相当甚至更好。例如，在SST-2上微调RoBERTa-base（125M参数）在epsilon=0.54时达到87.88%的准确率，优于高斯（87.16%）和标准Laplace（48.97%）。

Conclusion: Lap2是一种有效的Laplace DP-SGD方法，可以显著提高性能并在隐私保护方面达到更好的效果。

Abstract: Differentially Private Stochastic Gradient Descent (DP-SGD) is a cornerstone technique for ensuring privacy in deep learning, widely used in both training from scratch and fine-tuning large-scale language models. While DP-SGD predominantly relies on the Gaussian mechanism, the Laplace mechanism remains underutilized due to its reliance on L1 norm clipping. This constraint severely limits its practicality in high-dimensional models because the L1 norm of an n-dimensional gradient can be up to sqrt(n) times larger than its L2 norm. As a result, the required noise scale grows significantly with model size, leading to poor utility or untrainable models.
  In this work, we introduce Lap2, a new solution that enables L2 clipping for Laplace DP-SGD while preserving strong privacy guarantees. We overcome the dimensionality-driven clipping barrier by computing coordinate-wise moment bounds and applying majorization theory to construct a tight, data-independent upper bound over the full model. By exploiting the Schur-convexity of the moment accountant function, we aggregate these bounds using a carefully designed majorization set that respects the L2 clipping constraint. This yields a multivariate privacy accountant that scales gracefully with model dimension and enables the use of thousands of moments. Empirical evaluations demonstrate that our approach significantly improves the performance of Laplace DP-SGD, achieving results comparable to or better than Gaussian DP-SGD under strong privacy constraints. For instance, fine-tuning RoBERTa-base (125M parameters) on SST-2 achieves 87.88% accuracy at epsilon=0.54, outperforming Gaussian (87.16%) and standard Laplace (48.97%) under the same budget.

</details>


### [115] [I've Seen This IP: A Practical Intersection Attack Against Tor Introduction Circuits and Hidden Services](https://arxiv.org/abs/2602.23560)
*Nicolas Constantinides*

Main category: cs.CR

TL;DR: 提出了一种针对Tor洋葱服务的交点攻击，实验表明攻击可行，并讨论了其实用性和影响。


<details>
  <summary>Details</summary>
Motivation: 匿名通信中，Tor洋葱服务依赖长生存期引入电路支持客户端和服务器的匿名会话。然而，引入协议保留了可被攻击者利用的确定性路由结构。

Method: 提出了一种针对Tor引入电路的交点攻击，通过重复交互，在只需观察每个阶段的单个中继的情况下，识别从引入点到洋葱服务的每个跳。攻击通过在狭窄定义的INTRODUCE1--RENDEZVOUS2时间窗口内重复探测和交点目的地IP地址集来识别每个跳。

Result: 实验结果表明，攻击在实践中具有可靠的收敛性，受共识权重和随时间变化的背景流量影响。在部分全局对手模型下评估了其实用性，并讨论了在不同司法管辖区中Tor中继权重的地理集中带来的影响。

Conclusion: 该攻击对Tor洋葱服务的安全性构成威胁，需要进一步的研究和改进来增强匿名通信的安全性。

Abstract: Tor onion services rely on long-lived introduction circuits to support anonymous rendezvous between clients and services. Although Tor includes some defenses against traffic analysis, the introduction protocol retains deterministic routing structure that can be leveraged by an adversary. We describe a practical intersection attack on Tor introduction circuits that can, over repeated interactions, identify each hop from the introduction point toward the onion service while requiring observation at only one relay per stage. The attack issues repeated probes and intersects destination IP address sets observed within narrowly defined \texttt{INTRODUCE1}--\texttt{RENDEZVOUS2} time windows, without assuming global visibility or access to packet payloads. We evaluate feasibility with live-network experiments using a self-operated onion service and relays, and we follow data-minimization and ethical safeguards throughout. The results show reliable convergence in practice, with the rate affected by consensus weight, and time-varying background traffic. We also assess practicality under a partial-global adversary model and discuss implications in light of the geographic concentration of Tor relay weight across cooperating jurisdictions.

</details>


### [116] [CLOAQ: Combined Logic and Angle Obfuscation for Quantum Circuits](https://arxiv.org/abs/2602.23569)
*Vincent Langford,Shihan Zhao,Hongyu Zhang,Ben Dong,Qian Wang,Anees Rehman,Yuntao Liu*

Main category: cs.CR

TL;DR: CLOAQ：一种有效的量子电路混淆方法，提高量子编译器安全性。


<details>
  <summary>Details</summary>
Motivation: 量子编译器存在安全风险，可能导致量子电路设计被盗和知识产权受到威胁。

Method: 提出CLOAQ量子电路混淆方法，隐藏选定的门的逻辑和相位角度。

Result: CLOAQ通过逻辑和相位保护相结合，提高了对攻击的抵抗能力，并在解锁密钥错误时造成更大的功能破坏。

Conclusion: CLOAQ是一种有效的量子电路混淆方法，可以提高量子编译器的安全性。

Abstract: In the realm of quantum computing, quantum circuits serve as essential depictions of quantum algorithms, which are then compiled into executable operations for quantum computations. Quantum compilers are responsible for converting these algorithmic quantum circuits into versions compatible with specific quantum hardware, thus connecting quantum software with hardware. Nevertheless, untrusted quantum compilers present notable threats. They have the potential to result in the theft of quantum circuit designs and jeopardize sensitive intellectual property (IP). In this work, we propose CLOAQ, a quantum circuit obfuscation (QCO) approach that hides the logic and the phase angles of selected gates within the obfuscated quantum circuit. To evaluate the effectiveness of CLOAQ, we sample the input state uniformly from the Hilbert space of all qubits, which is more accurate than prior work that use all-|0> inputs. Our results show that CLOAQ benefits from the synergy between logic and phase protections. Compared with prior QCO approaches using only one perspective, the combined method is more resilient to attacks and causes greater functional disruption when the unlocking key is incorrect.

</details>


### [117] [PDF: PUF-based DNN Fingerprinting for Knowledge Distillation Traceability](https://arxiv.org/abs/2602.23587)
*Ning Lyu,Yuntao Liu,Yonghong Bai,Zhiyuan Yan*

Main category: cs.CR

TL;DR: 提出了一种基于PUF签名的指纹框架，用于保护蒸馏模型，实现高密钥恢复率和可忽略的精度损失。


<details>
  <summary>Details</summary>
Motivation: 为了提供模型被盗后的责任归属和可追溯性，我们提出了一种新的指纹框架。

Method: 在知识蒸馏过程中，将特定于设备的物理不可克隆功能（PUF）签名叠加到教师模型的logits上。

Result: 实验结果表明，该框架实现了高密钥恢复率和可忽略的精度损失，同时允许在两个关键指标之间进行可调的权衡。

Conclusion: 该框架是一种实用且健壮的保护蒸馏模型的解决方案。

Abstract: Knowledge distillation transfers large teacher models to compact student models, enabling deployment on resource-limited platforms while suffering minimal performance degradation. However, this paradigm could lead to various security risks, especially model theft. Existing defenses against model theft, such as watermarking and secure enclaves, focus primarily on identity authentication and incur significant resource costs. Aiming to provide post-theft accountability and traceability, we propose a novel fingerprinting framework that superimposes device-specific Physical Unclonable Function (PUF) signatures onto teacher logits during distillation. Compared with watermarking or secure enclaves, our approach is lightweight, requires no architectural changes, and enables traceability of any leaked or cloned model. Since the signatures are based on PUFs, this framework is robust against reverse engineering and tampering attacks. In this framework, the signature recovery process consists of two stages: first a neural network-based decoder and then a Hamming distance decoder. Furthermore, we also propose a bit compression scheme to support a large number of devices. Experiment results demonstrate that our framework achieves high key recovery rate and negligible accuracy loss while allowing a tunable trade-off between these two key metrics. These results show that the proposed framework is a practical and robust solution for protecting distilled models.

</details>


### [118] [Central Bank Digital Currencies: Where is the Privacy, Technology, and Anonymity?](https://arxiv.org/abs/2602.23659)
*Jeff Nijsse,Andrea Pinto*

Main category: cs.CR

TL;DR: CBDC隐私保护设计研究


<details>
  <summary>Details</summary>
Motivation: 金融系统数字化和数字货币的普及推动了中央银行数字货币（CBDC）的发展，隐私合规成为CBDC设计的关键因素。

Method: 对20个现行CBDC的案例研究，提出综合隐私定义并映射到密码学领域。

Result: 研究显示，在提案阶段可以设计出综合隐私，但CBDC的发布版本并未实现隐私保护。

Conclusion: CBDC的隐私保护需要在设计阶段进行，但实现难度较大。

Abstract: In an age of financial system digitisation and the increasing adoption of digital currencies, Central Bank Digital Currencies (CBDCs) have emerged as a focal point for technological innovation. Privacy compliance has become a key factor in the successful design of CBDCs, extending beyond technical requirements to influence legal requirements, user trust, and security considerations. Implementing Privacy-Enhancing Technologies (PETs) in CBDCs requires an interdisciplinary approach, however, the lack of a common understanding of privacy and the essential technological characteristics restricts progress. This work investigates: (1) How privacy can be defined within the framework of CBDCs and what implications does this definition have for CBDCs design? and (2) Which PETs can be employed to enhance privacy in CBDC design? We propose a comprehensive definition for privacy that is mapped to the cryptographic landscape for feature implementation. The research is validated against case studies from 20 current CBDCs. The study shows that comprehensive privacy can be designed in the proposal stage, but that privacy does not reach the launched version of the CBDC.

</details>


### [119] [PLA for Drone RID Frames via Motion Estimation and Consistency Verification](https://arxiv.org/abs/2602.23760)
*Jie Li,Jing Li,Lu Lv,Zhanyu Ju,Fengkui Gong*

Main category: cs.CR

TL;DR: 提出了一种基于一致性验证的物理层认证算法，有效提高了无人机RID帧的安全性。


<details>
  <summary>Details</summary>
Motivation: Drone RID frames易受欺骗和重放攻击，需要提高安全性。

Method: 提出基于一致性验证的物理层认证算法，利用传感器参数和身份信息进行认证。

Result: 该算法在现实无线干扰和复杂无人机机动情况下，显著提高了认证可靠性和鲁棒性。

Conclusion: 该算法有效提高了无人机RID帧的安全性。

Abstract: Drone Remote Identification (RID) plays a critical role in low-altitude airspace supervision, yet its broadcast nature and lack of cryptographic protection make it vulnerable to spoofing and replay attacks. In this paper, we propose a consistency verification-based physical-layer authentication (PLA) algorithm for drone RID frames. A RID-aware sensing and decoding module is first developed to extract communication-derived sensing parameters, including angle-of-arrival, Doppler shift, average channel gain, and the number of transmit antennas, together with the identity and motion-related information decoded from previously authenticated RID frames. Rather than fusing all heterogeneous information into a single representation, different types of information are selectively utilized according to their physical relevance and reliability. Specifically, real-time wireless sensing parameter constraints and previously authenticated motion states are incorporated in a yaw-augmented constant-acceleration extended Kalman filter (CA-EKF) to estimate the three-dimensional position and motion states of the drone. To further enhance authentication reliability under highly maneuverable and non-stationary flight scenarios, a data-driven long short-term memory-based motion estimator is employed, and its predictions are adaptively combined with the CA-EKF via an error-aware fusion strategy. Finally, RID frames are authenticated by verifying consistency in the number of transmit antennas, motion estimates, and no-fly-zone constraints. Simulation results demonstrate that the proposed algorithm significantly improves authentication reliability and robustness under realistic wireless impairments and complex drone maneuvers, outperforming existing RF feature-based and motion model-based PLA schemes.

</details>


### [120] [Enhancing Continual Learning for Software Vulnerability Prediction: Addressing Catastrophic Forgetting via Hybrid-Confidence-Aware Selective Replay for Temporal LLM Fine-Tuning](https://arxiv.org/abs/2602.23834)
*Xuhui Dou,Hayretdin Bahsi,Alejandro Guerra-Manzanares*

Main category: cs.CR

TL;DR: This paper investigates continual fine-tuning of a decoder-style language model for source-code vulnerability detection. The proposed Hybrid-CASR method achieves higher accuracy and efficiency compared to traditional methods.


<details>
  <summary>Details</summary>
Motivation: Recent work applies Large Language Models (LLMs) to source-code vulnerability detection, but most evaluations still rely on random train-test splits that ignore time and overestimate real-world performance. In practice, detectors are deployed on evolving code bases and must recognise future vulnerabilities under temporal distribution shift.

Method: Continual fine-tuning of a decoder-style language model (microsoft/phi-2 with LoRA) on a CVE-linked dataset spanning 2018-2024, organised into bi-monthly windows. We evaluate eight continual learning strategies, including window-only and cumulative training, replay-based baselines and regularisation-based variants. We propose Hybrid Class-Aware Selective Replay (Hybrid-CASR), a confidence-aware replay method for binary vulnerability classification that prioritises uncertain samples while maintaining a balanced ratio of VULNERABLE and FIXED functions in the replay buffer.

Result: On bi-monthly forward evaluation Hybrid-CASR achieves a Macro-F1 of 0.667, improving on the window-only baseline (0.651) by 0.016 with statistically significant gains ($p = 0.026$) and stronger backward retention (IBR@1 of 0.741). Hybrid-CASR also reduces training time per window by about 17 percent compared to the baseline, whereas cumulative training delivers only a minor F1 increase (0.661) at a 15.9-fold computational cost.

Conclusion: Selective replay with class balancing offers a practical accuracy-efficiency trade-off for LLM-based temporal vulnerability detection under continuous temporal drift.

Abstract: Recent work applies Large Language Models (LLMs) to source-code vulnerability detection, but most evaluations still rely on random train-test splits that ignore time and overestimate real-world performance. In practice, detectors are deployed on evolving code bases and must recognise future vulnerabilities under temporal distribution shift. This paper investigates continual fine-tuning of a decoder-style language model (microsoft/phi-2 with LoRA) on a CVE-linked dataset spanning 2018-2024, organised into bi-monthly windows. We evaluate eight continual learning strategies, including window-only and cumulative training, replay-based baselines and regularisation-based variants. We propose Hybrid Class-Aware Selective Replay (Hybrid-CASR), a confidence-aware replay method for binary vulnerability classification that prioritises uncertain samples while maintaining a balanced ratio of VULNERABLE and FIXED functions in the replay buffer. On bi-monthly forward evaluation Hybrid-CASR achieves a Macro-F1 of 0.667, improving on the window-only baseline (0.651) by 0.016 with statistically significant gains ($p = 0.026$) and stronger backward retention (IBR@1 of 0.741). Hybrid-CASR also reduces training time per window by about 17 percent compared to the baseline, whereas cumulative training delivers only a minor F1 increase (0.661) at a 15.9-fold computational cost. Overall, the results show that selective replay with class balancing offers a practical accuracy-efficiency trade-off for LLM-based temporal vulnerability detection under continuous temporal drift.

</details>


### [121] [MI$^2$DAS: A Multi-Layer Intrusion Detection Framework with Incremental Learning for Securing Industrial IoT Networks](https://arxiv.org/abs/2602.23846)
*Wei Lian,Alejandro Guerra-Manzanares*

Main category: cs.CR

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The rapid expansion of Industrial IoT (IIoT) systems has amplified security challenges, as heterogeneous devices and dynamic traffic patterns increase exposure to sophisticated and previously unseen cyberattacks. Traditional intrusion detection systems often struggle in such environments due to their reliance on extensive labeled data and limited ability to detect new threats. To address these challenges, we propose MI$^2$DAS, a multi-layer intrusion detection framework that integrates anomaly-based hierarchical traffic pooling, open-set recognition to distinguish between known and unknown attacks and incremental learning for adapting to novel attack types with minimal labeling. Experiments conducted on the Edge-IIoTset dataset demonstrate strong performance across all layers. In the first layer, GMM achieves superior normal-attack discrimination (accuracy = 0.953, TPR = 1.000). In open-set recognition, GMM attains a recall of 0.813 for known attacks, while LOF achieves 0.882 recall for unknown attacks. For fine-grained classification of known attacks, Random Forest achieves a macro-F1 of 0.941. Finally, the incremental learning module maintains robust performance when incorporation novel attack classes, achieving a macro-F1 of 0.8995. These results showcase MI$^2$DAS as an effective, scalable and adaptive framework for enhancing IIoT security against evolving threats.

</details>


### [122] [SAILOR: A Scalable and Energy-Efficient Ultra-Lightweight RISC-V for IoT Security](https://arxiv.org/abs/2602.24166)
*Christian Ewert,Tim Hardow,Melf Fritsch,Leon Dietrich,Henrik Strunck,Rainer Buchty,Mladen Berekovic,Saleh Mulhem*

Main category: cs.CR

TL;DR: 提出了一种节能的RISC-V内核SAILOR，解决了物联网设备中的能源效率、面积和安全问题。


<details>
  <summary>Details</summary>
Motivation: 为了解决当前RISC-V内核在物联网设备中在能源效率、面积和集成安全之间的平衡问题。

Method: 提出了SAILOR，这是一个节能和可扩展的超轻量级RISC-V内核系列，适用于物联网中的加密应用。设计是模块化的，包括1-、2-、4-、8-、16-和32位序列化执行数据路径。

Result: SAILOR在性能和能源效率方面超过了最先进解决方案高达13倍，面积减少了高达59%。

Conclusion: 证明了在物联网中，轻量级加密功能可以添加而不产生过高的开销，并且能源或面积高效的设计不必牺牲性能。

Abstract: Recently, RISC-V has contributed to the development of IoT devices, requiring architectures that balance energy efficiency, compact area, and integrated security. However, most recent RISC-V cores for IoT prioritize either area footprint or energy efficiency, while adding cryptographic support further compromises compactness. As a result, truly integrated architectures that simultaneously optimize efficiency and security remain largely unexplored, leaving constrained IoT environments vulnerable to performance and security trade-offs. In this paper, we introduce SAILOR, an energy-efficient and scalable ultra-lightweight RISC-V core family for cryptographic applications in IoT. Our design is modular and spans 1-, 2-, 4-, 8-, 16-, and 32-bit serialized execution data-paths, prioritizing minimal area. This modular design and adaptable data-path minimizes the overhead of integrating RISC-V cryptography extensions, achieving low hardware cost while significantly improving energy efficiency. We validate our design approach through a comprehensive analysis of area, energy, and efficiency trade-offs. The results surpass state-of-the-art solutions in both performance and energy efficiency by up to 13x and reduce area by up to 59 %, demonstrating that lightweight cryptographic features can be added without prohibitive overhead, and that energy- or area-efficient designs need not compromise performance.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [123] [HumanMCP: A Human-Like Query Dataset for Evaluating MCP Tool Retrieval Performance](https://arxiv.org/abs/2602.23367)
*Shubh Laddha,Lucas Changbencharoen,Win Kuptivej,Surya Shringla,Archana Vaidheeswaran,Yash Bhaskar*

Main category: cs.AI

TL;DR: 本研究提出了一种新的MCP数据集，用于评估MCP服务器工具使用和生态系统。


<details>
  <summary>Details</summary>
Motivation: 为了评估MCP服务器工具使用和生态系统，现有的数据集和基准测试缺乏真实、类似人类的用户查询。

Method: 创建了一个大规模的MCP数据集，包含针对308个MCP服务器上的2800个工具生成的多样化、高质量的查询。

Result: 每个工具都与多个独特的用户角色配对，以捕捉不同层次的用户意图，从精确的任务请求到模糊的探索性命令。

Conclusion: 该研究为MCP服务器工具使用和生态系统评估提供了更全面的数据集。

Abstract: Model Context Protocol (MCP) servers contain a collection of thousands of open-source standardized tools, linking LLMs to external systems; however, existing datasets and benchmarks lack realistic, human-like user queries, remaining a critical gap in evaluating the tool usage and ecosystems of MCP servers. Existing datasets often do contain tool descriptions but fail to represent how different users portray their requests, leading to poor generalization and inflated reliability of certain benchmarks. This paper introduces the first large-scale MCP dataset featuring diverse, high-quality diverse user queries generated specifically to match 2800 tools across 308 MCP servers, developing on the MCP Zero dataset. Each tool is paired with multiple unique user personas that we have generated, to capture varying levels of user intent ranging from precise task requests, and ambiguous, exploratory commands, reflecting the complexity of real-world interaction patterns.

</details>


### [124] [An Agentic LLM Framework for Adverse Media Screening in AML Compliance](https://arxiv.org/abs/2602.23373)
*Pavel Chernakov,Sasan Jafarnejad,Raphaël Frank*

Main category: cs.AI

TL;DR: 提出了一种基于LLM和RAG的不良媒体筛查系统，提高了筛查效率和准确性


<details>
  <summary>Details</summary>
Motivation: 提高反洗钱（AML）和了解你的客户（KYC）合规流程中不良媒体筛查的效率

Method: 使用大型语言模型（LLM）和检索增强生成（RAG）技术

Result: 自动化不良媒体筛查，提高筛查准确性

Conclusion: 该系统能够有效区分高风险和低风险个体

Abstract: Adverse media screening is a critical component of anti-money laundering (AML) and know-your-customer (KYC) compliance processes in financial institutions. Traditional approaches rely on keyword-based searches that generate high false-positive rates or require extensive manual review. We present an agentic system that leverages Large Language Models (LLMs) with Retrieval-Augmented Generation (RAG) to automate adverse media screening. Our system implements a multi-step approach where an LLM agent searches the web, retrieves and processes relevant documents, and computes an Adverse Media Index (AMI) score for each subject. We evaluate our approach using multiple LLM backends on a dataset comprising Politically Exposed Persons (PEPs), persons from regulatory watchlists, and sanctioned persons from OpenSanctions and clean names from academic sources, demonstrating the system's ability to distinguish between high-risk and low-risk individuals.

</details>


### [125] [Causal Identification from Counterfactual Data: Completeness and Bounding Results](https://arxiv.org/abs/2602.23541)
*Arvind Raghavan,Elias Bareinboim*

Main category: cs.AI

TL;DR: 提出CTFIDU+算法，揭示了第三层反事实识别的理论极限，并证明了反事实数据在分析非可识别量时的作用。


<details>
  <summary>Details</summary>
Motivation: 分析反事实识别在三层因果层次结构中第三层数据的新访问方式，以及它对可识别反事实数量的影响。

Method: 开发CTFIDU+算法以从任意第三层分布中识别反事实查询，并证明其在任务上的完备性。建立理论极限，以确定哪些反事实可以从物理可实现分布中识别出来。使用可实现反事实数据推导出新型分析界限，并通过模拟证实反事实数据有助于在实践中收紧非可识别量的界限。

Result: 证明了CTFIDU+算法在识别第三层反事实查询方面的完备性，确定了可识别反事实的理论极限，并推导出了新型分析界限，证实了反事实数据在收紧非可识别量界限方面的作用。

Conclusion: CTFIDU+算法为从第三层数据中识别反事实提供了新的方法，揭示了非参数设置下精确因果推断的根本限制，并提出了使用可实现反事实数据进行分析的新方法。

Abstract: Previous work establishing completeness results for $\textit{counterfactual identification}$ has been circumscribed to the setting where the input data belongs to observational or interventional distributions (Layers 1 and 2 of Pearl's Causal Hierarchy), since it was generally presumed impossible to obtain data from counterfactual distributions, which belong to Layer 3. However, recent work (Raghavan & Bareinboim, 2025) has formally characterized a family of counterfactual distributions which can be directly estimated via experimental methods - a notion they call $\textit{counterfactual realizabilty}$. This leaves open the question of what $\textit{additional}$ counterfactual quantities now become identifiable, given this new access to (some) Layer 3 data. To answer this question, we develop the CTFIDU+ algorithm for identifying counterfactual queries from an arbitrary set of Layer 3 distributions, and prove that it is complete for this task. Building on this, we establish the theoretical limit of which counterfactuals can be identified from physically realizable distributions, thus implying the $\textit{fundamental limit to exact causal inference in the non-parametric setting}$. Finally, given the impossibility of identifying certain critical types of counterfactuals, we derive novel analytic bounds for such quantities using realizable counterfactual data, and corroborate using simulations that counterfactual data helps tighten the bounds for non-identifiable quantities in practice.

</details>


### [126] [Planning under Distribution Shifts with Causal POMDPs](https://arxiv.org/abs/2602.23545)
*Matteo Ceriscioli,Karthika Mohan*

Main category: cs.AI

TL;DR: 提出了一种基于因果知识的POMDP规划框架，用于应对分布变化，并保持规划的可行性。


<details>
  <summary>Details</summary>
Motivation: 在现实世界中，由于分布变化，规划经常受到挑战。因此，在一种条件下获得的关于环境的模型可能不再有效，因为状态分布或环境动态发生变化，这反过来又导致之前学习到的策略失效。

Method: 提出了一种使用因果知识公理化的部分可观察马尔可夫决策过程（POMDPs）的理论框架，用于在部分可观察性下进行规划。通过将环境的变化表示为对因果POMDP的干预，该框架使评估假设变化下的计划成为可能，并主动识别哪些环境组件已更改。

Result: 证明了在增强信念空间中，值函数保持分段线性且凸（PWLC）。在分布变化下保持PWLC的优点是，通过基于$α$向量的POMDP方法保持规划的可行性。

Conclusion: 该框架为在分布变化的情况下进行规划提供了一种新的方法，有助于识别环境变化并保持规划的可行性。

Abstract: In the real world, planning is often challenged by distribution shifts. As such, a model of the environment obtained under one set of conditions may no longer remain valid as the distribution of states or the environment dynamics change, which in turn causes previously learned strategies to fail. In this work, we propose a theoretical framework for planning under partial observability using Partially Observable Markov Decision Processes (POMDPs) formulated using causal knowledge. By representing shifts in the environment as interventions on this causal POMDP, the framework enables evaluating plans under hypothesized changes and actively identifying which components of the environment have been altered. We show how to maintain and update a belief over both the latent state and the underlying domain, and we prove that the value function remains piecewise linear and convex (PWLC) in this augmented belief space. Preservation of PWLC under distribution shifts has the advantage of maintaining the tractability of planning via $α$-vector-based POMDP methods.

</details>


### [127] [Construct, Merge, Solve & Adapt with Reinforcement Learning for the min-max Multiple Traveling Salesman Problem](https://arxiv.org/abs/2602.23579)
*Guillem Rodríguez-Corominas,Maria J. Blesa,Christian Blum*

Main category: cs.AI

TL;DR: RL-CMSA在多旅行商问题上表现出色


<details>
  <summary>Details</summary>
Motivation: 解决对称单仓库最小-最大多旅行商问题

Method: 提出了一种混合方法，即使用强化学习的构建、合并、求解和适应（RL-CMSA）

Result: 在随机和TSPLIB实例上的计算结果表明，RL-CMSA始终找到（近）最佳解，并在可比时间限制下优于最先进的混合遗传算法，特别是在实例规模和销售人员数量增加时

Conclusion: RL-CMSA是一种有效的对称单仓库最小-最大多旅行商问题的解决方案

Abstract: The Multiple Traveling Salesman Problem (mTSP) extends the Traveling Salesman Problem to m tours that start and end at a common depot and jointly visit all customers exactly once. In the min-max variant, the objective is to minimize the longest tour, reflecting workload balance. We propose a hybrid approach, Construct, Merge, Solve & Adapt with Reinforcement Learning (RL-CMSA), for the symmetric single-depot min-max mTSP. The method iteratively constructs diverse solutions using probabilistic clustering guided by learned pairwise q-values, merges routes into a compact pool, solves a restricted set-covering MILP, and refines solutions via inter-route remove, shift, and swap moves. The q-values are updated by reinforcing city-pair co-occurrences in high-quality solutions, while the pool is adapted through ageing and pruning. This combination of exact optimization and reinforcement-guided construction balances exploration and exploitation. Computational results on random and TSPLIB instances show that RL-CMSA consistently finds (near-)best solutions and outperforms a state-of-the-art hybrid genetic algorithm under comparable time limits, especially as instance size and the number of salesmen increase.

</details>


### [128] [SleepLM: Natural-Language Intelligence for Human Sleep](https://arxiv.org/abs/2602.23605)
*Zongzhe Xu,Zitao Shuai,Eideen Mozaffari,Ravi S. Aysola,Rajesh Kumar,Yuzhe Yang*

Main category: cs.AI

TL;DR: SleepLM是一种新型睡眠分析模型，能够实现睡眠生理学的语言化表示，并在多个任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 为了解决睡眠分析系统在描述、查询或推广到新的睡眠现象方面的不足，作者提出了SleepLM模型。

Method: SleepLM结合了自然语言和多模态睡眠脑电图，引入了多级睡眠字幕生成流程，并提出了统一的预训练目标。

Result: SleepLM在零样本和少样本学习、跨模态检索和睡眠字幕生成方面优于现有技术，并展现出语言引导的事件定位、针对性见解生成和零样本泛化等能力。

Conclusion: SleepLM是一种有效的睡眠分析工具，能够实现睡眠生理学的语言化表示，并具有广泛的应用前景。

Abstract: We present SleepLM, a family of sleep-language foundation models that enable human sleep alignment, interpretation, and interaction with natural language. Despite the critical role of sleep, learning-based sleep analysis systems operate in closed label spaces (e.g., predefined stages or events) and fail to describe, query, or generalize to novel sleep phenomena. SleepLM bridges natural language and multimodal polysomnography, enabling language-grounded representations of sleep physiology. To support this alignment, we introduce a multilevel sleep caption generation pipeline that enables the curation of the first large-scale sleep-text dataset, comprising over 100K hours of data from more than 10,000 individuals. Furthermore, we present a unified pretraining objective that combines contrastive alignment, caption generation, and signal reconstruction to better capture physiological fidelity and cross-modal interactions. Extensive experiments on real-world sleep understanding tasks verify that SleepLM outperforms state-of-the-art in zero-shot and few-shot learning, cross-modal retrieval, and sleep captioning. Importantly, SleepLM also exhibits intriguing capabilities including language-guided event localization, targeted insight generation, and zero-shot generalization to unseen tasks. All code and data will be open-sourced.

</details>


### [129] [MMKG-RDS: Reasoning Data Synthesis via Deep Mining of Multimodal Knowledge Graphs](https://arxiv.org/abs/2602.23632)
*Lun Zhan,Feng Xiong,Huanyong Liu,Feng Zhang,Yuhui Yin*

Main category: cs.AI

TL;DR: 提出MMKG-RDS框架，提高推理数据合成质量和效率


<details>
  <summary>Details</summary>
Motivation: 为了解决现有方法在长尾知识覆盖、有效性验证和可解释性方面的局限性，以及知识图谱方法在功能、粒度、可定制性和评估方面的不足。

Method: 提出了一种名为MMKG-RDS的灵活框架，该框架利用多模态知识图谱进行推理数据合成。它支持细粒度知识提取、可定制的路径采样和多维度数据质量评分。

Result: 实验结果表明，在少量合成的样本上微调Qwen3模型（0.6B/8B/32B）可以提高推理精度9.2%。框架还生成了独特的数据，在涉及表格和公式的任务中挑战了现有模型，有助于复杂基准的构建。

Conclusion: MMKG-RDS框架能够有效提升推理数据合成的质量和效率，为复杂基准的构建提供了新的思路和方法。

Abstract: Synthesizing high-quality training data is crucial for enhancing domain models' reasoning abilities. Existing methods face limitations in long-tail knowledge coverage, effectiveness verification, and interpretability. Knowledge-graph-based approaches still fall short in functionality, granularity, customizability, and evaluation. To address these issues, we propose MMKG-RDS, a flexible framework for reasoning data synthesis that leverages multimodal knowledge graphs. It supports fine-grained knowledge extraction, customizable path sampling, and multidimensional data quality scoring. We validate MMKG-RDS with the MMKG-RDS-Bench dataset, covering five domains, 17 task types, and 14,950 samples. Experimental results show fine-tuning Qwen3 models (0.6B/8B/32B) on a small number of synthesized samples improves reasoning accuracy by 9.2%. The framework also generates distinct data, challenging existing models on tasks involving tables and formulas, useful for complex benchmark construction. The dataset and code are available at https://github.com/360AILAB-NLP/MMKG-RDS

</details>


### [130] [AI Must Embrace Specialization via Superhuman Adaptable Intelligence](https://arxiv.org/abs/2602.23643)
*Judah Goldfeder,Philippe Wyder,Yann LeCun,Ravid Shwartz Ziv*

Main category: cs.AI

TL;DR: 本文提出SAI概念，旨在替代AGI，以推动AI技术向更精确、更有效的方向发展。


<details>
  <summary>Details</summary>
Motivation: 探讨对AGI的理解和定义存在的问题，并提出SAI概念作为替代方案。

Method: 分析现有AGI定义的局限性，提出SAI的定义和优势。

Result: 提出SAI概念，并阐述其在AI发展中的潜在应用和影响。

Conclusion: SAI是一个更精确、更有用的AI概念，有助于推动AI技术的健康发展。

Abstract: Everyone from AI executives and researchers to doomsayers, politicians, and activists is talking about Artificial General Intelligence (AGI). Yet, they often don't seem to agree on its exact definition. One common definition of AGI is an AI that can do everything a human can do, but are humans truly general? In this paper, we address what's wrong with our conception of AGI, and why, even in its most coherent formulation, it is a flawed concept to describe the future of AI. We explore whether the most widely accepted definitions are plausible, useful, and truly general. We argue that AI must embrace specialization, rather than strive for generality, and in its specialization strive for superhuman performance, and introduce Superhuman Adaptable Intelligence (SAI). SAI is defined as intelligence that can learn to exceed humans at anything important that we can do, and that can fill in the skill gaps where humans are incapable. We then lay out how SAI can help hone a discussion around AI that was blurred by an overloaded definition of AGI, and extrapolate the implications of using it as a guide for the future.

</details>


### [131] [Unlocking Cognitive Capabilities and Analyzing the Perception-Logic Trade-off](https://arxiv.org/abs/2602.23730)
*Longyin Zhang,Shuo Sun,Yingxu He,Won Cheng Yi Lewis,Muhammad Huzaifah Bin Md Shahrin,Hardik Bhupendra Sailor,Heng Meng Jeremy Wong,Tarun Kumar Vangani,Yi Ma,Qiongqiong Wang,Minh Duc Pham,Ridong Jiang,Jingtao Li,Jingyi Liao,Zhuohan Liu,Yanfeng Lu,Manas Gupta,Ai Ti Aw*

Main category: cs.AI

TL;DR: MERaLiON2-Omni（Alpha）模型通过正交模态自适应和Generate-Judge-Refine流程实现多模态感知和推理，揭示了效率-稳定性悖论。


<details>
  <summary>Details</summary>
Motivation: 为了解决将稳健的感觉基础与复杂的推理相结合的挑战，特别是对于代表性不足的地区，研究人员开发了MERaLiON2-Omni（Alpha）模型。

Method: 通过正交模态自适应将特定于地区的音频-视觉线索（例如，Singlish代码转换、当地文化地标）与多语言LLM对齐，建立稳健的感觉骨干。提出了一种成本效益高的Generate-Judge-Refine流程，利用Super-LLM进行幻觉过滤和冲突解决。

Result: 在SEA-Omni基准套件上进行了全面评估，揭示了效率-稳定性悖论。推理在抽象任务中作为非线性放大器，但在低级感官处理中引入了不稳定性。

Conclusion: 本文详细介绍了架构、数据高效的训练方案以及稳健感知和结构化推理之间的权衡的诊断分析。

Abstract: Recent advancements in Multimodal Large Language Models (MLLMs) pursue omni-perception capabilities, yet integrating robust sensory grounding with complex reasoning remains a challenge, particularly for underrepresented regions. In this report, we introduce the research preview of MERaLiON2-Omni (Alpha), a 10B-parameter multilingual omni-perception tailored for Southeast Asia (SEA). We present a progressive training pipeline that explicitly decouples and then integrates "System 1" (Perception) and "System 2" (Reasoning) capabilities. First, we establish a robust Perception Backbone by aligning region-specific audio-visual cues (e.g., Singlish code-switching, local cultural landmarks) with a multilingual LLM through orthogonal modality adaptation. Second, to inject cognitive capabilities without large-scale supervision, we propose a cost-effective Generate-Judge-Refine pipeline. By utilizing a Super-LLM to filter hallucinations and resolve conflicts via a consensus mechanism, we synthesize high-quality silver data that transfers textual Chain-of-Thought reasoning to multimodal scenarios.
  Comprehensive evaluation on our newly introduced SEA-Omni Benchmark Suite reveals an Efficiency-Stability Paradox: while reasoning acts as a non-linear amplifier for abstract tasks (boosting mathematical and instruction-following performance significantly), it introduces instability in low-level sensory processing. Specifically, we identify Temporal Drift in long-context audio, where extended reasoning desynchronizes the model from acoustic timestamps, and Visual Over-interpretation, where logic overrides pixel-level reality. This report details the architecture, the data-efficient training recipe, and a diagnostic analysis of the trade-offs between robust perception and structured reasoning.

</details>


### [132] [Reasoning-Driven Multimodal LLM for Domain Generalization](https://arxiv.org/abs/2602.23777)
*Zhipeng Xu,Zilong Wang,Xinyang Jiang,Dongsheng Li,De Cheng,Nannan Wang*

Main category: cs.AI

TL;DR: 本文提出了一种基于推理的领域泛化方法，在标准数据集上取得了最先进的性能


<details>
  <summary>Details</summary>
Motivation: 解决深度学习中领域泛化（DG）问题

Method: 利用多模态大型语言模型（MLLMs）的推理能力，构建推理链来提高预测的鲁棒性

Result: 提出RD-MLDG框架，包含MTCT和SARR两个组件，在标准DomainBed数据集上取得最先进的性能

Conclusion: 推理是鲁棒跨领域泛化的有希望的补充信号

Abstract: This paper addresses the domain generalization (DG) problem in deep learning. While most DG methods focus on enforcing visual feature invariance, we leverage the reasoning capability of multimodal large language models (MLLMs) and explore the potential of constructing reasoning chains that derives image categories to achieve more robust predictions under domain shift. To this end, we systematically study the role of reasoning in DG using DomainBed-Reasoning, a newly constructed extension of DomainBed dataset, in which each sample is paired with class-relevant reasoning chains. Our analysis reveals two key challenges: (i) fine-tuning MLLMs with reasoning chains for classification is more challenging than direct label supervision, since the model must optimize complex reasoning sequences before label prediction; and (ii) mismatches in reasoning patterns between supervision signals and fine-tuned MLLMs lead to a trade-off between semantic richness (informative but harder to optimize) and optimization efficiency (easier to optimize but less informative). To address these issues, we propose RD-MLDG (Reasoning-Driven Multimodal LLM for Domain Generalization), a framework with two components: (i) MTCT (Multi-Task Cross-Training), which introduces an additional direct classification pathway to guide reasoning supervision; and (ii) SARR (Self-Aligned Reasoning Regularization), which preserves the semantic richness of reasoning chains while mitigating reasoning-pattern mismatches via iterative self-labeling. Experiments on standard DomainBed datasets (PACS, VLCS, OfficeHome, TerraInc) demonstrate that RD-MLDG achieves state-of-the-art performances, highlighting reasoning as a promising complementary signal for robust out-of-domain generalization.

</details>


### [133] [EMO-R3: Reflective Reinforcement Learning for Emotional Reasoning in Multimodal Large Language Models](https://arxiv.org/abs/2602.23802)
*Yiyang Fang,Wenke Huang,Pei Fu,Yihao Yang,Kehua Su,Zhenbo Luo,Jian Luan,Mang Ye*

Main category: cs.AI

TL;DR: EMO-R3显著提高了MLLM的情感推理能力。


<details>
  <summary>Details</summary>
Motivation: MLLMs在视觉推理和理解任务上取得了显著进展，但仍然难以捕捉人类情感的主观性和复杂性。

Method: 提出Reflective Reinforcement Learning for Emotional Reasoning (EMO-R3)框架，引入结构化情感思考和设计反思情感奖励，以增强MLLM的情感推理能力。

Result: 实验证明，EMO-R3显著提高了MLLM的解释性和情感智力，在多个视觉情感理解基准测试中表现出色。

Conclusion: EMO-R3是一个有效的框架，可以增强MLLM的情感推理能力，并提高其在视觉情感理解任务中的性能。

Abstract: Multimodal Large Language Models (MLLMs) have shown remarkable progress in visual reasoning and understanding tasks but still struggle to capture the complexity and subjectivity of human emotions. Existing approaches based on supervised fine-tuning often suffer from limited generalization and poor interpretability, while reinforcement learning methods such as Group Relative Policy Optimization fail to align with the intrinsic characteristics of emotional cognition. To address these challenges, we propose Reflective Reinforcement Learning for Emotional Reasoning (EMO-R3), a framework designed to enhance the emotional reasoning ability of MLLMs. Specifically, we introduce Structured Emotional Thinking to guide the model to perform step-by-step emotional reasoning in a structured and interpretable manner, and design a Reflective Emotional Reward that enables the model to re-evaluate its reasoning based on visual-text consistency and emotional coherence. Extensive experiments demonstrate that EMO-R3 significantly improves both the interpretability and emotional intelligence of MLLMs, achieving superior performance across multiple visual emotional understanding benchmarks.

</details>


### [134] [Pessimistic Auxiliary Policy for Offline Reinforcement Learning](https://arxiv.org/abs/2602.23974)
*Fan Zhang,Baoru Huang,Xin Zhang*

Main category: cs.AI

TL;DR: 本文提出了一种新的悲观辅助策略，有效提高了离线强化学习的效果。


<details>
  <summary>Details</summary>
Motivation: 避免在实时交互中出现不安全和低效的问题，同时减少学习过程中的误差积累和过估计。

Method: 构建一个新的悲观辅助策略来采样可靠的动作，通过最大化Q函数的下置信界来实现。

Result: 实验结果表明，使用悲观辅助策略可以有效地提高其他离线强化学习方法的效率。

Conclusion: 悲观辅助策略有助于减少离线强化学习中的误差累积和过估计，并提高学习效率。

Abstract: Offline reinforcement learning aims to learn an agent from pre-collected datasets, avoiding unsafe and inefficient real-time interaction. However, inevitable access to out-ofdistribution actions during the learning process introduces approximation errors, causing the error accumulation and considerable overestimation. In this paper, we construct a new pessimistic auxiliary policy for sampling reliable actions. Specifically, we develop a pessimistic auxiliary strategy by maximizing the lower confidence bound of the Q-function. The pessimistic auxiliary strategy exhibits a relatively high value and low uncertainty in the vicinity of the learned policy, avoiding the learned policy sampling high-value actions with potentially high errors during the learning process. Less approximation error introduced by sampled action from pessimistic auxiliary strategy leads to the alleviation of error accumulation. Extensive experiments on offline reinforcement learning benchmarks reveal that utilizing the pessimistic auxiliary strategy can effectively improve the efficacy of other offline RL approaches.

</details>


### [135] [CIRCLE: A Framework for Evaluating AI from a Real-World Lens](https://arxiv.org/abs/2602.24055)
*Reva Schwartz,Carina Westling,Morgan Briggs,Marzieh Fadaee,Isar Nejadgholi,Matthew Holmes,Fariza Rashid,Maya Carlyle,Afaf Taïk,Kyra Wilson,Peter Douglas,Theodora Skeadas,Gabriella Waters,Rumman Chowdhury,Thiago Lacerda*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This paper proposes CIRCLE, a six-stage, lifecycle-based framework to bridge the reality gap between model-centric performance metrics and AI's materialized outcomes in deployment. While existing frameworks like MLOps focus on system stability and benchmarks measure abstract capabilities, decision-makers outside the AI stack lack systematic evidence about the behavior of AI technologies under real-world user variability and constraints. CIRCLE operationalizes the Validation phase of TEVV (Test, Evaluation, Verification, and Validation) by formalizing the translation of stakeholder concerns outside the stack into measurable signals. Unlike participatory design, which often remains localized, or algorithmic audits, which are often retrospective, CIRCLE provides a structured, prospective protocol for linking context-sensitive qualitative insights to scalable quantitative metrics. By integrating methods such as field testing, red teaming, and longitudinal studies into a coordinated pipeline, CIRCLE produces systematic knowledge: evidence that is comparable across sites yet sensitive to local context. This can enable governance based on materialized downstream effects rather than theoretical capabilities.

</details>


### [136] [Human or Machine? A Preliminary Turing Test for Speech-to-Speech Interaction](https://arxiv.org/abs/2602.24080)
*Xiang Li,Jiabao Gao,Sipei Lin,Xuan Zhou,Chi Zhang,Bo Cheng,Jiale Han,Benyou Wang*

Main category: cs.AI

TL;DR: 首次对S2S系统进行图灵测试，发现现有系统在人性化方面存在显著差距，并提出了一种新的评估方法


<details>
  <summary>Details</summary>
Motivation: 为了解决现代语音到语音（S2S）系统是否能够像人类一样对话的问题

Method: 进行首次S2S系统的图灵测试，收集了2,968名人类对9个最先进的S2S系统和28名人类参与者之间的对话的判断

Result: 没有现有的S2S系统通过测试，揭示了在人性化方面存在显著差距；分析表明瓶颈不是语义理解，而是来自副语言特征、情感表达和对话个性；提出了一种可解释的模型，利用细粒度的人性化评分，提供准确和透明的人类与机器区分，为自动人性化评估提供了一种强大的工具

Conclusion: 建立了S2S系统的首次人性化评估，超越了二元结果，实现了详细的诊断洞察，为对话人工智能系统的类人改进铺平了道路

Abstract: The pursuit of human-like conversational agents has long been guided by the Turing test. For modern speech-to-speech (S2S) systems, a critical yet unanswered question is whether they can converse like humans. To tackle this, we conduct the first Turing test for S2S systems, collecting 2,968 human judgments on dialogues between 9 state-of-the-art S2S systems and 28 human participants. Our results deliver a clear finding: no existing evaluated S2S system passes the test, revealing a significant gap in human-likeness. To diagnose this failure, we develop a fine-grained taxonomy of 18 human-likeness dimensions and crowd-annotate our collected dialogues accordingly. Our analysis shows that the bottleneck is not semantic understanding but stems from paralinguistic features, emotional expressivity, and conversational persona. Furthermore, we find that off-the-shelf AI models perform unreliably as Turing test judges. In response, we propose an interpretable model that leverages the fine-grained human-likeness ratings and delivers accurate and transparent human-vs-machine discrimination, offering a powerful tool for automatic human-likeness evaluation. Our work establishes the first human-likeness evaluation for S2S systems and moves beyond binary outcomes to enable detailed diagnostic insights, paving the way for human-like improvements in conversational AI systems.

</details>


### [137] [Artificial Agency Program: Curiosity, compression, and communication in agents](https://arxiv.org/abs/2602.24100)
*Richard Csaky*

Main category: cs.AI

TL;DR: 本文提出了一种构建人工智能系统的新方法，旨在将其作为扩展的人类-工具系统的一部分，以实现更高效的人工智能应用。


<details>
  <summary>Details</summary>
Motivation: 提出将人工智能系统构建为现实嵌入、资源受限的智能体，其发展由好奇心驱动，在物理和计算约束下进行学习。

Method: 将预测压缩、内在动机、赋权与控制、界面质量（统一）和语言/自我通信作为选择性的信息瓶颈，构建一个可验证的程序，包括明确的成本、分阶段的实验和一个具体的跨模态标记测试平台。

Result: 提供一个概念和实验框架，将内在动机、信息理论、热力学、有限理性和现代推理系统联系起来。

Conclusion: AI作为扩展的人类-工具系统的一部分，可以增加感知、理解和执行能力，同时减少人与人、工具和环境之间的摩擦。

Abstract: This paper presents the Artificial Agency Program (AAP), a position and research agenda for building AI systems as reality embedded, resource-bounded agents whose development is driven by curiosity-as-learning-progress under physical and computational constraints. The central thesis is that AI is most useful when treated as part of an extended human--tool system that increases sensing, understanding, and actuation capability while reducing friction at the interface between people, tools, and environments. The agenda unifies predictive compression, intrinsic motivation, empowerment and control, interface quality (unification), and language/self-communication as selective information bottlenecks. We formulate these ideas as a falsifiable program with explicit costs, staged experiments, and a concrete multimodal tokenized testbed in which an agent allocates limited budget among observation, action, and deliberation. The aim is to provide a conceptual and experimental framework that connects intrinsic motivation, information theory, thermodynamics, bounded rationality, and modern reasoning systems

</details>


### [138] [Recycling Failures: Salvaging Exploration in RLVR via Fine-Grained Off-Policy Guidance](https://arxiv.org/abs/2602.24110)
*Yanwei Ren,Haotian Zhang,Likang Xiao,Xikai Zhang,Jiaxing Huang,Jiayan Qiu,Baosheng Yu,Quan Chen,Liu Liu*

Main category: cs.AI

TL;DR: SCOPE 框架通过精确修复提升了 RLVR 性能，拓宽了探索空间。


<details>
  <summary>Details</summary>
Motivation: Reinforcement Learning from Verifiable Rewards (RLVR) 提升大型推理模型复杂推理能力，但标准结果监督存在缺陷。

Method: 提出 SCOPE 框架，利用 Process Reward Models 精确修复不理想运行轨迹中的第一步错误。

Result: 在数学推理任务上实现平均准确率 46.6%，在分布外推理任务上达到 53.4% 的准确率，并提高了多样性得分。

Conclusion: SCOPE 框架有效提升了 RLVR 的性能，拓宽了探索空间。

Abstract: Reinforcement Learning from Verifiable Rewards (RLVR) has emerged as a powerful paradigm for enhancing the complex reasoning capabilities of Large Reasoning Models. However, standard outcome-based supervision suffers from a critical limitation that penalizes trajectories that are largely correct but fail due to several missteps as heavily as completely erroneous ones. This coarse feedback signal causes the model to discard valuable largely correct rollouts, leading to a degradation in rollout diversity that prematurely narrows the exploration space. Process Reward Models have demonstrated efficacy in providing reliable step-wise verification for test-time scaling, naively integrating these signals into RLVR as dense rewards proves ineffective.Prior methods attempt to introduce off-policy guided whole-trajectory replacement that often outside the policy model's distribution, but still fail to utilize the largely correct rollouts generated by the model itself and thus do not effectively mitigate the narrowing of the exploration space. To address these issues, we propose SCOPE (Step-wise Correction for On-Policy Exploration), a novel framework that utilizes Process Reward Models to pinpoint the first erroneous step in suboptimal rollouts and applies fine-grained, step-wise off-policy rectification. By applying precise refinement on partially correct rollout, our method effectively salvages partially correct trajectories and increases diversity score by 13.5%, thereby sustaining a broad exploration space. Extensive experiments demonstrate that our approach establishes new state-of-the-art results, achieving an average accuracy of 46.6% on math reasoning and exhibiting robust generalization with 53.4% accuracy on out-of-distribution reasoning tasks.

</details>


### [139] [LemmaBench: A Live, Research-Level Benchmark to Evaluate LLM Capabilities in Mathematics](https://arxiv.org/abs/2602.24173)
*Antoine Peyronnet,Fabian Gloeckle,Amaury Hayat*

Main category: cs.AI

TL;DR: 提出一种新的LLM数学能力评估方法，但LLM在定理证明方面仍有提升空间


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型在研究级数学方面的能力

Method: 建立自动管道，从arXiv中提取引理并重写为独立陈述

Result: LLM在定理证明中的准确率约为10-15%，表明LLM在研究环境中达到人类水平的证明能力仍有较大进步空间

Conclusion: 提出了一种新的评估LLM在数学研究方面能力的方法，但LLM在定理证明方面的表现仍有待提高

Abstract: We present a new approach for benchmarking Large Language Model (LLM) capabilities on research-level mathematics. Existing benchmarks largely rely on static, hand-curated sets of contest or textbook-style problems as proxies for mathematical research. Instead, we establish an updatable benchmark evaluating models directly on the latest research results in mathematics. This consists of an automatic pipeline that extracts lemmas from arXiv and rewrites them into self-contained statements by making all assumptions and required definitions explicit. It results in a benchmark that can be updated regularly with new problems taken directly from human mathematical research, while previous instances can be used for training without compromising future evaluations. We benchmark current state-of-the-art LLMs, which obtain around 10-15$\%$ accuracy in theorem proving (pass@1) depending on the model, showing that there is currently a large margin of progression for LLMs to reach human-level proving capabilities in a research context.

</details>


### [140] [Uncertainty Quantification for Multimodal Large Language Models with Incoherence-adjusted Semantic Volume](https://arxiv.org/abs/2602.24195)
*Gregory Kang Ruey Lau,Hieu Dao,Nicole Kan Hui Lin,Bryan Kian Hsiang Low*

Main category: cs.AI

TL;DR: UMPIRE是一种无需训练的不确定性量化框架，可提高MLLMs的可靠性和性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决多模态大型语言模型（MLLMs）可能产生合理但错误的输出的问题，阻碍了可靠的部署。准确的不确定性度量可以启用将不可靠的查询升级到人类专家或更大模型以改进性能。然而，现有不确定性度量存在实际限制，例如仅针对特定模态设计，依赖于外部工具或计算成本高昂。

Method: 提出了一种名为UMPIRE的无需训练的不确定性量化框架，该框架适用于各种输入和输出模态，无需外部工具，仅依赖于模型的内部模态特征。UMPIRE计算给定任务实例中采样MLLM响应的失调调整后的语义体积，有效地捕捉样本的全局语义多样性和基于内部模型置信度的响应的局部失调。

Result: UMPIRE在错误检测和不确定性校准方面优于基线度量，包括图像、音频和视频文本基准，包括对抗性和分布外设置。还证明了UMPIRE对非文本输出任务的泛化，包括图像和音频生成。

Conclusion: UMPIRE是一种有效的不确定性量化框架，可以提高MLLMs的可靠性和性能。

Abstract: Despite their capabilities, Multimodal Large Language Models (MLLMs) may produce plausible but erroneous outputs, hindering reliable deployment. Accurate uncertainty metrics could enable escalation of unreliable queries to human experts or larger models for improved performance. However, existing uncertainty metrics have practical constraints, such as being designed only for specific modalities, reliant on external tools, or computationally expensive. We introduce UMPIRE, a training-free uncertainty quantification framework for MLLMs that works efficiently across various input and output modalities without external tools, relying only on the models' own internal modality features. UMPIRE computes the incoherence-adjusted semantic volume of sampled MLLM responses for a given task instance, effectively capturing both the global semantic diversity of samples and the local incoherence of responses based on internal model confidence. We propose uncertainty desiderata for MLLMs and provide theoretical analysis motivating UMPIRE's design. Extensive experiments show that UMPIRE consistently outperforms baseline metrics in error detection and uncertainty calibration across image, audio, and video-text benchmarks, including adversarial and out-of-distribution settings. We also demonstrate UMPIRE's generalization to non-text output tasks, including image and audio generation.

</details>


### [141] [A Minimal Agent for Automated Theorem Proving](https://arxiv.org/abs/2602.24273)
*Borja Requena Pozo,Austin Letson,Krystian Nowakowski,Izan Beltran Ferreiro,Leopoldo Sarra*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We propose a minimal agentic baseline that enables systematic comparison across different AI-based theorem prover architectures. This design implements the core features shared among state-of-the-art systems: iterative proof refinement, library search and context management. We evaluate our baseline using qualitatively different benchmarks and compare various popular models and design choices, and demonstrate competitive performance compared to state-of-the-art approaches, while using a significantly simpler architecture. Our results demonstrate consistent advantages of an iterative approach over multiple single-shot generations, especially in terms of sample efficiency and cost effectiveness. The implementation is released open-source as a candidate reference for future research and as an accessible prover for the community.

</details>


### [142] [DARE-bench: Evaluating Modeling and Instruction Fidelity of LLMs in Data Science](https://arxiv.org/abs/2602.24288)
*Fan Shu,Yite Wang,Ruofan Wu,Boyi Liu,Zhewei Yao,Yuxiong He,Feng Yan*

Main category: cs.AI

TL;DR: DARE-bench is a new benchmark for LLMs, significantly improving model performance in complex data science tasks.


<details>
  <summary>Details</summary>
Motivation: The fast-growing demands in using Large Language Models (LLMs) to tackle complex multi-step data science tasks create an emergent need for accurate benchmarking.

Method: Introducing DARE-bench, a benchmark designed for machine learning modeling and data science instruction following. It consists of 6,300 Kaggle-derived tasks and provides both large-scale training data and evaluation sets.

Result: DARE-bench helps improve model performance. For example, supervised fine-tuning boosts Qwen3-32B's accuracy by 1.83x and reinforcement learning boosts Qwen3-4B's accuracy by more than 8x.

Conclusion: DARE-bench is an important evaluation benchmark and critical training data for LLMs.

Abstract: The fast-growing demands in using Large Language Models (LLMs) to tackle complex multi-step data science tasks create an emergent need for accurate benchmarking. There are two major gaps in existing benchmarks: (i) the lack of standardized, process-aware evaluation that captures instruction adherence and process fidelity, and (ii) the scarcity of accurately labeled training data. To bridge these gaps, we introduce DARE-bench, a benchmark designed for machine learning modeling and data science instruction following. Unlike many existing benchmarks that rely on human- or model-based judges, all tasks in DARE-bench have verifiable ground truth, ensuring objective and reproducible evaluation. To cover a broad range of tasks and support agentic tools, DARE-bench consists of 6,300 Kaggle-derived tasks and provides both large-scale training data and evaluation sets. Extensive evaluations show that even highly capable models such as gpt-o4-mini struggle to achieve good performance, especially in machine learning modeling tasks. Using DARE-bench training tasks for fine-tuning can substantially improve model performance. For example, supervised fine-tuning boosts Qwen3-32B's accuracy by 1.83x and reinforcement learning boosts Qwen3-4B's accuracy by more than 8x. These significant improvements verify the importance of DARE-bench both as an accurate evaluation benchmark and critical training data.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [143] [Detoxifying LLMs via Representation Erasure-Based Preference Optimization](https://arxiv.org/abs/2602.23391)
*Nazanin Mohammadi Sepahvand,Eleni Triantafillou,Hugo Larochelle,Doina Precup,Daniel M. Roy,Gintare Karolina Dziugaite*

Main category: cs.LG

TL;DR: 提出REPO方法，有效解决大型语言模型的有害输出问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在训练过程中可能产生有害输出，引发安全性担忧。

Method: 提出基于表示擦除的偏好优化（REPO）方法，将脱毒问题重新定义为标记级别的偏好问题。

Result: REPO在对抗性提示和再学习攻击等复杂威胁方面表现出色，优于现有方法。

Conclusion: REPO方法在提高大型语言模型安全性方面具有显著优势。

Abstract: Large language models (LLMs) trained on webscale data can produce toxic outputs, raising concerns for safe deployment. Prior defenses, based on applications of DPO, NPO, and similar algorithms, reduce the likelihood of harmful continuations, but not robustly so: they are vulnerable to adversarial prompting and easily undone by fine-tuning-based relearning attacks. Indeed, research has shown that these edits to the model are superficial: linear probing reveals that harmful "directions" remain present in representations. To address this, we propose Representation Erasure-based Preference Optimization (REPO), reformulating detoxification as a token-level preference problem. Using a novel objective with preference data, we force the representations of toxic continuations to converge toward their benign counterparts. Our mechanistic analysis reveals that this granular approach is critical: unlike baselines, REPO induces deep, localized edits to toxicity-encoding neurons while preserving general model utility. Exhaustive evaluations show that REPO achieves state-of-the-art robustness, stopping sophisticated threats-including relearning attacks and enhanced GCG jailbreaks-where existing representation- and output-based methods fail.

</details>


### [144] [U-CAN: Utility-Aware Contrastive Attenuation for Efficient Unlearning in Generative Recommendation](https://arxiv.org/abs/2602.23400)
*Zezheng Wu,Rui Wang,Xinghe Cheng,Yang Shao,Qing Yang,Jiapu Wang,Jingwei Zhang*

Main category: cs.LG

TL;DR: U-CAN：一种解决生成式推荐中隐私问题的精确反学习框架


<details>
  <summary>Details</summary>
Motivation: 为了解决在生成式推荐（GenRec）中，由于微调用户日志而无意中将敏感属性编码到模型参数中，从而引发隐私问题。

Method: 提出了一种名为U-CAN的精确反学习框架，该框架在低秩适配器上运行。U-CAN通过对比激活来量化风险，重点关注对遗忘集高度敏感但在保留集上被抑制的具有不对称响应的神经元。为了保护性能，引入了一种效用感知校准机制，该机制结合了权重幅度和保留集激活范数，将更高的效用分数分配给对保留性能贡献较大的维度。与二进制剪枝不同，U-CAN开发了一种自适应软衰减，具有可微分的衰减函数，以选择性地降低LoRA适配器上的高风险参数，抑制敏感的检索路径，并保留推理电路的拓扑连通性。

Result: 在两个公共数据集上的七个指标上进行的实验表明，U-CAN实现了强大的隐私遗忘、效用保留和计算效率。

Conclusion: U-CAN是一种有效的隐私保护方法，可以有效地解决生成式推荐中的隐私问题，同时保持性能和效率。

Abstract: Generative Recommendation (GenRec) typically leverages Large Language Models (LLMs) to redefine personalization as an instruction-driven sequence generation task. However, fine-tuning on user logs inadvertently encodes sensitive attributes into model parameters, raising critical privacy concerns. Existing Machine Unlearning (MU) techniques struggle to navigate this tension due to the Polysemy Dilemma, where neurons superimpose sensitive data with general reasoning patterns, leading to catastrophic utility loss under traditional gradient or pruning methods. To address this, we propose Utility-aware Contrastive AttenuatioN (U-CAN), a precision unlearning framework that operates on low-rank adapters. U-CAN quantifies risk by contrasting activations and focuses on neurons with asymmetric responses that are highly sensitive to the forgetting set but suppressed on the retention set. To safeguard performance, we introduce a utility-aware calibration mechanism that combines weight magnitudes with retention-set activation norms, assigning higher utility scores to dimensions that contribute strongly to retention performance. Unlike binary pruning, which often fragments network structure, U-CAN develop adaptive soft attenuation with a differentiable decay function to selectively down-scale high-risk parameters on LoRA adapters, suppressing sensitive retrieval pathways and preserving the topological connectivity of reasoning circuits. Experiments on two public datasets across seven metrics demonstrate that U-CAN achieves strong privacy forgetting, utility retention, and computational efficiency.

</details>


### [145] [Long Range Frequency Tuning for QML](https://arxiv.org/abs/2602.23409)
*Michael Poppel,Jonas Stein,Sebastian Wölckert,Markus Baumann,Claudia Linnhoff-Popien*

Main category: cs.LG

TL;DR: 量子机器学习模型通过角度编码实现函数逼近，三进制网格初始化克服频率可达性限制，显著提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 提出量子机器学习模型使用角度编码以自然地表示截断傅里叶级数，从而实现通用的函数逼近能力。

Method: 提出可训练频率方法，通过系统实验验证频率前因子可训练性有限，并提出基于网格的初始化方法使用三进制编码以克服频率可达性限制。

Result: 三进制网格初始化在合成目标和现实世界数据集上均显著优于可训练频率方法，分别达到0.9969和0.9671的R^2分数，分别提高了22.8%和18.9%。

Conclusion: 三进制网格初始化是克服量子机器学习模型频率可达性限制的有效方法。

Abstract: Quantum machine learning models using angle encoding naturally represent truncated Fourier series, providing universal function approximation capabilities with sufficient circuit depth. For unary fixed-frequency encodings, circuit depth scales as O(omega_max * (omega_max + epsilon^{-2})) with target frequency magnitude omega_max and precision epsilon. Trainable-frequency approaches theoretically reduce this to match the target spectrum size, requiring only as many encoding gates as frequencies in the target spectrum. Despite this compelling efficiency, their practical effectiveness hinges on a key assumption: that gradient-based optimization can drive prefactors to arbitrary target values. We demonstrate through systematic experiments that frequency prefactors exhibit limited trainability: movement is constrained to approximately +/-1 units with typical learning rates. When target frequencies lie outside this reachable range, optimization frequently fails. To overcome this frequency reachability limitation, we propose grid-based initialization using ternary encodings, which generate dense integer frequency spectra. While this approach requires O(log_3(omega_max)) encoding gates -- more than the theoretical optimum but exponentially fewer than fixed-frequency methods -- it ensures target frequencies lie within the locally reachable range. On synthetic targets with three shifted high frequencies, ternary grid initialization achieves a median R^2 score of 0.9969, compared to 0.1841 for the trainable-frequency baseline. For the real-world Flight Passengers dataset, ternary grid initialization achieves a median R^2 score of 0.9671, representing a 22.8% improvement over trainable-frequency initialization (median R^2 = 0.7876).

</details>


### [146] [EvoX: Meta-Evolution for Automated Discovery](https://arxiv.org/abs/2602.23413)
*Shu Liu,Shubham Agarwal,Monishwaran Maheswaran,Mert Cemri,Zhifei Li,Qiuyang Mang,Ashwin Naren,Ethan Boneh,Audrey Cheng,Melissa Z. Pan,Alexander Du,Kurt Keutzer,Alexandros G. Dimakis,Koushik Sen,Matei Zaharia,Ion Stoica*

Main category: cs.LG

TL;DR: EvoX是一种自适应进化方法，通过优化进化过程提高了LLM驱动的优化和进化搜索的效果。


<details>
  <summary>Details</summary>
Motivation: 为了提高程序、提示和算法的效率，结合LLM驱动的优化和进化搜索已被证明是有效的。然而，大多数现有方法依赖于固定的搜索策略，这些策略在执行过程中保持静态，无法适应任务变化。

Method: 提出了一种名为EvoX的适应性进化方法，该方法在进化过程中优化其自身的进化过程。EvoX同时进化候选解决方案和用于生成它们的搜索策略，并根据进展情况持续更新如何选择和变异先前解决方案的方式。

Result: 在近200个真实世界优化任务中，EvoX在大多数任务上优于现有的AI驱动进化方法，包括AlphaEvolve、OpenEvolve、GEPA和ShinkaEvolve。

Conclusion: EvoX是一种有效的适应性进化方法，能够提高程序、提示和算法的效率。

Abstract: Recent work such as AlphaEvolve has shown that combining LLM-driven optimization with evolutionary search can effectively improve programs, prompts, and algorithms across domains. In this paradigm, previously evaluated solutions are reused to guide the model toward new candidate solutions. Crucially, the effectiveness of this evolution process depends on the search strategy: how prior solutions are selected and varied to generate new candidates. However, most existing methods rely on fixed search strategies with predefined knobs (e.g., explore-exploit ratios) that remain static throughout execution. While effective in some settings, these approaches often fail to adapt across tasks, or even within the same task as the search space changes over time. We introduce EvoX, an adaptive evolution method that optimizes its own evolution process. EvoX jointly evolves candidate solutions and the search strategies used to generate them, continuously updating how prior solutions are selected and varied based on progress. This enables the system to dynamically shift between different search strategies during the optimization process. Across nearly 200 real-world optimization tasks, EvoX outperforms existing AI-driven evolutionary methods including AlphaEvolve, OpenEvolve, GEPA, and ShinkaEvolve on the majority of tasks.

</details>


### [147] [Human Supervision as an Information Bottleneck: A Unified Theory of Error Floors in Human-Guided Learning](https://arxiv.org/abs/2602.23446)
*Alejandro Rodriguez Dominguez*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Large language models are trained primarily on human-generated data and feedback, yet they exhibit persistent errors arising from annotation noise, subjective preferences, and the limited expressive bandwidth of natural language. We argue that these limitations reflect structural properties of the supervision channel rather than model scale or optimization. We develop a unified theory showing that whenever the human supervision channel is not sufficient for a latent evaluation target, it acts as an information-reducing channel that induces a strictly positive excess-risk floor for any learner dominated by it. We formalize this Human-Bounded Intelligence limit and show that across six complementary frameworks (operator theory, PAC-Bayes, information theory, causal inference, category theory, and game-theoretic analyses of reinforcement learning from human feedback), non-sufficiency yields strictly positive lower bounds arising from the same structural decomposition into annotation noise, preference distortion, and semantic compression. The theory explains why scaling alone cannot eliminate persistent human-aligned errors and characterizes conditions under which auxiliary non-human signals (e.g., retrieval, program execution, tools) increase effective supervision capacity and collapse the floor by restoring information about the latent target. Experiments on real preference data, synthetic known-target tasks, and externally verifiable benchmarks confirm the predicted structural signatures: human-only supervision exhibits a persistent floor, while sufficiently informative auxiliary channels strictly reduce or eliminate excess error.

</details>


### [148] [Global Interpretability via Automated Preprocessing: A Framework Inspired by Psychiatric Questionnaires](https://arxiv.org/abs/2602.23459)
*Eric V. Strobl*

Main category: cs.LG

TL;DR: REFINE方法通过将非线性能力限制在预处理模块中，提高了精神病学问卷数据预测的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 在精神病学问卷数据中预测症状严重程度存在困难，因为问卷具有高度情境敏感性，并且通常只能弱预测后续症状严重程度。

Method: 采用两阶段方法REFINE（冗余利用后续信息告知非线性增强），将非线性能力限制在基线预处理模块中，该模块估计稳定的项值，然后从这些稳定的基线项到未来的严重程度学习线性映射。

Result: 在实验中，REFINE优于其他可解释方法，同时保持了跨精神病学和非精神病学纵向预测任务中预后因素的明确全局归因。

Conclusion: REFINE方法在保持预后关系透明线性并可全局解释的同时，提高了预测准确性。

Abstract: Psychiatric questionnaires are highly context sensitive and often only weakly predict subsequent symptom severity, which makes the prognostic relationship difficult to learn. Although flexible nonlinear models can improve predictive accuracy, their limited interpretability can erode clinical trust. In fields such as imaging and omics, investigators commonly address visit- and instrument-specific artifacts by extracting stable signal through preprocessing and then fitting an interpretable linear model. We adopt the same strategy for questionnaire data by decoupling preprocessing from prediction: we restrict nonlinear capacity to a baseline preprocessing module that estimates stable item values, and then learn a linear mapping from these stabilized baseline items to future severity. We refer to this two-stage method as REFINE (Redundancy-Exploiting Follow-up-Informed Nonlinear Enhancement), which concentrates nonlinearity in preprocessing while keeping the prognostic relationship transparently linear and therefore globally interpretable through a coefficient matrix, rather than through post hoc local attributions. In experiments, REFINE outperforms other interpretable approaches while preserving clear global attribution of prognostic factors across psychiatric and non-psychiatric longitudinal prediction tasks.

</details>


### [149] [Uncertainty-aware Language Guidance for Concept Bottleneck Models](https://arxiv.org/abs/2602.23495)
*Yangyi Li,Mengdi Huai*

Main category: cs.LG

TL;DR: 提出了一种新的不确定性感知CBM方法，解决了LLMs标注的不确定性和概念不确定性在CBM中的应用问题，提高了CBMs的准确性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 概念瓶颈模型（CBMs）在输入样本映射到高级语义概念后进行组合以进行最终分类，但人工标注这些概念需要大量专家知识和劳动力，限制了CBMs的广泛应用。另一方面，一些工作利用大型语言模型（LLMs）的知识来构建概念瓶颈，但存在两个基本限制：首先，它们忽略了LLMs标注的概念相关的不确定性，缺乏一个有效的机制来量化标注概念的不确定性，增加了由于LLMs的幻觉而造成错误的风险。此外，它们未能将标注的不确定性纳入概念瓶颈模型的学习过程中。

Method: 提出了一种新的不确定性感知CBM方法，该方法不仅严格量化LLMs标注的概念标签的不确定性，具有有效和分布无关的保证，而且还把量化后的概念不确定性纳入CBM训练过程中，以考虑到LLMs标注的概念的可靠性水平的不同。

Result: 通过在真实世界数据集上的大量实验验证了所提出方法的期望特性。

Conclusion: 提出了一种新的不确定性感知CBM方法，解决了LLMs标注的不确定性和概念不确定性在CBM中的应用问题，提高了CBMs的准确性和可靠性。

Abstract: Concept Bottleneck Models (CBMs) provide inherent interpretability by first mapping input samples to high-level semantic concepts, followed by a combination of these concepts for the final classification. However, the annotation of human-understandable concepts requires extensive expert knowledge and labor, constraining the broad adoption of CBMs. On the other hand, there are a few works that leverage the knowledge of large language models (LLMs) to construct concept bottlenecks. Nevertheless, they face two essential limitations: First, they overlook the uncertainty associated with the concepts annotated by LLMs and lack a valid mechanism to quantify uncertainty about the annotated concepts, increasing the risk of errors due to hallucinations from LLMs. Additionally, they fail to incorporate the uncertainty associated with these annotations into the learning process for concept bottleneck models. To address these limitations, we propose a novel uncertainty-aware CBM method, which not only rigorously quantifies the uncertainty of LLM-annotated concept labels with valid and distribution-free guarantees, but also incorporates quantified concept uncertainty into the CBM training procedure to account for varying levels of reliability across LLM-annotated concepts. We also provide the theoretical analysis for our proposed method. Extensive experiments on the real-world datasets validate the desired properties of our proposed methods.

</details>


### [150] [FedDAG: Clustered Federated Learning via Global Data and Gradient Integration for Heterogeneous Environments](https://arxiv.org/abs/2602.23504)
*Anik Pramanik,Murat Kantarcioglu,Vincent Oria,Shantanu Sharma*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Federated Learning (FL) enables a group of clients to collaboratively train a model without sharing individual data, but its performance drops when client data are heterogeneous. Clustered FL tackles this by grouping similar clients. However, existing clustered FL approaches rely solely on either data similarity or gradient similarity; however, this results in an incomplete assessment of client similarities. Prior clustered FL approaches also restrict knowledge and representation sharing to clients within the same cluster. This prevents cluster models from benefiting from the diverse client population across clusters. To address these limitations, FedDAG introduces a clustered FL framework, FedDAG, that employs a weighted, class-wise similarity metric that integrates both data and gradient information, providing a more holistic measure of similarity during clustering. In addition, FedDAG adopts a dual-encoder architecture for cluster models, comprising a primary encoder trained on its own clients' data and a secondary encoder refined using gradients from complementary clusters. This enables cross-cluster feature transfer while preserving cluster-specific specialization. Experiments on diverse benchmarks and data heterogeneity settings show that FedDAG consistently outperforms state-of-the-art clustered FL baselines in accuracy.

</details>


### [151] [Neural Operators Can Discover Functional Clusters](https://arxiv.org/abs/2602.23528)
*Yicen Li,Jose Antonio Lara Benitez,Ruiyang Hong,Anastasis Kratsios,Paul David McNicholas,Maarten Valentijn de Hoop*

Main category: cs.LG

TL;DR: 神经算子（NOs）在无限维再生核希尔伯特空间中学习类别，并应用于聚类和功能数据分析，表现出优于传统方法的潜力。


<details>
  <summary>Details</summary>
Motivation: 通过在无限个问题家族中摊销推理，算子学习正在改变科学计算。虽然神经算子（NOs）在回归方面越来越被人们所理解，但在分类及其无监督类似物：聚类方面，了解甚少。

Method: 我们证明了基于样本的神经算子可以在无限维再生核希尔伯特空间中学习任何有限类别的集合，即使在类别既不凸也不连通的情况下，只要满足轻微的核采样假设。我们的一般聚类定理表明，任何K个闭类都可以在上 Kuratowski拓扑的闭集上由NO参数化类任意精确地近似，这可以解释为不允许错误的误分类。

Result: 基于此，我们开发了一个基于NO的聚类流程，用于功能数据，并将其应用于未标记的常微分方程（ODE）轨迹家族。离散轨迹通过一个固定的预训练编码器提升到一个连续的特征图，并通过一个轻量级的可训练头映射到软分配。在多种合成ODE基准上的实验表明，所得到的实际SNO在经典方法失败的区域中恢复了潜在的动态结构，提供了与我们的一般聚类理论一致的证据。

Conclusion: 神经算子（NOs）在分类和聚类方面具有广泛的应用潜力，能够处理复杂的非线性问题。

Abstract: Operator learning is reshaping scientific computing by amortizing inference across infinite families of problems. While neural operators (NOs) are increasingly well understood for regression, far less is known for classification and its unsupervised analogue: clustering. We prove that sample-based neural operators can learn any finite collection of classes in an infinite-dimensional reproducing kernel Hilbert space, even when the classes are neither convex nor connected, under mild kernel sampling assumptions. Our universal clustering theorem shows that any $K$ closed classes can be approximated to arbitrary precision by NO-parameterized classes in the upper Kuratowski topology on closed sets, a notion that can be interpreted as disallowing false-positive misclassifications.
  Building on this, we develop an NO-powered clustering pipeline for functional data and apply it to unlabeled families of ordinary differential equation (ODE) trajectories. Discretized trajectories are lifted by a fixed pre-trained encoder into a continuous feature map and mapped to soft assignments by a lightweight trainable head. Experiments on diverse synthetic ODE benchmarks show that the resulting practical SNO recovers latent dynamical structure in regimes where classical methods fail, providing evidence consistent with our universal clustering theory.

</details>


### [152] [Sample Size Calculations for Developing Clinical Prediction Models: Overview and pmsims R package](https://arxiv.org/abs/2602.23507)
*Diana Shamsutdinova,Felix Zimmer,Oyebayo Ridwan Olaniran,Sarah Markham,Daniel Stahl,Gordon Forbes,Ewan Carr*

Main category: cs.LG

TL;DR: 提出了一种新的模拟方法来估计临床预测模型的样本量，该方法结合了多种技术，提高了估计的灵活性和准确性。


<details>
  <summary>Details</summary>
Motivation: 确定临床预测模型开发的最小样本量是一个关键且未解决的挑战，样本量不足可能导致过拟合、泛化能力差和预测偏差。

Method: 回顾现有预测模型样本量估计方法，提出一种基于模拟的方法，结合学习曲线、高斯过程优化和保证原则来识别达到目标性能的样本量。

Result: 案例研究表明，不同方法、性能指标和建模策略的样本量估计存在显著差异。pmsims提供灵活、高效、可解释的解决方案，适应不同的模型和用户定义的指标，同时明确考虑模型性能的变异性。

Conclusion: 该框架和软件通过结合灵活性和计算效率，推进了临床预测模型样本量方法。未来工作应扩展这些方法到分层和多模态数据，纳入公平性和稳定性指标，并解决缺失数据和复杂依赖结构等挑战。

Abstract: Background: Clinical prediction models are increasingly used to inform healthcare decisions, but determining the minimum sample size for their development remains a critical and unresolved challenge. Inadequate sample sizes can lead to overfitting, poor generalisability, and biased predictions. Existing approaches, such as heuristic rules, closed-form formulas, and simulation-based methods, vary in flexibility and accuracy, particularly for complex data structures and machine learning models. Methods: We review current methodologies for sample size estimation in prediction modelling and introduce a conceptual framework that distinguishes between mean-based and assurance-based criteria. Building on this, we propose a novel simulation-based approach that integrates learning curves, Gaussian Process optimisation, and assurance principles to identify sample sizes that achieve target performance with high probability. This approach is implemented in pmsims, an open-source, model-agnostic R package. Results: Through case studies, we demonstrate that sample size estimates vary substantially across methods, performance metrics, and modelling strategies. Compared to existing tools, pmsims provides flexible, efficient, and interpretable solutions that accommodate diverse models and user-defined metrics while explicitly accounting for variability in model performance. Conclusions: Our framework and software advance sample size methodology for clinical prediction modelling by combining flexibility with computational efficiency. Future work should extend these methods to hierarchical and multimodal data, incorporate fairness and stability metrics, and address challenges such as missing data and complex dependency structures.

</details>


### [153] [Neural Diffusion Intensity Models for Point Process Data](https://arxiv.org/abs/2602.24083)
*Xinlong Du,Harsha Honnappa,Vinayak Rao*

Main category: cs.LG

TL;DR: 提出了一种基于神经扩散的Cox过程模型，通过模拟漂移校正的SDE，实现了快速的后验推理，显著提高了计算效率。


<details>
  <summary>Details</summary>
Motivation: 对Cox过程进行建模，以处理过度分散的点过程数据，但传统的非参数估计和后验推理方法通常难以实现，依赖于昂贵的MCMC方法。

Method: 提出了一种基于神经随机微分方程（SDEs）的Cox过程变分框架，称为神经扩散强度模型。该方法通过模拟漂移校正的SDE，将可变长度的事件序列映射到后验强度路径，从而避免了重复的MCMC运行。

Result: 在合成和真实世界数据上的实验表明，该方法能够准确地恢复潜在的强度动态和后验路径，比基于MCMC的方法快几个数量级。

Conclusion: 神经扩散强度模型为Cox过程的建模提供了一种高效且准确的方法，能够显著提高计算效率。

Abstract: Cox processes model overdispersed point process data via a latent stochastic intensity, but both nonparametric estimation of the intensity model and posterior inference over intensity paths are typically intractable, relying on expensive MCMC methods. We introduce Neural Diffusion Intensity Models, a variational framework for Cox processes driven by neural SDEs. Our key theoretical result, based on enlargement of filtrations, shows that conditioning on point process observations preserves the diffusion structure of the latent intensity with an explicit drift correction. This guarantees the variational family contains the true posterior, so that ELBO maximization coincides with maximum likelihood estimation under sufficient model capacity. We design an amortized encoder architecture that maps variable-length event sequences to posterior intensity paths by simulating the drift-corrected SDE, replacing repeated MCMC runs with a single forward pass. Experiments on synthetic and real-world data demonstrate accurate recovery of latent intensity dynamics and posterior paths, with orders-of-magnitude speedups over MCMC-based methods.

</details>


### [154] [The Stability of Online Algorithms in Performative Prediction](https://arxiv.org/abs/2602.24207)
*Gabriele Farina,Juan Carlos Perdomo*

Main category: cs.LG

TL;DR: 研究发现，无监管算法在表现式环境中会收敛到稳定均衡，揭示了算法稳定性的原因。


<details>
  <summary>Details</summary>
Motivation: 研究算法预测在决策中的应用及其对数据分布的影响。

Method: 使用鞅论据和允许随机化，避免了对模型影响分布的任何假设，并绕过了寻找稳定模型的一些最新难度结果。

Result: 发现了表现式稳定均衡的存在，并揭示了为什么常见的算法（如梯度下降）具有自然稳定性和防止反馈循环的能力。

Conclusion: 证明了任何在表现式环境中部署的无悔算法都会收敛到一个（混合的）表现式稳定均衡。这种均衡中，模型会以使其预测在事后看起来最优的方式主动塑造数据分布。

Abstract: The use of algorithmic predictions in decision-making leads to a feedback loop where the models we deploy actively influence the data distributions we see, and later use to retrain on. This dynamic was formalized by Perdomo et al. 2020 in their work on performative prediction. Our main result is an unconditional reduction showing that any no-regret algorithm deployed in performative settings converges to a (mixed) performatively stable equilibrium: a solution in which models actively shape data distributions in ways that their own predictions look optimal in hindsight. Prior to our work, all positive results in this area made strong restrictions on how models influenced distributions. By using a martingale argument and allowing randomization, we avoid any such assumption and sidestep recent hardness results for finding stable models. Lastly, on a more conceptual note, our connection sheds light on why common algorithms, like gradient descent, are naturally stabilizing and prevent runaway feedback loops. We hope our work enables future technical transfer of ideas between online optimization and performativity.

</details>


### [155] [Active Value Querying to Minimize Additive Error in Subadditive Set Function Learning](https://arxiv.org/abs/2602.23529)
*Martin Černý,David Sychrovský,Filip Úradník,Jakub Černý*

Main category: cs.LG

TL;DR: 本文研究了如何逼近未知子可加集合函数，提出了有效的方法，并证明了其在实际场景中的有效性。


<details>
  <summary>Details</summary>
Motivation: 受限于计算经济学、组合优化和人工智能应用（如可解释机器学习）中子可加集合函数的不可约性，本文研究了一个问题：如何用加性误差逼近未知子可加集合函数。

Method: （i）彻底探索不同类别的缺失值集合函数的最小和最大补全以及它们的结果距离；（ii）开发方法最小化具有已知先验的集合函数类别之间的距离，通过在离线和在线方式披露额外的子集值；（iii）实证演示算法在实际场景中的性能。

Result: 本文提出了三种主要贡献，包括对缺失值集合函数的最小和最大补全的彻底探索，开发了一种最小化距离的方法，以及在实际场景中展示了算法的性能。

Conclusion: 本文对子可加集合函数的逼近问题进行了深入研究，提出了有效的方法来处理缺失值，并证明了算法在实际应用中的有效性。

Abstract: Subadditive set functions play a pivotal role in computational economics (especially in combinatorial auctions), combinatorial optimization or artificial intelligence applications such as interpretable machine learning. However, specifying a set function requires assigning values to an exponentially large number of subsets in general, a task that is often resource-intensive in practice, particularly when the values derive from external sources such as retraining of machine learning models. A~simple omission of certain values introduces ambiguity that becomes even more significant when the incomplete set function has to be further optimized over. Motivated by the well-known result about inapproximability of subadditive functions using deterministic value queries with respect to a multiplicative error, we study a problem of approximating an unknown subadditive (or a subclass of thereof) set function with respect to an additive error -- i. e., we aim to efficiently close the distance between minimal and maximal completions. Our contributions are threefold: (i) a thorough exploration of minimal and maximal completions of different classes of set functions with missing values and an analysis of their resulting distance; (ii) the development of methods to minimize this distance over classes of set functions with a known prior, achieved by disclosing values of additional subsets in both offline and online manner; and (iii) empirical demonstrations of the algorithms' performance in practical scenarios.

</details>


### [156] [Dynamics of Learning under User Choice: Overspecialization and Peer-Model Probing](https://arxiv.org/abs/2602.23565)
*Adhyyan Narang,Sarah Dean,Lillian J Ratliff,Maryam Fazel*

Main category: cs.LG

TL;DR: 提出了一种新的机器学习算法，用于解决过度专业化陷阱问题，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 在许多经济相关场景中，机器学习被部署在多个平台上，每个平台都从同一用户池中获取数据，每个用户都选择最能满足他们需求的平台。先前的工作仅关注学习者在他们观察到的数据分布上的“局部”损失。

Method: 提出了一种算法，允许学习者“探测”同伴模型的预测，使他们能够了解未选择他们的用户。

Result: 分析表明，当探测源足够信息丰富时（例如，已知的行业领导者或具有良好全局性能的大多数同伴），该过程几乎必然收敛到一个具有有界全人口风险的平稳点。

Conclusion: 通过反馈诱导的机制，即过度专业化陷阱，使用现有算法的学习者几乎肯定收敛到具有任意差全局性能的模型。

Abstract: In many economically relevant contexts where machine learning is deployed, multiple platforms obtain data from the same pool of users, each of whom selects the platform that best serves them. Prior work in this setting focuses exclusively on the "local" losses of learners on the distribution of data that they observe. We find that there exist instances where learners who use existing algorithms almost surely converge to models with arbitrarily poor global performance, even when models with low full-population loss exist. This happens through a feedback-induced mechanism, which we call the overspecialization trap: as learners optimize for users who already prefer them, they become less attractive to users outside this base, which further restricts the data they observe. Inspired by the recent use of knowledge distillation in modern ML, we propose an algorithm that allows learners to "probe" the predictions of peer models, enabling them to learn about users who do not select them. Our analysis characterizes when probing succeeds: this procedure converges almost surely to a stationary point with bounded full-population risk when probing sources are sufficiently informative, e.g., a known market leader or a majority of peers with good global performance. We verify our findings with semi-synthetic experiments on the MovieLens, Census, and Amazon Sentiment datasets.

</details>


### [157] [MPU: Towards Secure and Privacy-Preserving Knowledge Unlearning for Large Language Models](https://arxiv.org/abs/2602.23798)
*Tiantong Wang,Xinyu Yan,Tiantong Wu,Yurong Hao,Yong Jiang,Fei Huang,Wei Yang Bryan Lim*

Main category: cs.LG

TL;DR: MPU是一种算法无关的隐私保护未学习框架，在未学习性能上与无噪声基线相当，且在1%噪声下某些算法甚至优于无噪声基线。


<details>
  <summary>Details</summary>
Motivation: 解决机器未学习过程中隐私困境的问题

Method: 提出MPU算法，包括预处理和后处理模块

Result: 实验表明，MPU在未学习性能上与无噪声基线相当，且在1%噪声下某些算法甚至优于无噪声基线

Conclusion: MPU是一种有效的隐私保护未学习框架

Abstract: Machine unlearning for large language models often faces a privacy dilemma in which strict constraints prohibit sharing either the server's parameters or the client's forget set. To address this dual non-disclosure constraint, we propose MPU, an algorithm-agnostic privacy-preserving Multiple Perturbed Copies Unlearning framework that primarily introduces two server-side modules: Pre-Process for randomized copy generation and Post-Process for update aggregation. In Pre-Process, the server distributes multiple perturbed and reparameterized model instances, allowing the client to execute unlearning locally on its private forget set without accessing the server's exact original parameters. After local unlearning, the server performs Post-Process by inverting the reparameterization and aggregating updates with a harmonic denoising procedure to alleviate the impact of perturbation. Experiments with seven unlearning algorithms show that MPU achieves comparable unlearning performance to noise-free baselines, with most algorithms' average degradation well below 1% under 10% noise, and can even outperform the noise-free baseline for some algorithms under 1% noise. Code is available at https://github.com/Tristan-SHU/MPU.

</details>


### [158] [SDMixer: Sparse Dual-Mixer for Time Series Forecasting](https://arxiv.org/abs/2602.23581)
*Xiang Ao*

Main category: cs.LG

TL;DR: 提出了一种新的多变量时间序列预测方法，通过双流稀疏Mixer框架提高了预测准确性。


<details>
  <summary>Details</summary>
Motivation: 多变量时间序列预测在交通、能源和金融等领域应用广泛，但数据通常存在多尺度特性、弱相关性以及噪声干扰等问题，限制了现有模型的预测性能。

Method: 提出了一种双流稀疏Mixer预测框架，分别从频率和时间域的序列中提取全局趋势和局部动态特征。采用稀疏机制过滤无效信息，从而提高交叉变量依赖建模的准确性。

Result: 实验结果表明，该方法在多个真实场景数据集上取得了领先性能，验证了其有效性和通用性。

Conclusion: 该方法有效提高了多变量时间序列预测的准确性，具有广泛的应用前景。

Abstract: Multivariate time series forecasting is widely applied in fields such as transportation, energy, and finance. However, the data commonly suffers from issues of multi-scale characteristics, weak correlations, and noise interference, which limit the predictive performance of existing models. This paper proposes a dual-stream sparse Mixer prediction framework that extracts global trends and local dynamic features from sequences in both the frequency and time domains, respectively. It employs a sparsity mechanism to filter out invalid information, thereby enhancing the accuracy of cross-variable dependency modeling. Experimental results demonstrate that this method achieves leading performance on multiple real-world scenario datasets, validating its effectiveness and generality. The code is available at https://github.com/SDMixer/SDMixer

</details>


### [159] [Normalisation and Initialisation Strategies for Graph Neural Networks in Blockchain Anomaly Detection](https://arxiv.org/abs/2602.23599)
*Dang Sy Duy,Nguyen Duy Chien,Kapil Dev,Jeff Nijsse*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Graph neural networks (GNNs) offer a principled approach to financial fraud detection by jointly learning from node features and transaction graph topology. However, their effectiveness on real-world anti-money laundering (AML) benchmarks depends critically on training practices such as specifically weight initialisation and normalisation that remain underexplored. We present a systematic ablation of initialisation and normalisation strategies across three GNN architectures (GCN, GAT, and GraphSAGE) on the Elliptic Bitcoin dataset. Our experiments reveal that initialisation and normalisation are architecture-dependent: GraphSAGE achieves the strongest performance with Xavier initialisation alone, GAT benefits most from combining GraphNorm with Xavier initialisation, while GCN shows limited sensitivity to these modifications. These findings offer practical, architecture-specific guidance for deploying GNNs in AML pipelines for datasets with severe class imbalance. We release a reproducible experimental framework with temporal data splits, seeded runs, and full ablation results.

</details>


### [160] [When Does Multimodal Learning Help in Healthcare? A Benchmark on EHR and Chest X-Ray Fusion](https://arxiv.org/abs/2602.23614)
*Kejing Yin,Haizhou Xu,Wenfang Yao,Chen Liu,Zijie Chen,Yui Haang Cheung,William K. Cheung,Jing Qin*

Main category: cs.LG

TL;DR: 这项研究揭示了多模态融合在提高临床预测中的优势和局限性，并为开发可靠的多模态系统提供了指导。


<details>
  <summary>Details</summary>
Motivation: 为了回答在哪些情况下多模态学习有助于提高临床预测，如何比较不同的融合策略，现有方法对缺失模态的鲁棒性，以及多模态模型是否实现算法公平性等四个基本问题。

Method: 对来自MIMIC-IV和MIMIC-CXR标准化队列的电子健康记录（EHR）和胸部X光片（CXR）之间的多模态融合进行系统基准测试。

Result: 多模态融合在模态完整时提高性能，尤其是在需要EHR和CXR互补信息的疾病中。在现实世界的缺失情况下，除非模型明确设计用于处理不完整输入，否则多模态优势会迅速降低。多模态融合本身并不提高公平性，子群体差异主要来自不同人群的敏感性不均。

Conclusion: 这项工作提供了关于何时多模态学习有帮助、何时失败以及为什么的实用指导，为开发既有效又可靠的临床可部署多模态系统奠定了基础。

Abstract: Machine learning holds promise for advancing clinical decision support, yet it remains unclear when multimodal learning truly helps in practice, particularly under modality missingness and fairness constraints. In this work, we conduct a systematic benchmark of multimodal fusion between Electronic Health Records (EHR) and chest X-rays (CXR) on standardized cohorts from MIMIC-IV and MIMIC-CXR, aiming to answer four fundamental questions: when multimodal fusion improves clinical prediction, how different fusion strategies compare, how robust existing methods are to missing modalities, and whether multimodal models achieve algorithmic fairness. Our study reveals several key insights. Multimodal fusion improves performance when modalities are complete, with gains concentrating in diseases that require complementary information from both EHR and CXR. While cross-modal learning mechanisms capture clinically meaningful dependencies beyond simple concatenation, the rich temporal structure of EHR introduces strong modality imbalance that architectural complexity alone cannot overcome. Under realistic missingness, multimodal benefits rapidly degrade unless models are explicitly designed to handle incomplete inputs. Moreover, multimodal fusion does not inherently improve fairness, with subgroup disparities mainly arising from unequal sensitivity across demographic groups. To support reproducible and extensible evaluation, we further release a flexible benchmarking toolkit that enables plug-and-play integration of new models and datasets. Together, this work provides actionable guidance on when multimodal learning helps, when it fails, and why, laying the foundation for developing clinically deployable multimodal systems that are both effective and reliable. The open-source toolkit can be found at https://github.com/jakeykj/CareBench.

</details>


### [161] [On the Convergence of Single-Loop Stochastic Bilevel Optimization with Approximate Implicit Differentiation](https://arxiv.org/abs/2602.23633)
*Yubo Zhou,Luo Luo,Guang Dai,Haishan Ye*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Stochastic Bilevel Optimization has emerged as a fundamental framework for meta-learning and hyperparameter optimization. Despite the practical prevalence of single-loop algorithms--which update lower and upper variables concurrently--their theoretical understanding, particularly in the stochastic regime, remains significantly underdeveloped compared to their multi-loop counterparts. Existing analyses often yield suboptimal convergence rates or obscure the critical dependence on the lower-level condition number $κ$, frequently burying it within generic Lipschitz constants. In this paper, we bridge this gap by providing a refined convergence analysis of the Single-loop Stochastic Approximate Implicit Differentiation (SSAID) algorithm. We prove that SSAID achieves an $ε$-stationary point with an oracle complexity of $\mathcal{O}(κ^7 ε^{-2})$. Our result is noteworthy in two aspects: (i) it matches the optimal $\mathcal{O}(ε^{-2})$ rate of state-of-the-art multi-loop methods (e.g., stocBiO) while maintaining the computational efficiency of a single-loop update; and (ii) it provides the first explicit, fine-grained characterization of the $κ$-dependence for stochastic AID-based single-loop methods. This work demonstrates that SSAID is not merely a heuristic approach, but admits a rigorous theoretical foundation with convergence guarantees competitive with mainstream multi-loop frameworks.

</details>


### [162] [FlexGuard: Continuous Risk Scoring for Strictness-Adaptive LLM Content Moderation](https://arxiv.org/abs/2602.23636)
*Zhihao Ding,Jinming Li,Ze Lu,Jieming Shi*

Main category: cs.LG

TL;DR: FlexGuard：一个自适应严格度的LLM审核器，提高了审核准确性和鲁棒性


<details>
  <summary>Details</summary>
Motivation: 确保LLM生成内容的安

Method: 提出FlexBench和FlexGuard模型

Result: FlexGuard在FlexBench和公共基准测试中表现出更高的审核准确性和鲁棒性

Conclusion: FlexGuard是一个鲁棒且准确的LLM审核器

Abstract: Ensuring the safety of LLM-generated content is essential for real-world deployment. Most existing guardrail models formulate moderation as a fixed binary classification task, implicitly assuming a fixed definition of harmfulness. In practice, enforcement strictness - how conservatively harmfulness is defined and enforced - varies across platforms and evolves over time, making binary moderators brittle under shifting requirements. We first introduce FlexBench, a strictness-adaptive LLM moderation benchmark that enables controlled evaluation under multiple strictness regimes. Experiments on FlexBench reveal substantial cross-strictness inconsistency in existing moderators: models that perform well under one regime can degrade substantially under others, limiting their practical usability. To address this, we propose FlexGuard, an LLM-based moderator that outputs a calibrated continuous risk score reflecting risk severity and supports strictness-specific decisions via thresholding. We train FlexGuard via risk-alignment optimization to improve score-severity consistency and provide practical threshold selection strategies to adapt to target strictness at deployment. Experiments on FlexBench and public benchmarks demonstrate that FlexGuard achieves higher moderation accuracy and substantially improved robustness under varying strictness. We release the source code and data to support reproducibility.

</details>


### [163] [FedRot-LoRA: Mitigating Rotational Misalignment in Federated LoRA](https://arxiv.org/abs/2602.23638)
*Haoran Zhang,Dongjun Kim,Seohyeon Cha,Haris Vikalo*

Main category: cs.LG

TL;DR: FedRot-LoRA通过正交变换对齐客户端更新，解决了联邦LoRA训练中的聚合误差问题，提高了训练效率和模型性能。


<details>
  <summary>Details</summary>
Motivation: Federated LoRA在分布式数据上微调大型语言模型时，由于因子平均与局部更新的正确聚合之间存在差异，导致聚合误差和训练不稳定。

Method: 提出FedRot-LoRA框架，通过正交变换对齐客户端更新，以减少聚合误差和跨客户端子空间不匹配。

Result: FedRot-LoRA在自然语言理解和生成任务上优于现有的联邦LoRA基线，且在不同异构性和LoRA秩水平上表现一致。

Conclusion: FedRot-LoRA通过正交变换对齐客户端更新，提高了联邦LoRA的训练效率和模型性能。

Abstract: Federated LoRA provides a communication-efficient mechanism for fine-tuning large language models on decentralized data. In practice, however, a discrepancy between the factor-wise averaging used to preserve low rank and the mathematically correct aggregation of local updates can cause significant aggregation error and unstable training. We argue that a major source of this problem is rotational misalignment, arising from the rotational invariance of low-rank factorizations -- semantically equivalent updates can be represented in different latent subspaces across clients since $(B_i R_i)(R_i^\top A_i) = B_i A_i$. When such misaligned factors are averaged directly, they interfere destructively and degrade the global update. To address this issue, we propose FedRot-LoRA, a federated LoRA framework that aligns client updates via orthogonal transformations prior to aggregation. This alignment preserves the semantic update while reducing cross-client subspace mismatch, without increasing communication cost or restricting model expressivity. We provide a convergence analysis that examines the aggregation error induced by factor-wise averaging and shows how rotational alignment yields a tighter upper bound on this error. Extensive experiments on natural language understanding and generative tasks demonstrate that FedRot-LoRA consistently outperforms existing federated LoRA baselines across a range of heterogeneity levels and LoRA ranks.

</details>


### [164] [Selective Denoising Diffusion Model for Time Series Anomaly Detection](https://arxiv.org/abs/2602.23662)
*Kohei Obata,Zheng Chen,Yasuko Matsubara,Lingwei Zhu,Yasushi Sakurai*

Main category: cs.LG

TL;DR: 提出了一种新的基于扩散的TSAD方法AnomalyFilter，该方法在去除异常部分的同时保留正常部分，通过掩码噪声和去噪过程提高检测性能。


<details>
  <summary>Details</summary>
Motivation: 时间序列异常检测（TSAD）是几十年来研究的重要领域，基于重建的方法，主要是基于生成模型的方法，越来越受欢迎并取得了成功。扩散模型最近因其先进的生成能力而引起了人们的注意。现有的基于扩散的TSAD方法依赖于条件策略，即通过条件器的帮助从白噪声中重建输入实例。然而，这给准确重建正常部分带来了挑战，导致检测性能不佳。为了应对这一问题，我们提出了一种新的基于扩散的方法，称为AnomalyFilter，它作为一种选择性过滤器，仅在实例中去除异常部分，同时保留正常部分。为了构建这样的过滤器，我们在训练阶段对高斯噪声进行掩码，并在去噪过程中不对实例添加噪声。这两个简单组件的结合大大提高了朴素扩散模型的表现。在五个数据集上的大量实验表明，AnomalyFilter在正常部分实现了显著的低重建误差，为其在异常检测中的有效性提供了经验支持。AnomalyFilter代表了一种开创性的方法，专注于为TSAD专门设计的扩散模型的噪声设计。

Method: 提出了一种名为AnomalyFilter的新方法，该方法作为一种选择性过滤器，仅在实例中去除异常部分，同时保留正常部分。在训练阶段对高斯噪声进行掩码，并在去噪过程中不对实例添加噪声。

Result: 在五个数据集上的大量实验表明，AnomalyFilter在正常部分实现了显著的低重建误差，为其在异常检测中的有效性提供了经验支持。

Conclusion: AnomalyFilter代表了一种开创性的方法，专注于为TSAD专门设计的扩散模型的噪声设计。

Abstract: Time series anomaly detection (TSAD) has been an important area of research for decades, with reconstruction-based methods, mostly based on generative models, gaining popularity and demonstrating success. Diffusion models have recently attracted attention due to their advanced generative capabilities. Existing diffusion-based methods for TSAD rely on a conditional strategy, which reconstructs input instances from white noise with the aid of the conditioner. However, this poses challenges in accurately reconstructing the normal parts, resulting in suboptimal detection performance. In response, we propose a novel diffusion-based method, named AnomalyFilter, which acts as a selective filter that only denoises anomaly parts in the instance while retaining normal parts. To build such a filter, we mask Gaussian noise during the training phase and conduct the denoising process without adding noise to the instances. The synergy of the two simple components greatly enhances the performance of naive diffusion models. Extensive experiments on five datasets demonstrate that AnomalyFilter achieves notably low reconstruction error on normal parts, providing empirical support for its effectiveness in anomaly detection. AnomalyFilter represents a pioneering approach that focuses on the noise design of diffusion models specifically tailored for TSAD.

</details>


### [165] [Disentangled Mode-Specific Representations for Tensor Time Series via Contrastive Learning](https://arxiv.org/abs/2602.23663)
*Kohei Obata,Taichi Murayama,Zheng Chen,Yasuko Matsubara,Yasushi Sakurai*

Main category: cs.LG

TL;DR: MoST是一种新的TTS表示学习方法，在真实世界数据集上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 学习多模态张量时间序列（TTS）的表示对于各种应用有益，但也很具有挑战性，因为张量本身的复杂性阻碍了丰富表示的实现。

Method: 提出了一种名为MoST的新颖表示学习方法，该方法使用张量切片方法来降低TTS结构的复杂性，并学习可以分解为单个非时间模式的表示。

Result: 在真实世界数据集上的大量实验表明，MoST在分类和预测精度方面始终优于最先进的方法。

Conclusion: MoST是一种有效的TTS表示学习方法，在分类和预测任务中表现出色。

Abstract: Multi-mode tensor time series (TTS) can be found in many domains, such as search engines and environmental monitoring systems. Learning representations of a TTS benefits various applications, but it is also challenging since the complexities inherent in the tensor hinder the realization of rich representations. In this paper, we propose a novel representation learning method designed specifically for TTS, namely MoST. Specifically, MoST uses a tensor slicing approach to reduce the complexity of the TTS structure and learns representations that can be disentangled into individual non-temporal modes. Each representation captures mode-specific features, which are the relationship between variables within the same mode, and mode-invariant features, which are in common in representations of different modes. We employ a contrastive learning framework to learn parameters; the loss function comprises two parts intended to learn representation in a mode-specific way and mode-invariant way, effectively exploiting disentangled representations as augmentations. Extensive experiments on real-world datasets show that MoST consistently outperforms the state-of-the-art methods in terms of classification and forecasting accuracy. Code is available at https://github.com/KoheiObata/MoST.

</details>


### [166] [Optimizer-Induced Low-Dimensional Drift and Transverse Dynamics in Transformer Training](https://arxiv.org/abs/2602.23696)
*Yongzhong Xu*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We study the geometry of training trajectories in small transformer models and find that parameter updates organize into a dominant drift direction with transverse residual dynamics. Using uncentered, row-normalized trajectory PCA, we show that a single direction captures a large fraction of cumulative parameter movement early in training, while remaining components encode oscillatory behavior in auxiliary probe performance. Instantaneous gradients exhibit little alignment with this dominant direction, indicating that it arises from accumulated optimizer updates rather than per-batch gradient structure. Comparing AdamW with SGD variants at matched loss levels reveals substantial differences in trajectory geometry: AdamW develops multi-dimensional drift structure, whereas SGD-family optimizers produce nearly colinear parameter evolution and weaker probe dynamics. Reheating selectively perturbs transverse components with minimal effect on the dominant drift coordinate. These findings suggest that optimizer choice shapes the effective dimensionality and structure of learning trajectories beyond what is apparent from loss values alone.

</details>


### [167] [Bridging Dynamics Gaps via Diffusion Schrödinger Bridge for Cross-Domain Reinforcement Learning](https://arxiv.org/abs/2602.23737)
*Hanping Zhang,Yuhong Guo*

Main category: cs.LG

TL;DR: BDGxRL is a novel framework for cross-domain reinforcement learning that outperforms existing methods and shows strong adaptability.


<details>
  <summary>Details</summary>
Motivation: Cross-domain reinforcement learning (RL) aims to learn transferable policies under dynamics shifts between source and target domains.

Method: BDGxRL framework leverages Diffusion Schrödinger Bridge (DSB) to align source transitions with target-domain dynamics encoded in offline demonstrations. A reward modulation mechanism estimates rewards based on state transitions.

Result: Experiments demonstrate BDGxRL outperforms state-of-the-art baselines and shows strong adaptability under transition dynamics shifts.

Conclusion: BDGxRL is an effective framework for cross-domain reinforcement learning.

Abstract: Cross-domain reinforcement learning (RL) aims to learn transferable policies under dynamics shifts between source and target domains. A key challenge lies in the lack of target-domain environment interaction and reward supervision, which prevents direct policy learning. To address this challenge, we propose Bridging Dynamics Gaps for Cross-Domain Reinforcement Learning (BDGxRL), a novel framework that leverages Diffusion Schrödinger Bridge (DSB) to align source transitions with target-domain dynamics encoded in offline demonstrations. Moreover, we introduce a reward modulation mechanism that estimates rewards based on state transitions, applying to DSB-aligned samples to ensure consistency between rewards and target-domain dynamics. BDGxRL performs target-oriented policy learning entirely within the source domain, without access to the target environment or its rewards. Experiments on MuJoCo cross-domain benchmarks demonstrate that BDGxRL outperforms state-of-the-art baselines and shows strong adaptability under transition dynamics shifts.

</details>


### [168] [OPTIAGENT: A Physics-Driven Agentic Framework for Automated Optical Design](https://arxiv.org/abs/2602.23761)
*Yuyu Geng,Lei Sun,Yao Gao,Xinxin Hu,Zhonghua Yi,Xiaolong Qian,Weijian Hu,Jian Bai,Kaiwei Wang*

Main category: cs.LG

TL;DR: 首次将LLM应用于光学设计，成功弥合专业知识差距，实验证明方法优越。


<details>
  <summary>Details</summary>
Motivation: 为了填补光学设计领域的专业知识差距，使没有正式光学训练的用户能够成功开发功能性镜头系统。

Method: 通过创建OptiDesignQA数据集，结合系统合成和镜头完成的混合目标，使用DrGRPO进行指导，并集成专门的光学优化程序进行端到端微调。

Result: 实验结果表明，该方法优于传统的基于优化的自动化设计算法和LLM对等方法。

Conclusion: 这项工作首次尝试使用LLM进行光学设计，成功实现了光学设计领域的专业知识差距的弥合，并展示了其优越性。

Abstract: Optical design is the process of configuring optical elements to precisely manipulate light for high-fidelity imaging. It is inherently a highly non-convex optimization problem that relies heavily on human heuristic expertise and domain-specific knowledge. While Large Language Models (LLMs) possess extensive optical knowledge, their capabilities in leveraging the knowledge in designing lens system remain significantly constrained. This work represents the first attempt to employ LLMs in the field of optical design. We bridge the expertise gap by enabling users without formal optical training to successfully develop functional lens systems. Concretely, we curate a comprehensive dataset, named OptiDesignQA, which encompasses both classical lens systems sourced from standard optical textbooks and novel configurations generated by automated design algorithms for training and evaluation. Furthermore, we inject domain-specific optical expertise into the LLM through a hybrid objective of full-system synthesis and lens completion. To align the model with optical principles, we employ Group Relative Policy Optimization Done Right (DrGRPO) guided by Optical Lexicographic Reward for physics-driven policy alignment. This reward system incorporates structural format rewards, physical feasibility rewards, light-manipulation accuracy, and LLM-based heuristics. Finally, our model integrates with specialized optical optimization routines for end-to-end fine-tuning and precision refinement. We benchmark our proposed method against both traditional optimization-based automated design algorithms and LLM counterparts, and experimental results show the superiority of our method.

</details>


### [169] [MAGE: Multi-scale Autoregressive Generation for Offline Reinforcement Learning](https://arxiv.org/abs/2602.23770)
*Chenxing Lin,Xinhui Gao,Haipeng Zhang,Xinran Li,Haitao Wang,Songzhu Mei,Chenglu Wen,Weiquan Liu,Siqi Shen,Cheng Wang*

Main category: cs.LG

TL;DR: MAGE：一种基于多尺度自回归生成器的离线RL方法，在长时程稀疏奖励环境中有效生成可控轨迹。


<details>
  <summary>Details</summary>
Motivation: 为了克服现有生成方法在长时程任务中奖励稀疏的问题，以及忽略轨迹中固有的多尺度时间结构的局限性。

Method: 提出了一种名为MAGE的基于多尺度自回归生成器的离线强化学习（RL）方法。MAGE结合了条件引导的多尺度自动编码器来学习层次化的轨迹表示，以及一个多尺度Transformer来自回归地生成从粗到细的时间尺度上的轨迹表示。

Result: 在五个离线RL基准上与十五个基线算法进行了广泛的实验，结果表明MAGE成功地结合了多尺度轨迹建模和条件引导，在长时程稀疏奖励环境中生成一致且可控的轨迹。

Conclusion: MAGE方法在长时程稀疏奖励的离线RL任务中表现出色，为解决现有方法的局限性提供了新的思路。

Abstract: Generative models have gained significant traction in offline reinforcement learning (RL) due to their ability to model complex trajectory distributions. However, existing generation-based approaches still struggle with long-horizon tasks characterized by sparse rewards. Some hierarchical generation methods have been developed to mitigate this issue by decomposing the original problem into shorter-horizon subproblems using one policy and generating detailed actions with another. While effective, these methods often overlook the multi-scale temporal structure inherent in trajectories, resulting in suboptimal performance. To overcome these limitations, we propose MAGE, a Multi-scale Autoregressive GEneration-based offline RL method. MAGE incorporates a condition-guided multi-scale autoencoder to learn hierarchical trajectory representations, along with a multi-scale transformer that autoregressively generates trajectory representations from coarse to fine temporal scales. MAGE effectively captures temporal dependencies of trajectories at multiple resolutions. Additionally, a condition-guided decoder is employed to exert precise control over short-term behaviors. Extensive experiments on five offline RL benchmarks against fifteen baseline algorithms show that MAGE successfully integrates multi-scale trajectory modeling with conditional guidance, generating coherent and controllable trajectories in long-horizon sparse-reward settings.

</details>


### [170] [Provable Subspace Identification of Nonlinear Multi-view CCA](https://arxiv.org/abs/2602.23785)
*Zhiwei Han,Stefan Matthes,Hao Shen*

Main category: cs.LG

TL;DR: 本文研究了多视角非线性CCA的可识别性，提出了一种新的识别方法，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 研究多视角非线性典型相关分析（CCA）的可识别性

Method: 将多视角CCA重构成基不变子空间识别问题，使用谱扰动理论确保有限样本一致性

Result: 证明了在合适的潜在先验和频谱分离条件下，多视角CCA可以恢复成对相关信号子空间，实验验证了理论发现

Conclusion: 多视角CCA在特定条件下能够有效识别非线性相关信号子空间

Abstract: We investigate the identifiability of nonlinear Canonical Correlation Analysis (CCA) in a multi-view setup, where each view is generated by an unknown nonlinear map applied to a linear mixture of shared latents and view-private noise. Rather than attempting exact unmixing, a problem proven to be ill-posed, we instead reframe multi-view CCA as a basis-invariant subspace identification problem. We prove that, under suitable latent priors and spectral separation conditions, multi-view CCA recovers the pairwise correlated signal subspaces up to view-wise orthogonal ambiguity. For $N \geq 3$ views, the objective provably isolates the jointly correlated subspaces shared across all views while eliminating view-private variations. We further establish finite-sample consistency guarantees by translating the concentration of empirical cross-covariances into explicit subspace error bounds via spectral perturbation theory. Experiments on synthetic and rendered image datasets validate our theoretical findings and confirm the necessity of the assumed conditions.

</details>


### [171] [GRAIL: Post-hoc Compensation by Linear Reconstruction for Compressed Networks](https://arxiv.org/abs/2602.23795)
*Wenwu Tang,Dong Wang,Lothar Thiele,Olga Saukh*

Main category: cs.LG

TL;DR: GRAIL是一种新的深度模型压缩方法，通过后处理块补偿恢复精度，在多个模型上提高了性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决在深度模型压缩后，由于压缩导致的精度下降，通常需要后压缩微调的问题。

Method: 提出了一种后处理块补偿方法，称为GRAIL，该方法在模型压缩后使用一个小型校准集恢复每个块的输入输出行为。

Result: GRAIL在ResNets、ViTs和仅解码器LLMs上，在实用压缩范围内，与无数据和数据感知剪枝或折叠基线相比，始终提高了精度或困惑度。

Conclusion: GRAIL是一种简单、高效、数据感知的模型压缩方法，可以显著提高压缩模型的性能。

Abstract: Structured deep model compression methods are hardware-friendly and substantially reduce memory and inference costs. However, under aggressive compression, the resulting accuracy degradation often necessitates post-compression finetuning, which can be impractical due to missing labeled data or high training cost. We propose post-hoc blockwise compensation, called GRAIL, a simple zero-finetuning step applied after model compression that restores each block's input-output behavior using a small calibration set. The method summarizes hidden activations via a Gram matrix and applies ridge regression to linearly reconstruct the original hidden representation from the reduced one. The resulting reconstruction map is absorbed into the downstream projection weights, while the upstream layer is compressed. The approach is selector-agnostic (Magnitude, Wanda, Gram-based selection, or folding), data-aware (requiring only a few forward passes without gradients or labels), and recovers classic pruning or folding when the Gram matrix is near identity, indicating weak inter-channel correlations. Across ResNets, ViTs, and decoder-only LLMs, GRAIL consistently improves accuracy or perplexity over data-free and data-aware pruning or folding baselines in practical compression regimes, with manageable overhead and no backpropagation. The code is available at https://github.com/TWWinde/GRAIL.

</details>


### [172] [Beyond State-Wise Mirror Descent: Offline Policy Optimization with Parameteric Policies](https://arxiv.org/abs/2602.23811)
*Xiang Li,Nan Jiang,Yuheng Zhang*

Main category: cs.LG

TL;DR: 提出了一种新的离线强化学习算法，解决了现有算法的局限性，并揭示了与模仿学习之间的联系。


<details>
  <summary>Details</summary>
Motivation: 现有离线强化学习算法存在局限性，如仅适用于有限动作空间，且需要从评论家函数中隐式地诱导动作执行者，这限制了独立策略参数化的应用。

Method: 提出了一种新的算法，该算法通过将镜像下降扩展到参数化策略，并引入上下文耦合来克服现有算法的局限性。

Result: 该算法将理论保证扩展到参数化策略类，适用于大或连续的动作空间，并揭示了离线强化学习和模仿学习之间的统一性。

Conclusion: 本研究为离线强化学习提供了新的理论分析和算法见解，为更广泛的应用奠定了基础。

Abstract: We investigate the theoretical aspects of offline reinforcement learning (RL) under general function approximation. While prior works (e.g., Xie et al., 2021) have established the theoretical foundations of learning a good policy from offline data via pessimism, existing algorithms that are computationally tractable (often in an oracle-efficient sense), such as PSPI, only apply to finite and small action spaces. Moreover, these algorithms rely on state-wise mirror descent and require actors to be implicitly induced from the critic functions, failing to accommodate standalone policy parameterization which is ubiquitous in practice. In this work, we address these limitations and extend the theoretical guarantees to parameterized policy classes over large or continuous action spaces. When extending mirror descent to parameterized policies, we identify contextual coupling as the core difficulty, and show how connecting mirror descent to natural policy gradient leads to novel analyses, guarantees, and algorithmic insights, including a surprising unification between offline RL and imitation learning.

</details>


### [173] [Learning to maintain safety through expert demonstrations in settings with unknown constraints: A Q-learning perspective](https://arxiv.org/abs/2602.23816)
*George Papadopoulos,George A. Vouros*

Main category: cs.LG

TL;DR: This paper proposes the SafeQIL algorithm for learning a policy that balances safety and reward in constrained MDPs.


<details>
  <summary>Details</summary>
Motivation: Given a set of trajectories demonstrating the execution of a task safely in a constrained MDP with observable rewards but with unknown constraints and non-observable costs, we aim to find a policy that maximizes the likelihood of demonstrated trajectories trading the balance between being conservative and increasing significantly the likelihood of high-rewarding trajectories but with potentially unsafe steps.

Method: Learning a policy that maximizes the probability of the most promising trajectories with respect to the demonstrations. Formulating the 'promise' of individual state-action pairs in terms of Q values, which depend on task-specific rewards as well as on the assessment of states' safety, mixing expectations in terms of rewards and safety. Safe Q-learning perspective of the inverse learning problem under constraints.

Result: The devised Safe Q Inverse Constrained Reinforcement Learning (SafeQIL) algorithm is compared to state-of-the-art inverse constraint reinforcement learning algorithms to a set of challenging benchmark tasks, showing its merits.

Conclusion: The SafeQIL algorithm is effective in learning a policy that balances safety and reward in constrained MDPs.

Abstract: Given a set of trajectories demonstrating the execution of a task safely in a constrained MDP with observable rewards but with unknown constraints and non-observable costs, we aim to find a policy that maximizes the likelihood of demonstrated trajectories trading the balance between being conservative and increasing significantly the likelihood of high-rewarding trajectories but with potentially unsafe steps. Having these objectives, we aim towards learning a policy that maximizes the probability of the most $promising$ trajectories with respect to the demonstrations. In so doing, we formulate the ``promise" of individual state-action pairs in terms of $Q$ values, which depend on task-specific rewards as well as on the assessment of states' safety, mixing expectations in terms of rewards and safety. This entails a safe Q-learning perspective of the inverse learning problem under constraints: The devised Safe $Q$ Inverse Constrained Reinforcement Learning (SafeQIL) algorithm is compared to state-of-the art inverse constraint reinforcement learning algorithms to a set of challenging benchmark tasks, showing its merits.

</details>


### [174] [Inferring Chronic Treatment Onset from ePrescription Data: A Renewal Process Approach](https://arxiv.org/abs/2602.23824)
*Pavlin G. Poličar,Dalibor Stanimirović,Blaž Zupan*

Main category: cs.LG

TL;DR: 提出了一种基于处方动态的疾病发病推断方法，有效处理了左截断数据，但检测性能在不同疾病中存在差异。


<details>
  <summary>Details</summary>
Motivation: 纵向电子健康记录数据常存在左截断，导致诊断记录不完整且不可靠，无法确定疾病发病时间。相比之下，门诊处方形成基于更新的轨迹，为疾病管理提供连续信号。

Method: 提出一种概率框架，通过将处方动态建模为更新过程，并通过在基线泊松（偶然处方）制度和特定制度Weibull（持续治疗）更新模型之间的变化点检测，检测从偶然到持续治疗的过渡。

Result: 使用涵盖240万人次的全国电子处方数据集，该方法比简单的基于规则的触发方式产生更合理的时间发病估计，在强左截断下显著减少了不合理早期检测。检测性能在不同疾病中有所不同，与处方密度密切相关，突出了基于治疗发病推断的优缺点。

Conclusion: 基于处方的疾病发病推断方法在处理左截断数据时优于简单规则触发方法，但检测性能在不同疾病中存在差异，且与处方密度相关。

Abstract: Longitudinal electronic health record (EHR) data are often left-censored, making diagnosis records incomplete and unreliable for determining disease onset. In contrast, outpatient prescriptions form renewal-based trajectories that provide a continuous signal of disease management. We propose a probabilistic framework to infer chronic treatment onset by modeling prescription dynamics as a renewal process and detecting transitions from sporadic to sustained therapy via change-point detection between a baseline Poisson (sporadic prescribing) regime and a regime-specific Weibull (sustained therapy) renewal model. Using a nationwide ePrescription dataset of 2.4 million individuals, we show that the approach yields more temporally plausible onset estimates than naive rule-based triggering, substantially reducing implausible early detections under strong left censoring. Detection performance varies across diseases and is strongly associated with prescription density, highlighting both the strengths and limits of treatment-based onset inference.

</details>


### [175] [FedNSAM:Consistency of Local and Global Flatness for Federated Learning](https://arxiv.org/abs/2602.23827)
*Junkang Liu,Fanhua Shang,Yuxuan Tian,Hongying Liu,Yuanyuan Liu*

Main category: cs.LG

TL;DR: 提出FedNSAM算法，通过引入全局Nesterov动量来加速SAM算法，提高全局模型的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 在联邦学习中，多步本地更新和数据异构性通常会导致更尖锐的全局最小值，从而降低全局模型的性能。流行的联邦学习算法将尖锐度感知最小化（SAM）集成到本地训练中，以解决这个问题。然而，在高度数据异构的设置中，本地训练中的平坦性并不一定意味着全局模型的平坦性。因此，在客户端数据上最小化本地损失表面的尖锐度并不能使SAM在联邦学习中的有效性提高全局模型的泛化能力。

Method: 我们定义了平坦度距离来解释这一现象。通过重新思考联邦学习中的SAM并理论分析平坦度距离，我们提出了一种新的FedNSAM算法，该算法通过引入全局Nesterov动量到本地更新中来协调全局和局部平坦性的一致性。FedNSAM使用全局Nesterov动量作为客户端全局扰动估计和扩展的方向。理论上，我们通过Nesterov外推证明了比FedSAM更紧的收敛界限。在CNN和Transformer模型上进行了广泛的实验来验证FedNSAM的优异性能和效率。

Result: FedNSAM算法通过引入全局Nesterov动量来加速SAM算法，并提高了全局模型的泛化能力。在CNN和Transformer模型上的实验结果表明，FedNSAM在性能和效率方面优于FedSAM。

Conclusion: FedNSAM算法通过引入全局Nesterov动量，有效地提高了联邦学习中的SAM算法的性能，从而提高了全局模型的泛化能力。

Abstract: In federated learning (FL), multi-step local updates and data heterogeneity usually lead to sharper global minima, which degrades the performance of the global model. Popular FL algorithms integrate sharpness-aware minimization (SAM) into local training to address this issue. However, in the high data heterogeneity setting, the flatness in local training does not imply the flatness of the global model. Therefore, minimizing the sharpness of the local loss surfaces on the client data does not enable the effectiveness of SAM in FL to improve the generalization ability of the global model. We define the \textbf{flatness distance} to explain this phenomenon. By rethinking the SAM in FL and theoretically analyzing the \textbf{flatness distance}, we propose a novel \textbf{FedNSAM} algorithm that accelerates the SAM algorithm by introducing global Nesterov momentum into the local update to harmonize the consistency of global and local flatness. \textbf{FedNSAM} uses the global Nesterov momentum as the direction of local estimation of client global perturbations and extrapolation. Theoretically, we prove a tighter convergence bound than FedSAM by Nesterov extrapolation. Empirically, we conduct comprehensive experiments on CNN and Transformer models to verify the superior performance and efficiency of \textbf{FedNSAM}. The code is available at https://github.com/junkangLiu0/FedNSAM.

</details>


### [176] [LK Losses: Direct Acceptance Rate Optimization for Speculative Decoding](https://arxiv.org/abs/2602.23881)
*Alexander Samarin,Sergei Krutikov,Anton Shevtsov,Sergei Skvortsov,Filipp Fisin,Alexander Golubev*

Main category: cs.LG

TL;DR: LK losses 通过优化接受率来加速自动回归大语言模型的推理。


<details>
  <summary>Details</summary>
Motivation: 标准训练通过最小化 KL 散度来优化接受率，但 KL 散度不保证最大化接受率。

Method: 提出了一种新的训练目标 LK losses，用于优化接受率。

Result: 实验结果表明，LK losses 相比标准 KL-based 训练，在所有配置中均提高了接受率。

Conclusion: LK losses 提高了接受率，且易于实现，无需额外的计算开销，可直接集成到现有的投机器训练框架中。

Abstract: Speculative decoding accelerates autoregressive large language model (LLM) inference by using a lightweight draft model to propose candidate tokens that are then verified in parallel by the target model. The speedup is significantly determined by the acceptance rate, yet standard training minimizes Kullback-Leibler (KL) divergence as a proxy objective. While KL divergence and acceptance rate share the same global optimum, small draft models, having limited capacity, typically converge to suboptimal solutions where minimizing KL does not guarantee maximizing acceptance rate. To address this issue, we propose LK losses, special training objectives that directly target acceptance rate. Comprehensive experiments across four draft architectures and six target models, ranging from 8B to 685B parameters, demonstrate consistent improvements in acceptance metrics across all configurations compared to the standard KL-based training. We evaluate our approach on general, coding and math domains and report gains of up to 8-10% in average acceptance length. LK losses are easy to implement, introduce no computational overhead and can be directly integrated into any existing speculator training framework, making them a compelling alternative to the existing draft training objectives.

</details>


### [177] [ULW-SleepNet: An Ultra-Lightweight Network for Multimodal Sleep Stage Scoring](https://arxiv.org/abs/2602.23852)
*Zhaowen Wang,Dongdong Zhou,Qi Xu,Fengyu Cong,Mohammad Al-Sa'd,Jenni Raitoharju*

Main category: cs.LG

TL;DR: ULW-SleepNet：一种超轻量级多模态睡眠阶段评分框架，显著降低计算成本，提高睡眠监测实用性。


<details>
  <summary>Details</summary>
Motivation: 自动睡眠阶段评分对于睡眠障碍的诊断和治疗至关重要。虽然深度学习模型在睡眠研究方面取得了进展，但许多现有模型计算成本高，且专为单通道脑电图（EEG）设计，限制了它们在多模式睡眠监测（PSG）数据中的实用性。

Method: 提出ULW-SleepNet，一个超轻量级的多模态睡眠阶段评分框架，有效地整合了来自多个生理信号的信息。ULW-SleepNet采用了新颖的Dual-Stream Separable Convolution (DSSC)块、深度可分离卷积、通道参数共享和全局平均池化，以减少计算开销，同时保持竞争力。

Result: 在Sleep-EDF-20和Sleep-EDF-78数据集上评估，ULW-SleepNet分别达到86.9%和81.4%的准确率，仅使用13.3K参数和7.89M FLOPs。与最先进的方法相比，我们的模型参数减少了高达98.6%，性能损失微乎其微，显示出其在可穿戴设备和物联网设备上实时睡眠监测的强大潜力。

Conclusion: ULW-SleepNet在保证准确性的同时显著降低了计算成本，为睡眠监测提供了新的解决方案。

Abstract: Automatic sleep stage scoring is crucial for the diagnosis and treatment of sleep disorders. Although deep learning models have advanced the field, many existing models are computationally demanding and designed for single-channel electroencephalography (EEG), limiting their practicality for multimodal polysomnography (PSG) data. To overcome this, we propose ULW-SleepNet, an ultra-lightweight multimodal sleep stage scoring framework that efficiently integrates information from multiple physiological signals. ULW-SleepNet incorporates a novel Dual-Stream Separable Convolution (DSSC) Block, depthwise separable convolutions, channel-wise parameter sharing, and global average pooling to reduce computational overhead while maintaining competitive accuracy. Evaluated on the Sleep-EDF-20 and Sleep-EDF-78 datasets, ULW-SleepNet achieves accuracies of 86.9% and 81.4%, respectively, with only 13.3K parameters and 7.89M FLOPs. Compared to state-of-the-art methods, our model reduces parameters by up to 98.6% with only marginal performance loss, demonstrating its strong potential for real-time sleep monitoring on wearable and IoT devices. The source code for this study is publicly available at https://github.com/wzw999/ULW-SLEEPNET.

</details>


### [178] [A Theory of Random Graph Shift in Truncated-Spectrum vRKHS](https://arxiv.org/abs/2602.23880)
*Zhang Wan,Tingting Mu,Samuel Kaski*

Main category: cs.LG

TL;DR: 提出了一种基于随机图生成模型的理论，用于分析图分类在领域偏移下的分布偏移。


<details>
  <summary>Details</summary>
Motivation: 针对图样本的结构信息以及图分布偏移的精细分析，提出了一种基于随机图生成模型的理论。

Method: 通过向量值再生核希尔伯特空间（vRKHS）公式的推导，得到一个泛化界，其中偏移惩罚可以分解为领域差异项、光谱几何项和振幅项。

Result: 在真实数据和模拟中验证了理论的有效性。

Conclusion: 该理论为图分类在领域偏移下的研究提供了新的视角和方法。

Abstract: This paper develops a theory of graph classification under domain shift through a random-graph generative lens, where we consider intra-class graphs sharing the same random graph model (RGM) and the domain shift induced by changes in RGM components. While classic domain adaptation (DA) theories have well-underpinned existing techniques to handle graph distribution shift, the information of graph samples, which are itself structured objects, is less explored. The non-Euclidean nature of graphs and specialized architectures for graph learning further complicate a fine-grained analysis of graph distribution shifts. In this paper, we propose a theory that assumes RGM as the data generative process, exploiting its connection to hypothesis complexity in function space perspective for such fine-grained analysis. Building on a vector-valued reproducing kernel Hilbert space (vRKHS) formulation, we derive a generalization bound whose shift penalty admits a factorization into (i) a domain discrepancy term, (ii) a spectral-geometry term summarized by the accessible truncated spectrum, and (iii) an amplitude term that aggregates convergence and construction-stability effects. We empirically verify the insights on these terms in both real data and simulations.

</details>


### [179] [RewardUQ: A Unified Framework for Uncertainty-Aware Reward Models](https://arxiv.org/abs/2602.24040)
*Daniel Yang,Samuel Stante,Florian Redhardt,Lena Libon,Parnian Kassraie,Ido Hakimi,Barna Pásztor,Andreas Krause*

Main category: cs.LG

TL;DR: This paper introduces a framework for evaluating uncertainty quantification in reward models, with a focus on improving LLM performance.


<details>
  <summary>Details</summary>
Motivation: Reward models are central to aligning large language models (LLMs) with human preferences, but most approaches rely on pointwise reward estimates that overlook the epistemic uncertainty in reward models arising from limited human feedback.

Method: This work introduces a unified framework, RewardUQ, to systematically evaluate uncertainty quantification for reward models. We compare common methods along standard metrics measuring accuracy and calibration, and we propose a new ranking strategy incorporating both dimensions for a simplified comparison.

Result: Our experimental results suggest that model size and initialization have the most meaningful impact on performance, and most prior work could have benefited from alternative design choices. We release our open-source framework as a Python package.

Conclusion: RewardUQ provides a systematic way to evaluate uncertainty quantification for reward models, which helps to improve the performance of LLMs aligned with human preferences.

Abstract: Reward models are central to aligning large language models (LLMs) with human preferences. Yet most approaches rely on pointwise reward estimates that overlook the epistemic uncertainty in reward models arising from limited human feedback. Recent work suggests that quantifying this uncertainty can reduce the costs of human annotation via uncertainty-guided active learning and mitigate reward overoptimization in LLM post-training. However, uncertainty-aware reward models have so far been adopted without thorough comparison, leaving them poorly understood. This work introduces a unified framework, RewardUQ, to systematically evaluate uncertainty quantification for reward models. We compare common methods along standard metrics measuring accuracy and calibration, and we propose a new ranking strategy incorporating both dimensions for a simplified comparison. Our experimental results suggest that model size and initialization have the most meaningful impact on performance, and most prior work could have benefited from alternative design choices. To foster the development and evaluation of new methods and aid the deployment in downstream applications, we release our open-source framework as a Python package. Our code is available at https://github.com/lasgroup/rewarduq.

</details>


### [180] [MINT: Multimodal Imaging-to-Speech Knowledge Transfer for Early Alzheimer's Screening](https://arxiv.org/abs/2602.23994)
*Vrushank Ahire,Yogesh Kumar,Anouck Girard,M. A. Ganaie*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Alzheimer's disease is a progressive neurodegenerative disorder in which mild cognitive impairment (MCI) marks a critical transition between aging and dementia. Neuroimaging modalities, such as structural MRI, provide biomarkers of this transition; however, their high costs and infrastructure needs limit their deployment at a population scale. Speech analysis offers a non-invasive alternative, but speech-only classifiers are developed independently of neuroimaging, leaving decision boundaries biologically ungrounded and limiting reliability on the subtle CN-versus-MCI distinction. We propose MINT (Multimodal Imaging-to-Speech Knowledge Transfer), a three-stage cross-modal framework that transfers biomarker structure from MRI into a speech encoder at training time. An MRI teacher, trained on 1,228 subjects, defines a compact neuroimaging embedding space for CN-versus-MCI classification. A residual projection head aligns speech representations to this frozen imaging manifold via a combined geometric loss, adapting speech to the learned biomarker space while preserving imaging encoder fidelity. The frozen MRI classifier, which is never exposed to speech, is applied to aligned embeddings at inference and requires no scanner. Evaluation on ADNI-4 shows aligned speech achieves performance comparable to speech-only baselines (AUC 0.720 vs 0.711) while requiring no imaging at inference, demonstrating that MRI-derived decision boundaries can ground speech representations. Multimodal fusion improves over MRI alone (0.973 vs 0.958). Ablation studies identify dropout regularization and self-supervised pretraining as critical design decisions. To our knowledge, this is the first demonstration of MRI-to-speech knowledge transfer for early Alzheimer's screening, establishing a biologically grounded pathway for population-level cognitive triage without neuroimaging at inference.

</details>


### [181] [Foundation World Models for Agents that Learn, Verify, and Adapt Reliably Beyond Static Environments](https://arxiv.org/abs/2602.23997)
*Florent Delgrange*

Main category: cs.LG

TL;DR: This paper proposes a foundation world model for efficient, reliable, and adaptable autonomous agents.


<details>
  <summary>Details</summary>
Motivation: Next generation of autonomous agents need to learn efficiently, act reliably, and adapt in open worlds.

Method: Proposing a foundation world model with four components: learnable reward models, adaptive formal verification, online abstraction calibration, and test-time synthesis and world-model generation.

Result: Framework enables agents to synthesize verifiable programs, derive new policies, and adapt to novelty while maintaining correctness.

Conclusion: Foundation world models are a substrate for learning, reasoning, and adaptation, leading to agents that can explain and justify their behavior.

Abstract: The next generation of autonomous agents must not only learn efficiently but also act reliably and adapt their behavior in open worlds. Standard approaches typically assume fixed tasks and environments with little or no novelty, which limits world models' ability to support agents that must evolve their policies as conditions change. This paper outlines a vision for foundation world models: persistent, compositional representations that unify reinforcement learning, reactive/program synthesis, and abstraction mechanisms. We propose an agenda built around four components: (i) learnable reward models from specifications to support optimization with clear objectives; (ii) adaptive formal verification integrated throughout learning; (iii) online abstraction calibration to quantify the reliability of the model's predictions; and (iv) test-time synthesis and world-model generation guided by verifiers. Together, these components enable agents to synthesize verifiable programs, derive new policies from a small number of interactions, and maintain correctness while adapting to novelty. The resulting framework positions foundation world models as a substrate for learning, reasoning, and adaptation, laying the groundwork for agents that not only act well but can explain and justify the behavior they adopt.

</details>


### [182] [Taming Momentum: Rethinking Optimizer States Through Low-Rank Approximation](https://arxiv.org/abs/2602.24283)
*Zhengbo Wang,Jian Liang,Ran He,Zilei Wang,Tieniu Tan*

Main category: cs.LG

TL;DR: LoRA-Pre是一种高效的低秩优化器，提高了大型语言模型的预训练和微调性能。


<details>
  <summary>Details</summary>
Motivation: 现代优化器如Adam和Muon在训练大型语言模型中起核心作用，但它们对一阶和二阶动量的依赖引入了显著的内存开销，这限制了可扩展性和计算效率。

Method: 将指数移动平均（EMA）重新定义为在线梯度流中线性回归器的训练，并基于此等价性，引入了LoRA-Pre，这是一种为高效预训练设计的低秩优化器。LoRA-Pre通过将完整动量矩阵分解为在线线性学习者中的紧凑低秩子空间，从而减少了优化器的内存占用。

Result: LoRA-Pre在从Llama架构家族的60M到1B参数的模型预训练中得到了验证，实现了所有模型尺寸的最高性能。在微调场景中，LoRA-Pre在相同的秩下，始终优于所有高效的微调基线。与标准LoRA相比，LoRA-Pre在Llama-3.1-8B上实现了3.14个百分点的显著改进，在Llama-2-7B上实现了6.17个百分点的改进。

Conclusion: LoRA-Pre是一种有效的低秩优化器，可以显著提高大型语言模型的预训练和微调效率。

Abstract: Modern optimizers like Adam and Muon are central to training large language models, but their reliance on first- and second-order momenta introduces significant memory overhead, which constrains scalability and computational efficiency. In this work, we reframe the exponential moving average (EMA) used in these momenta as the training of a linear regressor via online gradient flow. Building on this equivalence, we introduce LoRA-Pre, a novel low-rank optimizer designed for efficient pre-training. Specifically, LoRA-Pre reduces the optimizer's memory footprint by decomposing the full momentum matrix into a compact low-rank subspace within the online linear learner, thereby maintaining optimization performance while improving memory efficiency. We empirically validate LoRA-Pre's efficacy by pre-training models from the Llama architecture family, scaling from 60M to 1B parameters. LoRA-Pre achieves the highest performance across all model sizes. Notably, LoRA-Pre demonstrates remarkable rank efficiency, achieving comparable or superior results using only 1/8 the rank of baseline methods. Beyond pre-training, we evaluate LoRA-Pre's effectiveness in fine-tuning scenarios. With the same rank, LoRA-Pre consistently outperforms all efficient fine-tuning baselines. Specifically, compared to standard LoRA, LoRA-Pre achieves substantial improvements of 3.14 points on Llama-3.1-8B and 6.17 points on Llama-2-7B, validating our approach's effectiveness across both pre-training and fine-tuning paradigms. Our code is publicly available at https://github.com/mrflogs/LoRA-Pre.

</details>


### [183] [InfoNCE Induces Gaussian Distribution](https://arxiv.org/abs/2602.24012)
*Roy Betser,Eyal Gofer,Meir Yossef Levi,Guy Gilboa*

Main category: cs.LG

TL;DR: This paper analyzes the Gaussian structure in contrastive learning representations and its implications for analysis and applications.


<details>
  <summary>Details</summary>
Motivation: Contrastive learning has become a cornerstone of modern representation learning, allowing training with massive unlabeled data for both task-specific and general (foundation) models.

Method: Analysis of InfoNCE objective in contrastive training, establishing Gaussian structure in representations, and conducting experiments on synthetic and CIFAR-10 datasets.

Result: Demonstrating consistent Gaussian behavior in representations, providing a principled explanation for Gaussianity in contrastive representations, and enabling principled analytical treatment of learned representations.

Conclusion: The Gaussian model in contrastive learning enables principled analytical treatment of learned representations and supports a wide range of applications.

Abstract: Contrastive learning has become a cornerstone of modern representation learning, allowing training with massive unlabeled data for both task-specific and general (foundation) models. A prototypical loss in contrastive training is InfoNCE and its variants. In this work, we show that the InfoNCE objective induces Gaussian structure in representations that emerge from contrastive training. We establish this result in two complementary regimes. First, we show that under certain alignment and concentration assumptions, projections of the high-dimensional representation asymptotically approach a multivariate Gaussian distribution. Next, under less strict assumptions, we show that adding a small asymptotically vanishing regularization term that promotes low feature norm and high feature entropy leads to similar asymptotic results. We support our analysis with experiments on synthetic and CIFAR-10 datasets across multiple encoder architectures and sizes, demonstrating consistent Gaussian behavior. This perspective provides a principled explanation for commonly observed Gaussianity in contrastive representations. The resulting Gaussian model enables principled analytical treatment of learned representations and is expected to support a wide range of applications in contrastive learning.

</details>


### [184] [pathsig: A GPU-Accelerated Library for Truncated and Projected Path Signatures](https://arxiv.org/abs/2602.24066)
*Tobias Nygaard*

Main category: cs.LG

TL;DR: pathsig是一个高效、可扩展的路径签名库，显著提高机器学习性能


<details>
  <summary>Details</summary>
Motivation: 解决现有库在大型、基于梯度的学习中的可扩展性问题

Method: 引入pathsig库，使用CUDA内核在词基础上直接计算路径签名

Result: pathsig在计算截断签名时速度比其他库快10-30倍，在需要通过签名进行反向传播的训练中快4-10倍

Conclusion: pathsig是一个高效的、可扩展的路径签名库，能够显著提高机器学习任务中的性能

Abstract: Path signatures provide a rich representation of sequential data, with strong theoretical guarantees and good performance in a variety of machine-learning tasks. While signatures have progressed from fixed feature extractors to trainable components of machine-learning models, existing libraries often lack the required scalability for large-scale, gradient-based learning. To address this gap, this paper introduces pathsig, a PyTorch-native library that computes path signatures directly in the word basis. By using CUDA kernels to update signature coefficients in parallel over prefix-closed word sets, pathsig achieves high GPU throughput and near-minimal peak memory. Compared with other libraries, pathsig achieves 10-30x speedups for computation of truncated signatures and up to 4-10x speedups in training that require backpropagation through the signature. Beyond regular truncation, pathsig supports projections of the (infinite-dimensional) signature onto user-specified sets of words and anisotropic truncation motivated by inhomogeneous path regularity, enabling more compact representations that can reduce dimensionality, redundancy, and computational cost.

</details>


### [185] [Leveraging Non-linear Dimension Reduction and Random Walk Co-occurrence for Node Embedding](https://arxiv.org/abs/2602.24069)
*Ryan DeWolfe*

Main category: cs.LG

TL;DR: COVE UMAP HDBSCAN pipeline improves clustering and link prediction performance


<details>
  <summary>Details</summary>
Motivation: Leveraging non-linear dimension reduction techniques to remove the low dimension constraint from node embedding

Method: Proposing COVE, an explainable high dimensional embedding that uses UMAP for low dimension reduction, inspired by neural embedding methods and diffusion process

Result: Slightly increases performance on clustering and link prediction tasks, similar to the popular Louvain algorithm in community detection

Conclusion: COVE UMAP HDBSCAN pipeline is effective for node embedding and community detection

Abstract: Leveraging non-linear dimension reduction techniques, we remove the low dimension constraint from node embedding and propose COVE, an explainable high dimensional embedding that, when reduced to low dimension with UMAP, slightly increases performance on clustering and link prediction tasks. The embedding is inspired by neural embedding methods that use co-occurrence on a random walk as an indication of similarity, and is closely related to a diffusion process. Extending on recent community detection benchmarks, we find that a COVE UMAP HDBSCAN pipeline performs similarly to the popular Louvain algorithm.

</details>


### [186] [Learning with a Budget: Identifying the Best Arm with Resource Constraints](https://arxiv.org/abs/2602.24146)
*Zitian Li,Wang Chi Cheung*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: In many applications, evaluating the effectiveness of different alternatives comes with varying costs or resource usage. Motivated by such heterogeneity, we study the Best Arm Identification with Resource Constraints (BAIwRC) problem, where an agent seeks to identify the best alternative (aka arm) in the presence of resource constraints. Each arm pull consumes one or more types of limited resources. We make two key contributions. First, we propose the Successive Halving with Resource Rationing (SH-RR) algorithm, which integrates resource-aware allocation into the classical successive halving framework on best arm identification. The SH-RR algorithm unifies the theoretical analysis for both the stochastic and deterministic consumption settings, with a new \textit{effective consumption measure

</details>


### [187] [Sandwiching Polynomials for Geometric Concepts with Low Intrinsic Dimension](https://arxiv.org/abs/2602.24178)
*Adam R. Klivans,Konstantinos Stavropoulos,Arsen Vasilyan*

Main category: cs.LG

TL;DR: Improved sandwiching polynomial approximators with significant theoretical improvements.


<details>
  <summary>Details</summary>
Motivation: Recent work has shown the surprising power of low-degree sandwiching polynomial approximators in challenging learning settings.

Method: A new method for constructing low-degree sandwiching polynomials that yield greatly improved degree bounds for several fundamental function classes and marginal distributions.

Result: Improved degree bounds for functions of k halfspaces under the Gaussian distribution, doubly exponential improvements for low-dimensional polynomial threshold functions with respect to Gaussians.

Conclusion: The method is simple and utilizes the smoothness of the target function's boundary, and provides significant improvements over previous bounds.

Abstract: Recent work has shown the surprising power of low-degree sandwiching polynomial approximators in the context of challenging learning settings such as learning with distribution shift, testable learning, and learning with contamination. A pair of sandwiching polynomials approximate a target function in expectation while also providing pointwise upper and lower bounds on the function's values. In this paper, we give a new method for constructing low-degree sandwiching polynomials that yield greatly improved degree bounds for several fundamental function classes and marginal distributions. In particular, we obtain degree $\mathrm{poly}(k)$ sandwiching polynomials for functions of $k$ halfspaces under the Gaussian distribution, improving exponentially over the prior $2^{O(k)}$ bound. More broadly, our approach applies to function classes that are low-dimensional and have smooth boundary.
  In contrast to prior work, our proof is relatively simple and directly uses the smoothness of the target function's boundary to construct sandwiching Lipschitz functions, which are amenable to results from high-dimensional approximation theory. For low-dimensional polynomial threshold functions (PTFs) with respect to Gaussians, we obtain doubly exponential improvements without applying the FT-mollification method of Kane used in the best previous result.

</details>


### [188] [Multi-Objective Reinforcement Learning for Large-Scale Tote Allocation in Human-Robot Collaborative Fulfillment Centers](https://arxiv.org/abs/2602.24182)
*Sikata Sengupta,Guangyi Liu,Omer Gottesman,Joseph W Durham,Michael Kearns,Aaron Roth,Michael Caldara*

Main category: cs.LG

TL;DR: 提出了一种基于MORL的优化方法，用于解决基于容器的配送中心合并流程中的复杂决策问题。


<details>
  <summary>Details</summary>
Motivation: 优化基于容器的配送中心合并流程，需要权衡处理速度、资源使用和空间利用率等竞争目标，同时遵守各种现实世界的运营约束。

Method: 提出一个大规模多目标强化学习（MORL）任务，该方法基于零和博弈中的最佳反应和非后悔动态解决约束RL问题，从而实现原理性的最小-最大策略学习。

Result: 在现实仓库模拟中对策略进行评估，显示该方法有效地权衡了目标，并通过经验观察到它学习到一个满足所有约束的单个策略。此外，引入了一个理论框架来解决误差消除问题，该方法返回一个拉格朗日值接近游戏最小-最大值的单次迭代。

Conclusion: MORL在解决大型工业系统中复杂、高影响决策问题方面具有前景。

Abstract: Optimizing the consolidation process in container-based fulfillment centers requires trading off competing objectives such as processing speed, resource usage, and space utilization while adhering to a range of real-world operational constraints. This process involves moving items between containers via a combination of human and robotic workstations to free up space for inbound inventory and increase container utilization. We formulate this problem as a large-scale Multi-Objective Reinforcement Learning (MORL) task with high-dimensional state spaces and dynamic system behavior. Our method builds on recent theoretical advances in solving constrained RL problems via best-response and no-regret dynamics in zero-sum games, enabling principled minimax policy learning. Policy evaluation on realistic warehouse simulations shows that our approach effectively trades off objectives, and we empirically observe that it learns a single policy that simultaneously satisfies all constraints, even if this is not theoretically guaranteed. We further introduce a theoretical framework to handle the problem of error cancellation, where time-averaged solutions display oscillatory behavior. This method returns a single iterate whose Lagrangian value is close to the minimax value of the game. These results demonstrate the promise of MORL in solving complex, high-impact decision-making problems in large-scale industrial systems.

</details>


### [189] [Flow-Based Density Ratio Estimation for Intractable Distributions with Applications in Genomics](https://arxiv.org/abs/2602.24201)
*Egor Antipov,Alessandro Palma,Lorenzo Consoli,Stephan Günnemann,Andrea Dittadi,Fabian J. Theis*

Main category: cs.LG

TL;DR: This paper proposes a new method for efficient density ratio estimation in probabilistic modeling and single-cell genomics data analysis.


<details>
  <summary>Details</summary>
Motivation: Estimating density ratios between pairs of intractable data distributions is a core problem in probabilistic modeling.

Method: Leveraging condition-aware flow matching to derive a single dynamical formulation for tracking density ratios along generative trajectories.

Result: Competitive performance on simulated benchmarks for closed-form ratio estimation, and versatile tasks in single-cell genomics data analysis.

Conclusion: The method provides an efficient and versatile approach for density ratio estimation in probabilistic modeling and single-cell genomics data analysis.

Abstract: Estimating density ratios between pairs of intractable data distributions is a core problem in probabilistic modeling, enabling principled comparisons of sample likelihoods under different data-generating processes across conditions and covariates. While exact-likelihood models such as normalizing flows offer a promising approach to density ratio estimation, naive flow-based evaluations are computationally expensive, as they require simulating costly likelihood integrals for each distribution separately. In this work, we leverage condition-aware flow matching to derive a single dynamical formulation for tracking density ratios along generative trajectories. We demonstrate competitive performance on simulated benchmarks for closed-form ratio estimation, and show that our method supports versatile tasks in single-cell genomics data analysis, where likelihood-based comparisons of cellular states across experimental conditions enable treatment effect estimation and batch correction evaluation.

</details>


### [190] [An Efficient Unsupervised Federated Learning Approach for Anomaly Detection in Heterogeneous IoT Networks](https://arxiv.org/abs/2602.24209)
*Mohsen Tajgardan,Atena Shiranzaei,Mahdi Rabbani,Reza Khoshkangini,Mahtab Jamali*

Main category: cs.LG

TL;DR: 提出了一种新的无监督联邦学习框架，用于在物联网环境中进行异常检测，该框架利用互补数据集的共享特征，并显著提高了检测精度。


<details>
  <summary>Details</summary>
Motivation: 在物联网（IoT）等分布式环境中，联邦学习（FL）是一种有效的范式，可以保护隐私并提高异常检测的准确性。然而，由于设备功能的差异、数据格式和通信约束，IoT数据具有异构性，这给维护全局模型性能和隐私带来了挑战。

Method: 提出了一种高效的无监督联邦学习框架，该框架利用来自两个不同物联网数据集的共享特征来增强异常检测，同时保留数据集特定的特征。为了提高透明度和可解释性，采用了可解释人工智能技术，如SHAP，以识别影响局部模型决策的关键特征。

Result: 在真实世界的物联网数据集上进行的实验表明，所提出的方法在异常检测精度方面显著优于传统的联邦学习方法。

Conclusion: 这项工作强调了使用互补数据集的共享特征来优化无监督联邦学习，并在去中心化的物联网环境中实现更优的异常检测结果的潜力。

Abstract: Federated learning (FL) is an effective paradigm for distributed environments such as the Internet of Things (IoT), where data from diverse devices with varying functionalities remains localized while contributing to a shared global model. By eliminating the need to transmit raw data, FL inherently preserves privacy. However, the heterogeneous nature of IoT data, stemming from differences in device capabilities, data formats, and communication constraints, poses significant challenges to maintaining both global model performance and privacy. In the context of IoT-based anomaly detection, unsupervised FL offers a promising means to identify abnormal behavior without centralized data aggregation. Nevertheless, feature heterogeneity across devices complicates model training and optimization, hindering effective implementation. In this study we propose an efficient unsupervised FL framework that enhances anomaly detection by leveraging shared features from two distinct IoT datasets: one focused on anomaly detection and the other on device identification, while preserving dataset-specific features. To improve transparency and interpretability, we employ explainable AI techniques, such as SHAP, to identify key features influencing local model decisions. Experiments conducted on real-world IoT datasets demonstrate that the proposed method significantly outperforms conventional FL approaches in anomaly detection accuracy. This work underscores the potential of using shared features from complementary datasets to optimize unsupervised federated learning and achieve superior anomaly detection results in decentralized IoT environments.

</details>


### [191] [Adaptive Combinatorial Experimental Design: Pareto Optimality for Decision-Making and Inference](https://arxiv.org/abs/2602.24231)
*Hongrui Xie,Junyu Cao,Kan Xu*

Main category: cs.LG

TL;DR: 提出了两种算法，优化了组合多臂老虎机中的权衡，为多目标决策提供了新的框架。


<details>
  <summary>Details</summary>
Motivation: 研究自适应组合实验设计，关注组合多臂老虎机（CMAB）中遗憾最小化与统计功效之间的权衡。

Method: 通过Pareto最优的概念形式化权衡，建立CMAB中Pareto有效学习的等价条件。针对不同信息结构（全老虎机反馈和半老虎机反馈）提出MixCombKL和MixCombUCB算法。

Result: 证明算法在遗憾和臂间距估计误差上均有有限时间保证。发现更丰富的反馈可以显著收紧可达的Pareto前沿。

Conclusion: 为多目标决策中的自适应组合实验提供了一个原则性框架。

Abstract: In this paper, we provide the first investigation into adaptive combinatorial experimental design, focusing on the trade-off between regret minimization and statistical power in combinatorial multi-armed bandits (CMAB). While minimizing regret requires repeated exploitation of high-reward arms, accurate inference on reward gaps requires sufficient exploration of suboptimal actions. We formalize this trade-off through the concept of Pareto optimality and establish equivalent conditions for Pareto-efficient learning in CMAB. We consider two relevant cases under different information structures, i.e., full-bandit feedback and semi-bandit feedback, and propose two algorithms MixCombKL and MixCombUCB respectively for these two cases. We provide theoretical guarantees showing that both algorithms are Pareto optimal, achieving finite-time guarantees on both regret and estimation error of arm gaps. Our results further reveal that richer feedback significantly tightens the attainable Pareto frontier, with the primary gains arising from improved estimation accuracy under our proposed methods. Taken together, these findings establish a principled framework for adaptive combinatorial experimentation in multi-objective decision-making.

</details>


### [192] [Time Series Foundation Models as Strong Baselines in Transportation Forecasting: A Large-Scale Benchmark Analysis](https://arxiv.org/abs/2602.24238)
*Javier Pulido,Filipe Rodrigues*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Accurate forecasting of transportation dynamics is essential for urban mobility and infrastructure planning. Although recent work has achieved strong performance with deep learning models, these methods typically require dataset-specific training, architecture design and hyper-parameter tuning. This paper evaluates whether general-purpose time-series foundation models can serve as forecasters for transportation tasks by benchmarking the zero-shot performance of the state-of-the-art model, Chronos-2, across ten real-world datasets covering highway traffic volume and flow, urban traffic speed, bike-sharing demand, and electric vehicle charging station data. Under a consistent evaluation protocol, we find that, even without any task-specific fine-tuning, Chronos-2 delivers state-of-the-art or competitive accuracy across most datasets, frequently outperforming classical statistical baselines and specialized deep learning architectures, particularly at longer horizons. Beyond point forecasting, we evaluate its native probabilistic outputs using prediction-interval coverage and sharpness, demonstrating that Chronos-2 also provides useful uncertainty quantification without dataset-specific training. In general, this study supports the adoption of time-series foundation models as a key baseline for transportation forecasting research.

</details>


### [193] [Chunk-wise Attention Transducers for Fast and Accurate Streaming Speech-to-Text](https://arxiv.org/abs/2602.24245)
*Hainan Xu,Vladimir Bataev,Travis M. Bartley,Jagadeesh Balam*

Main category: cs.LG

TL;DR: 提出了CHAT模型，提高了RNN-T的效率和准确性，同时保持了流处理能力。


<details>
  <summary>Details</summary>
Motivation: 为了提高RNN-T模型的效率和准确性，同时保持其流处理能力。

Method: 提出了一种名为Chunk-wise Attention Transducer (CHAT)的新型模型，该模型在固定大小的块中处理音频，并在每个块中使用交叉注意力。

Result: 显著提高了效率，包括46.2%的训练内存峰值降低、1.36倍的训练速度提升和1.69倍的推理速度提升。同时，在多个语言和任务上实现了准确性的提升，包括6.3%的相对WER降低和18.0%的BLEU提升。

Conclusion: CHAT模型为部署更强大的流式语音模型提供了实际解决方案，同时满足了实时性限制。

Abstract: We propose Chunk-wise Attention Transducer (CHAT), a novel extension to RNN-T models that processes audio in fixed-size chunks while employing cross-attention within each chunk. This hybrid approach maintains RNN-T's streaming capability while introducing controlled flexibility for local alignment modeling. CHAT significantly reduces the temporal dimension that RNN-T must handle, yielding substantial efficiency improvements: up to 46.2% reduction in peak training memory, up to 1.36X faster training, and up to 1.69X faster inference. Alongside these efficiency gains, CHAT achieves consistent accuracy improvements over RNN-T across multiple languages and tasks -- up to 6.3% relative WER reduction for speech recognition and up to 18.0% BLEU improvement for speech translation. The method proves particularly effective for speech translation, where RNN-T's strict monotonic alignment hurts performance. Our results demonstrate that the CHAT model offers a practical solution for deploying more capable streaming speech models without sacrificing real-time constraints.

</details>


### [194] [Histopathology Image Normalization via Latent Manifold Compaction](https://arxiv.org/abs/2602.24251)
*Xiaolong Zhang,Jianwei Zhang,Selim Sevim,Emek Demir,Ece Eksi,Xubo Song*

Main category: cs.LG

TL;DR: 提出了一种新的无监督学习框架 LMC，用于解决计算病理学中的批次效应问题，显著提高了模型的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 内容中提到，在计算病理学中，来自染色协议、扫描仪和采集管道的技术差异导致的批次效应是一个持续的挑战，阻碍了跨批次的泛化，并限制了模型在临床地点的可靠部署。

Method: 提出了一种名为 Latent Manifold Compaction (LMC) 的无监督表示学习框架，通过显式压缩由染色引起的潜在流形来从单个源数据集中学习批次不变的嵌入，从而实现图像归一化。

Result: 在三个具有挑战性的公共和内部基准测试中评估了 LMC，它显著减少了多个数据集中的批次引起的分离，并在下游的跨批次分类和检测任务中一致地优于最先进的归一化方法，实现了更好的泛化。

Conclusion: LMC 在计算病理学中表现出色，能够有效减少批次效应，提高模型的泛化能力。

Abstract: Batch effects arising from technical variations in histopathology staining protocols, scanners, and acquisition pipelines pose a persistent challenge for computational pathology, hindering cross-batch generalization and limiting reliable deployment of models across clinical sites. In this work, we introduce Latent Manifold Compaction (LMC), an unsupervised representation learning framework that performs image harmonization by learning batch-invariant embeddings from a single source dataset through explicit compaction of stain-induced latent manifolds. This allows LMC to generalize to target domain data unseen during training. Evaluated on three challenging public and in-house benchmarks, LMC substantially reduces batch-induced separations across multiple datasets and consistently outperforms state-of-the-art normalization methods in downstream cross-batch classification and detection tasks, enabling superior generalization.

</details>


### [195] [Who Guards the Guardians? The Challenges of Evaluating Identifiability of Learned Representations](https://arxiv.org/abs/2602.24278)
*Shruti Joshi,Théo Saulus,Wieland Brendel,Philippe Brouillard,Dhanya Sridhar,Patrik Reizinger*

Main category: cs.LG

TL;DR: 现有指标在特定条件下有效，但在其他情况下可能产生误导性结果。


<details>
  <summary>Details</summary>
Motivation: 评估表示学习中的可识别性通常使用标准指标（例如，MCC，DCI，R^2）在具有已知真实因素的合成基准上进行。这些指标被认为反映了可识别性理论保证的等价类内的恢复。

Method: 引入一个将DGP假设与编码器几何分离的分类法，用于描述现有指标的适用域，并发布一个可重复的压力测试和比较评估套件。

Result: 发现这些指标仅在特定结构条件下才成立，否则会产生系统性的错误阳性反应和错误阴性反应。

Conclusion: 需要更深入地理解指标背后的假设，以避免错误地评估可识别性。

Abstract: Identifiability in representation learning is commonly evaluated using standard metrics (e.g., MCC, DCI, R^2) on synthetic benchmarks with known ground-truth factors. These metrics are assumed to reflect recovery up to the equivalence class guaranteed by identifiability theory. We show that this assumption holds only under specific structural conditions: each metric implicitly encodes assumptions about both the data-generating process (DGP) and the encoder. When these assumptions are violated, metrics become misspecified and can produce systematic false positives and false negatives. Such failures occur both within classical identifiability regimes and in post-hoc settings where identifiability is most needed. We introduce a taxonomy separating DGP assumptions from encoder geometry, use it to characterise the validity domains of existing metrics, and release an evaluation suite for reproducible stress testing and comparison.

</details>
